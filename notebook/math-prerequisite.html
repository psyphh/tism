

<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>1. 先備數學知識 &#8212; 統計建模技法</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.min.css" integrity="sha384-KA6wR/X5RY4zFAHpv/CnoG2UW1uogYfdnP67Uv7eULvTveboZJg0qUpmJZb5VqzN" crossorigin="anonymous">
    <link href="../_static/css/index.css" rel="stylesheet">
    <link rel="stylesheet" href="../_static/sphinx-book-theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyter-sphinx.css" />
    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/sphinx-book-theme.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/mystnb.js"></script>
    <script src="../_static/sphinx-book-theme.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.18.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="2. 線性迴歸" href="linear-regression.html" />
    <link rel="prev" title="關於「統計建模技法」" href="../intro.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="docsearch:language" content="en">



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  
  <h1 class="site-logo" id="site-title">統計建模技法</h1>
  
</a>
</div>

<form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>

<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <ul class="current nav sidenav_l1">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   1. 先備數學知識
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="linear-regression.html">
   2. 線性迴歸
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lab-torch-tensor.html">
   3. Lab: 張量與線性代數
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="logistic-regression.html">
   4. 邏輯斯迴歸
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lab-torch-diff-opt.html">
   5. Lab: 數值微分與優化
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="probability-distribution.html">
   6. 機率分佈
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="maximum-likelihood.html">
   7. 最大概似法
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lab-torch-mle.html">
   8. Lab: 最大概似估計
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="likelihood-inference.html">
   9. 概似推論
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="true-score-model.html">
   10. 真實分數模型
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="factor-analysis.html">
   11. 因素分析
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="item-response-theory.html">
   12. 試題反應理論
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="mixture-modeling.html">
   13. 混合建模
  </a>
 </li>
</ul>

</nav>

 <!-- To handle the deprecated key -->

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        <div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    
    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/notebook/math-prerequisite.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
    
</div>
        <!-- Source interaction buttons -->


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/psyphh/tism/blob/master/tism/notebook/math-prerequisite.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="Launch Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="../_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        
    </div>
</div>

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id2">
   1.1. 向量
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id3">
     1.1.1. 何謂向量？
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id4">
     1.1.2. 向量的運算
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id5">
     1.1.3. 距離、內積、與餘弦值
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id6">
   1.2. 矩陣
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id7">
     1.2.1. 何謂矩陣
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id8">
     1.2.2. 矩陣的運算
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id9">
     1.2.3. 反矩陣
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id10">
     1.2.4. 分解
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id11">
   1.3. 微分
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id12">
     1.3.1. 何謂微分？
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id13">
     1.3.2. 微分的規則
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id14">
     1.3.3. 多變數函數的微分
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id15">
     1.3.4. 泰勒之定理
    </a>
   </li>
  </ul>
 </li>
</ul>

        </nav>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="id1">
<h1><span class="section-number">1. </span>先備數學知識<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h1>
<div class="section" id="id2">
<h2><span class="section-number">1.1. </span>向量<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id3">
<h3><span class="section-number">1.1.1. </span>何謂向量？<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h3>
<p>在進行統計建模時，一筆觀測值（observation）常透過<strong>向量</strong>（vector）來表徵。令 <span class="math notranslate nohighlight">\(x\)</span> 表示一 <span class="math notranslate nohighlight">\(N\)</span> 維之直行向量（column vector），則其包含了 <span class="math notranslate nohighlight">\(x_1,x_2,...,x_N\)</span> 共 <span class="math notranslate nohighlight">\(N\)</span> 個元素（element），按順序由上至下排列而成，即</p>
<div class="math notranslate nohighlight">
\[\begin{split}
x =
\begin{pmatrix}
x_1 \\
x_2 \\
\vdots \\
x_N
\end{pmatrix}.
\end{split}\]</div>
<p>在此講義中，我們通常使用大寫的英文字母作為一組數列的元素個數，而該字母的小寫則作為索引使用，因此，<span class="math notranslate nohighlight">\(x\)</span> 的元素個素為 <span class="math notranslate nohighlight">\(N\)</span>，我們用<span class="math notranslate nohighlight">\(x_n\)</span> 來表示 <span class="math notranslate nohighlight">\(x\)</span> 的第 <span class="math notranslate nohighlight">\(n\)</span> 個元素。</p>
<p>我們可以將 <span class="math notranslate nohighlight">\(x\)</span> 進行<strong>轉置</strong>（transpose），將其轉為一橫列向量（row vector），即</p>
<div class="math notranslate nohighlight">
\[
x^T =
\begin{pmatrix}
x_1 &amp; x_2 &amp; \cdots &amp; x_N
\end{pmatrix}.
\]</div>
<p>透過轉置，原本由上而下的排列，改成有左至右的排列。不過，請記得在文獻中向量一詞，大多指稱的是直行向量。</p>
<p>有時為了節省呈現空間，會將一直行向量寫為 <span class="math notranslate nohighlight">\(x = (x_1, x_2,...,x_N)\)</span>，利用逗點來分隔不同的上下欄位。注意，這跟橫列向量利用空格將元素左右分隔的做法是不同的。</p>
<p>一個向量<strong>長度</strong>（length），可透過其<strong>範數</strong>（norm）來獲得。範數有許多種定義方式，不過，最常見的為 <span class="math notranslate nohighlight">\(L_2\)</span> 範數，即</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
||x|| &amp;= \sqrt{x_1^2 + x_2^2 +...+x_N^2}\\
&amp; = \sqrt{ \sum_{n=1}^N x_n^2}.
\end{aligned}
\end{split}\]</div>
<p>此式被稱作 <span class="math notranslate nohighlight">\(L_2\)</span> 範數的原因在於，其使用了二次方來處理每一項。從公式中可以看出來，唯有當 <span class="math notranslate nohighlight">\(x\)</span> 的所有成分皆為0時，其範數才會是0。</p>
<p>當一向量的範數為1時，我們會說其為標準化的向量（normalized vector），給定任何長度不為0的向量 <span class="math notranslate nohighlight">\(x\)</span>，我們可以透過以下公式對其進行標準化</p>
<div class="math notranslate nohighlight">
\[\begin{split}
x^* = \frac{1}{||x||} x =
\begin{pmatrix}
\frac{1}{||x||} x_1 \\
\frac{1}{||x||} x_2 \\
\vdots \\
\frac{1}{||x||} x_N
\end{pmatrix}.
\end{split}\]</div>
<p>這邊牽涉到純量對向量的乘法，請見下一小節。</p>
</div>
<div class="section" id="id4">
<h3><span class="section-number">1.1.2. </span>向量的運算<a class="headerlink" href="#id4" title="Permalink to this headline">¶</a></h3>
<p>令 <span class="math notranslate nohighlight">\(x\)</span> 與 <span class="math notranslate nohighlight">\(y\)</span> 表示兩 <span class="math notranslate nohighlight">\(N\)</span> 維之向量，則我們可以將向量的加法與減法分別定義為</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
x  + y=
\begin{pmatrix}
x_1 \\
x_2 \\
\vdots \\
x_N
\end{pmatrix}
+
\begin{pmatrix}
y_1 \\
y_2 \\
\vdots \\
y_N
\end{pmatrix}
=
\begin{pmatrix}
x_1 + y_1 \\
x_2 + y_2 \\
\vdots \\
x_N + y_N
\end{pmatrix}.
\end{aligned}
\end{split}\]</div>
<p>與</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
x  - y=
\begin{pmatrix}
x_1 \\
x_2 \\
\vdots \\
x_N
\end{pmatrix}
-
\begin{pmatrix}
y_1 \\
y_2 \\
\vdots \\
y_N
\end{pmatrix}
=
\begin{pmatrix}
x_1 - y_1 \\
x_2 - y_2 \\
\vdots \\
x_N - y_N
\end{pmatrix}.
\end{aligned}
\end{split}\]</div>
<p>即所謂元素對元素的（element to element）加法與減法。</p>
<p>依循相同的邏輯，我們可定義所謂元素對元素的乘法與除法，不過，在線性代數（linear algebra）此一學門中，甚少直接使用此類的運算子。相較之下，純量對向量之乘法則較常使用。令 <span class="math notranslate nohighlight">\(\alpha\)</span> 表示一純量（scalar），純量對向量之乘法定義為</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\alpha x =
\alpha
\begin{pmatrix}
x_1 \\
x_2 \\
\vdots \\
x_N
\end{pmatrix}
=
\begin{pmatrix}
\alpha x_1 \\
\alpha x_2 \\
\vdots \\
\alpha x_N
\end{pmatrix}.
\end{aligned}
\end{split}\]</div>
</div>
<div class="section" id="id5">
<h3><span class="section-number">1.1.3. </span>距離、內積、與餘弦值<a class="headerlink" href="#id5" title="Permalink to this headline">¶</a></h3>
<p>在度量兩向量是否相似時，最基本的做法是計算兩者之間的<strong>距離</strong>（distance），即</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
d(x, y) &amp;= ||x - y|| \\
&amp;=
\sqrt{(x_1 - y_1)^2 + (x_2 - y_2)^2 + ... + (x_N - y_N)^2} \\
&amp;=
\sqrt{\sum_{n=1}^N (x_n - y_n)^2 }.
\end{aligned}
\end{split}\]</div>
<p>前述根據 <span class="math notranslate nohighlight">\(L_2\)</span> 範數計算的距離，亦稱做 <span class="math notranslate nohighlight">\(L_2\)</span> 距離，或是歐幾里德距離（Euclidean distance）。從公式中可以看出來，<span class="math notranslate nohighlight">\(x\)</span> 和 <span class="math notranslate nohighlight">\(y\)</span> 唯有在所有元素都相等的前提之下，其距離才會等於0。當 <span class="math notranslate nohighlight">\(x\)</span> 與 <span class="math notranslate nohighlight">\(y\)</span> 的內積為0時，我們會說 <span class="math notranslate nohighlight">\(x\)</span> 與 <span class="math notranslate nohighlight">\(y\)</span> 為垂直（orthogonal），表示兩向量在 <span class="math notranslate nohighlight">\(N\)</span> 為空間中，呈現90度的夾角，兩垂直的向量常被解讀為其具有獨立未重疊的訊息。</p>
<p>另外一種度量兩向量是否相似的做法是，計算其<strong>內積</strong>（inner product），即</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\langle x,y \rangle &amp;=
x_1 y_1 + x_2 y_2 + ... + x_N y_N \\
&amp; = \sum_{n=1}^N x_n y_n.
\end{aligned}
\end{split}\]</div>
<p>當 <span class="math notranslate nohighlight">\(x\)</span> 與 <span class="math notranslate nohighlight">\(y\)</span> 個元素間存在同時大同時小的關係時，兩者的內積會很大，若存在一個大另一個小的關係時，則內積會很小（指的是存在負號的很小），若未存在前述的組型時，則內積會靠近0。</p>
<p>有時，<span class="math notranslate nohighlight">\(x\)</span> 與 <span class="math notranslate nohighlight">\(y\)</span> 的內積會簡單的寫為 <span class="math notranslate nohighlight">\(x^T y\)</span>，這與下一小節會提到的矩陣乘法有關。</p>
<p>然而，內積並未考慮到 <span class="math notranslate nohighlight">\(x\)</span> 和 <span class="math notranslate nohighlight">\(y\)</span> 自身的長度，其數值大小較難直接做解釋。故此，令<span class="math notranslate nohighlight">\(\theta\)</span> 表示兩向量之夾角，則其<strong>餘弦值</strong>（cosine）之計算，乃將兩向量之內積除上各自的長度，即</p>
<div class="math notranslate nohighlight">
\[
\text{cos}(\theta) = \frac{\langle x,y \rangle}{||x|| ||y||}.
\]</div>
<p>當兩向量夾角的餘弦值，可透過以下的方式解釋：</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\text{cos}(\theta)\)</span> 靠近1時，表示兩向量在同一方向上，相似性高。</p></li>
<li><p><span class="math notranslate nohighlight">\(\text{cos}(\theta)\)</span> 靠近-1時，表示兩向量在相反方向上，相似性亦高，但存在相反的關係。</p></li>
<li><p><span class="math notranslate nohighlight">\(\text{cos}(\theta)\)</span> 靠近0時，表示兩向量靠近垂直的關係，相似性低。</p></li>
</ul>
<p>不過，餘弦值大多在向量內部數值皆為正的情境下作為相似性指標（即所謂的第一象限），此時，<span class="math notranslate nohighlight">\(0 \leq\text{cos}(\theta) \leq 1\)</span>，不需考慮 <span class="math notranslate nohighlight">\(-1 \leq\text{cos}(\theta) \leq 0\)</span> 的情況。</p>
</div>
</div>
<div class="section" id="id6">
<h2><span class="section-number">1.2. </span>矩陣<a class="headerlink" href="#id6" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id7">
<h3><span class="section-number">1.2.1. </span>何謂矩陣<a class="headerlink" href="#id7" title="Permalink to this headline">¶</a></h3>
<p>若把 <span class="math notranslate nohighlight">\(M\)</span> 個 <span class="math notranslate nohighlight">\(N\)</span> 維的橫列向量由上至下排列，則可形成一尺寸為 <span class="math notranslate nohighlight">\(M \times N\)</span> 之<strong>矩陣</strong>（matrix）。這裡，<span class="math notranslate nohighlight">\(M\)</span> 為矩陣的橫列（row）個數，<span class="math notranslate nohighlight">\(N\)</span> 則為矩陣的直行（column）個數。</p>
<p>舉例來說，令 <span class="math notranslate nohighlight">\(a_1, a_2,...,a_M\)</span> 皆表示 <span class="math notranslate nohighlight">\(N\)</span> 維之向量，則我們可以將其排為一矩陣 <span class="math notranslate nohighlight">\(A\)</span></p>
<div class="math notranslate nohighlight">
\[\begin{split}
A =
\underbrace{\begin{pmatrix}
  a_{1}^T \\
   a_{2}^T \\
    \vdots \\
     a_{M}^T \\
 \end{pmatrix}}_{M \times N}.
\end{split}\]</div>
<p>注意，在這邊，我們有過度使用符號的狀況，在前一小節，<span class="math notranslate nohighlight">\(a_n\)</span>用於表示向量 <span class="math notranslate nohighlight">\(a\)</span> 的第 <span class="math notranslate nohighlight">\(n\)</span> 個元素，但在這邊，<span class="math notranslate nohighlight">\(a_m\)</span> 被用於表示第 <span class="math notranslate nohighlight">\(m\)</span> 個 <span class="math notranslate nohighlight">\(N\)</span> 維之向量，讀者應嘗試理解以具備獨立判斷的能力。</p>
<p>若我們將前述的矩陣 <span class="math notranslate nohighlight">\(A\)</span> 每一個元素寫開來，則可以表示為</p>
<div class="math notranslate nohighlight">
\[\begin{split}
A =
 \underbrace{\begin{pmatrix}
  a_{1,1} &amp; a_{1,2} &amp; \cdots &amp; a_{1,N} \\
  a_{2,1} &amp; a_{2,2} &amp; \cdots &amp; a_{2,N} \\
  \vdots  &amp; \vdots  &amp; \ddots &amp; \vdots  \\
  a_{M,1} &amp; a_{M,2} &amp; \cdots &amp; a_{M,N}
 \end{pmatrix}}_{M \times N}.
\end{split}\]</div>
<p>這裡，<span class="math notranslate nohighlight">\(A\)</span> 的第 <span class="math notranslate nohighlight">\((m,n)\)</span> 個元素，我們使用 <span class="math notranslate nohighlight">\(a_{m,n}\)</span>（或<span class="math notranslate nohighlight">\(a_{mn}\)</span>）來表示。</p>
<p>給定一尺寸為 <span class="math notranslate nohighlight">\(M \times N\)</span>之矩陣 <span class="math notranslate nohighlight">\(A\)</span>，其第 <span class="math notranslate nohighlight">\((m,n)\)</span> 個元素為 <span class="math notranslate nohighlight">\(a_{mn}\)</span>，則 <span class="math notranslate nohighlight">\(A\)</span> 的<strong>轉置</strong>（transpose）被定義為</p>
<div class="math notranslate nohighlight">
\[\begin{split}
A^T =
 \underbrace{\begin{pmatrix}
  a_{11} &amp; a_{21} &amp; \cdots &amp; a_{M1} \\
  a_{12} &amp; a_{22} &amp; \cdots &amp; a_{M2} \\
  \vdots  &amp; \vdots  &amp; \ddots &amp; \vdots  \\
  a_{1N} &amp; a_{2N} &amp; \cdots &amp; a_{MN}
 \end{pmatrix}}_{N \times M}.
\end{split}\]</div>
<p>因此，<span class="math notranslate nohighlight">\(A^T\)</span> 可視為將 <span class="math notranslate nohighlight">\(A\)</span> 的直行與橫列訊息互換的結果，而 <span class="math notranslate nohighlight">\(A^T\)</span> 的尺寸則轉為了 <span class="math notranslate nohighlight">\(N \times M\)</span>。</p>
<p>舉例來說，若矩陣 <span class="math notranslate nohighlight">\(A =  \begin{pmatrix}
  1 &amp; 2 &amp; 3  \\
  4 &amp; 5 &amp; 6
 \end{pmatrix}\)</span>為一<span class="math notranslate nohighlight">\(2 \times 3\)</span>的矩陣，則其轉置為一 <span class="math notranslate nohighlight">\(3 \times 2\)</span> 之矩陣 <span class="math notranslate nohighlight">\(A^T =  \begin{pmatrix}
  1 &amp; 4 \\
  2 &amp; 5 \\
  3 &amp; 6
 \end{pmatrix}\)</span>。</p>
<p>在矩陣的世界中，有幾種特別的矩陣讀者需要特別認識：</p>
<ol class="simple">
<li><p>當 <span class="math notranslate nohighlight">\(A\)</span> 的尺寸為 <span class="math notranslate nohighlight">\(M \times M\)</span>時，則 <span class="math notranslate nohighlight">\(A\)</span> 被稱作<strong>方陣</strong>（square matrix）。</p></li>
<li><p>當 <span class="math notranslate nohighlight">\(A\)</span> 為方陣，且進一步滿足 <span class="math notranslate nohighlight">\(A = A^T\)</span> 時，則其稱作<strong>對稱矩陣</strong>（symmetric matrix）。</p></li>
<li><p>當 <span class="math notranslate nohighlight">\(A\)</span> 為方陣，且其只有對角線左下角（可包含對角線）之元素不為0時，其稱作<strong>下三角矩陣</strong>（lower triangular matrix），反之，若只有對角線右上角之元素不為0時，則其稱作<strong>上三角矩陣</strong>（upper triangular matrix）。</p></li>
<li><p>當 <span class="math notranslate nohighlight">\(A\)</span> 為方陣，且其只有對角線元素不為0時，則其稱作<strong>對角矩陣</strong>（diagonal matrix）。</p></li>
<li><p>當 <span class="math notranslate nohighlight">\(A\)</span> 為方陣，且其僅有對角線元素數值為1，其它為0時，則其稱作<strong>單位矩陣</strong>（identity matrix）。其在矩陣的世界中，扮演像是純量1的角色。</p></li>
</ol>
<p>這幾個特別的矩陣，在計算矩陣乘法、反矩陣、或是拆解時，可能會有一些好的特性讓計算變得比較容易。</p>
</div>
<div class="section" id="id8">
<h3><span class="section-number">1.2.2. </span>矩陣的運算<a class="headerlink" href="#id8" title="Permalink to this headline">¶</a></h3>
<p>令 <span class="math notranslate nohighlight">\(A\)</span> 與 <span class="math notranslate nohighlight">\(B\)</span> 皆表示 <span class="math notranslate nohighlight">\(M \times N\)</span> 之矩陣，其內部元素分別為 <span class="math notranslate nohighlight">\(a_{mn}\)</span> 與 <span class="math notranslate nohighlight">\(b_{mn}\)</span>，則矩陣加減法，即 <span class="math notranslate nohighlight">\(A \pm B\)</span>，被定義元素對元素的加減法：</p>
<div class="math notranslate nohighlight">
\[\begin{split}
A  + B=
 \begin{pmatrix}
  a_{11} \pm b_{11} &amp; a_{12}\pm  b_{12} &amp; \cdots &amp; a_{1N}\pm  b_{1N} \\
  a_{21} \pm  b_{21} &amp; a_{22}\pm  b_{22} &amp; \cdots &amp; a_{2N}\pm  b_{2N} \\
  \vdots  &amp; \vdots  &amp; \ddots &amp; \vdots  \\
  a_{M1} \pm  b_{M1}&amp; a_{M2}\pm  b_{M2} &amp; \cdots &amp; a_{MN}\pm  b_{MN}
 \end{pmatrix}.
\end{split}\]</div>
<p>由於此為元素對元素的運算，因此，<span class="math notranslate nohighlight">\(A\)</span> 和 <span class="math notranslate nohighlight">\(B\)</span> 兩者的尺寸必須一樣。</p>
<p>既然可以計算元素對元素的加減法，自然也可以同樣定義元素對元素的乘除法，不過，線性代數的領域依然很少直接用到此運算子。</p>
<p><strong>矩陣乘法</strong>（matrix multiplication）在統計建模中則是相當的關鍵。令 <span class="math notranslate nohighlight">\(A\)</span> 表示一 <span class="math notranslate nohighlight">\(M \times N\)</span> 之矩陣，<span class="math notranslate nohighlight">\(x\)</span> 表示一 <span class="math notranslate nohighlight">\(N\)</span> 維之向量，或視為一 <span class="math notranslate nohighlight">\(N \times 1\)</span> 的矩陣，則矩陣對向量的乘法被定義為</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
Ax &amp;=  \underbrace{\begin{pmatrix}
  a_{11} &amp; a_{12} &amp; \cdots &amp; a_{1N} \\
  a_{21} &amp; a_{22} &amp; \cdots &amp; a_{2N} \\
  \vdots  &amp; \vdots  &amp; \ddots &amp; \vdots  \\
  a_{M1} &amp; a_{M2} &amp; \cdots &amp; a_{MN}
 \end{pmatrix}}_{M \times N}
\underbrace{\begin{pmatrix}
x_1 \\
x_2 \\
\vdots \\
x_N
\end{pmatrix}}_{N \times 1} \\
&amp;=
\underbrace{\begin{pmatrix}
  a_{11} x_1 + a_{12} x_2 + ... + a_{1N} x_N \\
  a_{21} x_1 + a_{22} x_2 + ... + a_{2N} x_N \\
  \vdots \\
  a_{M1} x_1 + a_{M2} x_2 + ... + a_{MN} x_N
 \end{pmatrix}}_{M \times 1}\\
&amp;=
\underbrace{\begin{pmatrix}
  \sum_{n=1}^N a_{1n} x_n \\
  \sum_{n=1}^N a_{2n} x_n\\
  \vdots \\
  \sum_{n=1}^N a_{Mn} x_n
 \end{pmatrix}}_{M \times 1}.
\end{aligned}
\end{split}\]</div>
<p>在此，我們可以觀察到兩件事情</p>
<ol class="simple">
<li><p><span class="math notranslate nohighlight">\(x\)</span> 的維度，必須跟 <span class="math notranslate nohighlight">\(A\)</span> 的直行個數相等，此矩陣向量之乘法才能夠被合法定義。</p></li>
<li><p><span class="math notranslate nohighlight">\(A\)</span> 和 <span class="math notranslate nohighlight">\(x\)</span> 相乘後的結果乃一 <span class="math notranslate nohighlight">\(M\)</span> 維之向量，其亦可理解為 <span class="math notranslate nohighlight">\(M \times 1\)</span> 之矩陣。</p></li>
<li><p><span class="math notranslate nohighlight">\(Ax\)</span> 的第 <span class="math notranslate nohighlight">\(m\)</span> 個元素，可以視為 <span class="math notranslate nohighlight">\(A\)</span> 的第 <span class="math notranslate nohighlight">\(m\)</span> 個橫列所形成之向量，對 <span class="math notranslate nohighlight">\(x\)</span> 做內積的結果。</p></li>
</ol>
<p>因此，若我們將 <span class="math notranslate nohighlight">\(A\)</span> 寫為 <span class="math notranslate nohighlight">\(A =
\begin{pmatrix}
  a_1^T \\
  a_2^T  \\
  \vdots \\
  a_{M}^T
 \end{pmatrix}\)</span>，這裡，<span class="math notranslate nohighlight">\(a_m^T\)</span> 表示由 <span class="math notranslate nohighlight">\(A\)</span> 的第 <span class="math notranslate nohighlight">\(m\)</span> 個橫列形成的橫列向量，則 <span class="math notranslate nohighlight">\(Ax\)</span> 可以表示為</p>
<div class="math notranslate nohighlight">
\[\begin{split}
 Ax
 = \begin{pmatrix}
   a_1^Tx  \\
   a_2^Tx  \\
  \vdots \\
   a_M^Tx
 \end{pmatrix}
 = \begin{pmatrix}
  \langle a_1,x \rangle \\
  \langle a_2,x \rangle \\
  \vdots \\
  \langle a_M,x \rangle
 \end{pmatrix}.
 \end{split}\]</div>
<p>我們可延伸前述的概念，來定義矩陣對矩陣的乘法。令 <span class="math notranslate nohighlight">\(A\)</span> 與 <span class="math notranslate nohighlight">\(B\)</span> 分別表示 <span class="math notranslate nohighlight">\(M \times N\)</span> 與 <span class="math notranslate nohighlight">\(N \times P\)</span> 之矩陣，其內部元素分別為 <span class="math notranslate nohighlight">\(a_{mn}\)</span> 與 <span class="math notranslate nohighlight">\(b_{np}\)</span>，則 <span class="math notranslate nohighlight">\(A\)</span> 與 <span class="math notranslate nohighlight">\(B\)</span> 相乘被定義為</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
AB &amp;=
 \underbrace{\begin{pmatrix}
  a_{11} &amp; a_{12} &amp; \cdots &amp; a_{1N} \\
  a_{21} &amp; a_{22} &amp; \cdots &amp; a_{2N} \\
  \vdots  &amp; \vdots  &amp; \ddots &amp; \vdots  \\
  a_{M1} &amp; a_{M2} &amp; \cdots &amp; a_{MN}
 \end{pmatrix}}_{M \times N}
  \underbrace{\begin{pmatrix}
  b_{11} &amp; b_{12} &amp; \cdots &amp; b_{1P} \\
  b_{21} &amp; b_{22} &amp; \cdots &amp; b_{2P} \\
  \vdots  &amp; \vdots  &amp; \ddots &amp; \vdots  \\
  b_{N1} &amp; b_{N2} &amp; \cdots &amp; b_{NP}
 \end{pmatrix}}_{N \times P} \\
  &amp;=
  \underbrace{\begin{pmatrix}
  \sum_{n=1}^N a_{1n} b_{n1} &amp; \sum_{n=1}^N a_{1n} b_{n2} &amp; \cdots &amp; \sum_{n=1}^N a_{1n} b_{nP} \\
  \sum_{n=1}^N a_{2n} b_{n1} &amp; \sum_{n=1}^N a_{2n} b_{n2} &amp; \cdots &amp; \sum_{n=1}^N a_{2n} b_{nP} \\
  \vdots  &amp; \vdots  &amp; \ddots &amp; \vdots  \\
  \sum_{n=1}^N a_{Nn} b_{n1} &amp; \sum_{n=1}^N a_{Nn} b_{n2} &amp; \cdots &amp; \sum_{n=1}^N a_{Nn} b_{nP}
 \end{pmatrix}}_{M \times P}.
 \end{aligned}
\end{split}\]</div>
<p>其相乘之結果為一 <span class="math notranslate nohighlight">\(N \times P\)</span> 之矩陣。</p>
<p>前述的公式，不太容易看出來矩陣乘法的結構，因此，我們將 <span class="math notranslate nohighlight">\(A\)</span> 與 <span class="math notranslate nohighlight">\(B\)</span> 重新寫成以下的結構</p>
<div class="math notranslate nohighlight">
\[\begin{split}
A =
\begin{pmatrix}
  a_1^T \\
  a_2^T  \\
  \vdots \\
  a_{M}^T
 \end{pmatrix},
 B =
\begin{pmatrix}
  b_1 &amp; b_2  &amp; \cdots &amp; b_{P}
 \end{pmatrix}.
\end{split}\]</div>
<p>這裡，<span class="math notranslate nohighlight">\(a_m^T\)</span> 表示由 <span class="math notranslate nohighlight">\(A\)</span> 的第 <span class="math notranslate nohighlight">\(m\)</span> 個橫列形成的橫列向量，<span class="math notranslate nohighlight">\(b_p\)</span> 表示由 <span class="math notranslate nohighlight">\(B\)</span> 的第 <span class="math notranslate nohighlight">\(p\)</span> 個直行形成的直行向量，則 <span class="math notranslate nohighlight">\(AB\)</span> 可寫為</p>
<div class="math notranslate nohighlight">
\[\begin{split}
AB =
  \begin{pmatrix}
  a_1^T b_1 &amp; a_1^T b_2 &amp; \cdots &amp; a_1^T b_P \\
  a_2^T b_1 &amp; a_2^T b_2 &amp; \cdots &amp; a_2^T b_P \\
  \vdots  &amp; \vdots  &amp; \ddots &amp; \vdots  \\
  a_M^T b_1 &amp; a_M^T b_2 &amp; \cdots &amp; a_M^T b_P \\
 \end{pmatrix}.
\end{split}\]</div>
</div>
<div class="section" id="id9">
<h3><span class="section-number">1.2.3. </span>反矩陣<a class="headerlink" href="#id9" title="Permalink to this headline">¶</a></h3>
<p>當 <span class="math notranslate nohighlight">\(A\)</span> 為 <span class="math notranslate nohighlight">\(N \times N\)</span>之方陣，且其行或列並未包含累贅的（redundant）訊息時，則 <span class="math notranslate nohighlight">\(A\)</span> 存在<strong>反矩陣</strong>（inverse）。意即，存在一 <span class="math notranslate nohighlight">\(N \times N\)</span> 矩陣 <span class="math notranslate nohighlight">\(A^{-1}\)</span>，其滿足</p>
<div class="math notranslate nohighlight">
\[
A^{-1} A = A A^{-1} = I.
\]</div>
<p>這裡 <span class="math notranslate nohighlight">\(I\)</span> 為 <span class="math notranslate nohighlight">\(N \times N\)</span> 單位矩陣。當反矩陣存在時，其為獨特的（unique），意思是，反矩陣只會有一個。</p>
<p>反矩陣的計算常與 <span class="math notranslate nohighlight">\(N\)</span> 元一次方程組的求解有關。考慮以下的聯立方程組</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{cases}
a_{11} x_1 + a_{12} x_2 + ... + a_{1N} x_N = b_1, \\
a_{21} x_1 + a_{22} x_2 + ... + a_{2N} x_N = b_2, \\
\vdots \\
a_{N1} x_1 + a_{N2} x_2 + ... + a_{NN} x_N = b_N. \\
\end{cases}
\end{split}\]</div>
<p>在此方程組中，有<span class="math notranslate nohighlight">\(x_1, x_2,...,x_N\)</span> 共 <span class="math notranslate nohighlight">\(N\)</span> 個未知數，並有 <span class="math notranslate nohighlight">\(N\)</span> 條式子。令<span class="math notranslate nohighlight">\(A\)</span>表示由 <span class="math notranslate nohighlight">\(a_{mn}\)</span>組成的 <span class="math notranslate nohighlight">\(N \times N\)</span> 矩陣（<span class="math notranslate nohighlight">\(1 \leq m,n\leq N\)</span>），<span class="math notranslate nohighlight">\(x\)</span> 與 <span class="math notranslate nohighlight">\(b\)</span> 則表示由 <span class="math notranslate nohighlight">\(x_n\)</span> 與 <span class="math notranslate nohighlight">\(b_n\)</span> 形成的 <span class="math notranslate nohighlight">\(N\)</span> 維向量。前述方程組可以用矩陣向量乘法的形式來表徵</p>
<div class="math notranslate nohighlight">
\[
Ax=b.
\]</div>
<p>因此，若可以獲得 <span class="math notranslate nohighlight">\(A^{-1}\)</span>，則根據 <span class="math notranslate nohighlight">\(A^{-1}Ax=A^{-1}b\)</span>，方程組的解即為 <span class="math notranslate nohighlight">\(x=A^{-1}b\)</span>。</p>
<p>反矩陣的計算主要仰賴電腦程式，採用<a class="reference external" href="https://en.wikipedia.org/wiki/Gaussian_elimination"><strong>高斯消去法</strong></a>（Gaussian elimination）或是<a class="reference external" href="https://en.wikipedia.org/wiki/QR_decomposition"><strong>QR分解</strong></a>（QR decomposition），這兩種方法的計算複雜度皆為 <span class="math notranslate nohighlight">\(O(N^3)\)</span>，意即，其牽涉到大約 <span class="math notranslate nohighlight">\(K \times N^3\)</span> 這麼多步驟的計算，這裡，<span class="math notranslate nohighlight">\(K\)</span> 表示一跟 <span class="math notranslate nohighlight">\(N\)</span> 無關的常數，因此，當 <span class="math notranslate nohighlight">\(N\)</span> 很大時，此反矩陣的計算可能會很耗時。</p>
<p>而讀者需要特別注意的是，究竟 <span class="math notranslate nohighlight">\(A\)</span> 是否真的存在反矩陣，<span class="math notranslate nohighlight">\(A\)</span> 存在反矩陣的條件為，其 <span class="math notranslate nohighlight">\(N\)</span> 個直行（或橫列）所形成的向量，並不存在線性相依（linear dependent）的狀況。令 <span class="math notranslate nohighlight">\(a_1, a_2, ..., a_N\)</span> 表示 <span class="math notranslate nohighlight">\(A\)</span> 的 <span class="math notranslate nohighlight">\(N\)</span> 個直行所對應之向量，若其中存在某 <span class="math notranslate nohighlight">\(a_i\)</span>，其可以寫為 <span class="math notranslate nohighlight">\(a_i = \sum_{n \neq i} w_n a_n\)</span> 的話，則表示有線性相依的狀況。這裡，<span class="math notranslate nohighlight">\(w_n\)</span> 為純量，用於表示一權重係數。事實上，線性相依的問題意味著在該聯立方程組的系統中，存在了多餘訊息，各位聰明的讀者，應該都知道此時存在無窮多組解，故不存在 <span class="math notranslate nohighlight">\(A^{-1}\)</span>。</p>
</div>
<div class="section" id="id10">
<h3><span class="section-number">1.2.4. </span>分解<a class="headerlink" href="#id10" title="Permalink to this headline">¶</a></h3>
<p>在矩陣的世界中，存在許多將矩陣拆成幾個比較簡單矩陣乘積的<strong>分解</strong>（decomposition），我們在這邊做個簡單的介紹（這邊只考慮實數矩陣，不考慮虛數）。</p>
<p>a. <span class="math notranslate nohighlight">\(LU\)</span> 分解</p>
<p>當 <span class="math notranslate nohighlight">\(A\)</span> 為 <span class="math notranslate nohighlight">\(N \times N\)</span> 可逆方陣時，則其存在 <strong><span class="math notranslate nohighlight">\(LU\)</span> 分解</strong>：</p>
<div class="math notranslate nohighlight">
\[
A = LU.
\]</div>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(L\)</span>表示一 <span class="math notranslate nohighlight">\(N \times N\)</span> 下三角矩陣。</p></li>
<li><p><span class="math notranslate nohighlight">\(U\)</span>表示一 <span class="math notranslate nohighlight">\(N \times N\)</span> 上三角矩陣。</p></li>
</ul>
<p>b. <span class="math notranslate nohighlight">\(QR\)</span> 分解</p>
<p>當 <span class="math notranslate nohighlight">\(A\)</span> 為 <span class="math notranslate nohighlight">\(N \times N\)</span> 可逆方陣時，則其存在 <strong><span class="math notranslate nohighlight">\(QR\)</span> 分解</strong>：</p>
<div class="math notranslate nohighlight">
\[
A = QR.
\]</div>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(Q\)</span> 表示一 <span class="math notranslate nohighlight">\(N \times N\)</span> 的<strong>垂直矩陣</strong>（orthogonal matrix）（垂直矩陣滿足 <span class="math notranslate nohighlight">\(Q Q^T = Q^T Q = I\)</span>）。</p></li>
<li><p><span class="math notranslate nohighlight">\(R\)</span>則表示一 <span class="math notranslate nohighlight">\(N \times N\)</span> 上三角矩陣。</p></li>
</ul>
<p>c. Cholesky 分解</p>
<p>當 <span class="math notranslate nohighlight">\(A\)</span> 為 <span class="math notranslate nohighlight">\(N \times N\)</span> 正定對稱矩陣（positive definite symmetric matrix）時（在此，我們先不對「正定」一詞多做解釋，其在矩陣中扮演類似正數的概念），則其存在 <strong>Cholesky 分解</strong>：</p>
<div class="math notranslate nohighlight">
\[
A = LL^T.
\]</div>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(L\)</span>表示一 <span class="math notranslate nohighlight">\(N \times N\)</span> 下三角矩陣，<span class="math notranslate nohighlight">\(L^T\)</span> 表示 <span class="math notranslate nohighlight">\(L\)</span> 的轉置</p></li>
</ul>
<p>d. 特徵值分解</p>
<p>當 <span class="math notranslate nohighlight">\(A\)</span> 為 <span class="math notranslate nohighlight">\(N \times N\)</span> 對稱矩陣時，其存在以下之<strong>特徵值分解</strong>（eigendecomposition）</p>
<div class="math notranslate nohighlight">
\[
A = Q \Lambda Q ^T.
\]</div>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\Lambda\)</span> 表示一 <span class="math notranslate nohighlight">\(N \times N\)</span> 對角矩陣，其對角線元素為 <span class="math notranslate nohighlight">\(A\)</span> 的特徵值。</p></li>
<li><p><span class="math notranslate nohighlight">\(Q\)</span> 表示一 <span class="math notranslate nohighlight">\(N \times N\)</span> 的垂直矩陣，其第 <span class="math notranslate nohighlight">\(n\)</span> 個直行表示 <span class="math notranslate nohighlight">\(\Lambda\)</span> 第 <span class="math notranslate nohighlight">\(n\)</span> 個元素所對應之特徵向量。</p></li>
</ul>
<p>e. 奇異值分解</p>
<p>對於任何的 <span class="math notranslate nohighlight">\(M \times N\)</span>矩陣 <span class="math notranslate nohighlight">\(A\)</span>，其存在<strong>奇異值分解</strong>（singular value decomposition）：</p>
<div class="math notranslate nohighlight">
\[
A = U \Sigma V^T.
\]</div>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\Sigma\)</span> 表示一 <span class="math notranslate nohighlight">\(M \times N\)</span> 的長方對角矩陣（rectangular diagonal matrix），其對角線元素為 <span class="math notranslate nohighlight">\(A\)</span> 的<strong>奇異值</strong>（singular value）</p></li>
<li><p><span class="math notranslate nohighlight">\(U\)</span> 表示一 <span class="math notranslate nohighlight">\(M \times M\)</span> 的垂直矩陣。</p></li>
<li><p><span class="math notranslate nohighlight">\(V\)</span> 表示一 <span class="math notranslate nohighlight">\(N \times N\)</span> 的垂直矩陣。</p></li>
</ul>
</div>
</div>
<div class="section" id="id11">
<h2><span class="section-number">1.3. </span>微分<a class="headerlink" href="#id11" title="Permalink to this headline">¶</a></h2>
<p><strong>微分</strong>（differentiation）乃微積分（calculus）此科目中，用於瞭解函數局部訊息的重要技術。在統計領域，此技術常用於逼近目標函數，以及求得參數解有關。</p>
<p>若讀者對於微分的概念很不熟悉的話，可以參考台灣大學開放式課程的<a class="reference external" href="http://ocw.aca.ntu.edu.tw/ntu-ocw/ocw/cou/103S121">影片</a>，特別是單元5跟6，以及28和29的內容。</p>
<div class="section" id="id12">
<h3><span class="section-number">1.3.1. </span>何謂微分？<a class="headerlink" href="#id12" title="Permalink to this headline">¶</a></h3>
<p>給定一函數 <span class="math notranslate nohighlight">\(f(x)\)</span>，其將一實數變量 <span class="math notranslate nohighlight">\(x\)</span>，從其<strong>定義域</strong>（domain）透過轉換（transformation）送至其<strong>值域</strong>（range）。若 <span class="math notranslate nohighlight">\(f(x)\)</span> 在 <span class="math notranslate nohighlight">\(x=x^*\)</span> 此位置為<strong>可微分</strong>（differentiable）的話，我們使用 <span class="math notranslate nohighlight">\(f'(x^*)\)</span> 來表示此微分值，其計算方式為</p>
<div class="math notranslate nohighlight">
\[
f'(x^*) = \lim_{\Delta x \to 0} \frac{f(x^* + \Delta x) - f(x^*)}{\Delta x}.
\]</div>
<p>由於 <span class="math notranslate nohighlight">\(\frac{f(x^* + \Delta x) - f(x^*)}{\Delta x}\)</span> 可視為對函數 <span class="math notranslate nohighlight">\(f\)</span> 於 <span class="math notranslate nohighlight">\(x^*\)</span> 位置斜率之逼近，透過使用極限（limit）的運算將 <span class="math notranslate nohighlight">\(\Delta x\)</span> 趨近於0，事實上，<span class="math notranslate nohighlight">\(f'(x^*)\)</span> 表徵的就是 <span class="math notranslate nohighlight">\(f\)</span> 於 <span class="math notranslate nohighlight">\(x^*\)</span> 位置切線之斜率。</p>
<p>實務上，我們常使用以下的符號來表示對函數 <span class="math notranslate nohighlight">\(f\)</span> 的 <span class="math notranslate nohighlight">\(x\)</span> 進行微分</p>
<div class="math notranslate nohighlight">
\[
f'(x) = \frac{\text{d} f(x)}{\text{d} x}.
\]</div>
<p>注意，在這邊 <span class="math notranslate nohighlight">\(f'(x)\)</span> 與 <span class="math notranslate nohighlight">\(f'(x^*)\)</span> 表徵的事情略有不同。<span class="math notranslate nohighlight">\(f'(x)\)</span> 表徵的是函數 <span class="math notranslate nohighlight">\(f\)</span> 的<strong>一階導數</strong>（first-order derivative），其為一函數，帶入不同的 <span class="math notranslate nohighlight">\(x\)</span> 則 <span class="math notranslate nohighlight">\(f'(x)\)</span> 會輸出不同的數值來，而 <span class="math notranslate nohighlight">\(f'(x^*)\)</span> 強調的是，該一階導數於 <span class="math notranslate nohighlight">\(x = x^*\)</span> 之數值。一般來說，比較精確的寫法是</p>
<div class="math notranslate nohighlight">
\[
f'(x^*) = \frac{\text{d} f(x)}{\text{d} x} \bigg|_{x = x^*}.
\]</div>
<p>下表呈現了一些常見函數的一階導數</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>函數名稱</p></th>
<th class="head"><p>函數形式</p></th>
<th class="head"><p>一階導數</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>常數函數</p></td>
<td><p><span class="math notranslate nohighlight">\(f(x)=c\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(f'(x)=0\)</span></p></td>
</tr>
<tr class="row-odd"><td><p>單位函數</p></td>
<td><p><span class="math notranslate nohighlight">\(f(x)=x\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(f'(x)=1\)</span></p></td>
</tr>
<tr class="row-even"><td><p>多項式函數</p></td>
<td><p><span class="math notranslate nohighlight">\(f(x)=x^K\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(f'(x)=K x^{K-1}\)</span></p></td>
</tr>
<tr class="row-odd"><td><p>對數函數</p></td>
<td><p><span class="math notranslate nohighlight">\(f(x)=\log(x)\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(f'(x)=\frac{1}{x}\)</span></p></td>
</tr>
<tr class="row-even"><td><p>指數函數</p></td>
<td><p><span class="math notranslate nohighlight">\(f(x)=\exp(x)\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(f'(x)=\exp(x)\)</span></p></td>
</tr>
</tbody>
</table>
<p>在獲得了 <span class="math notranslate nohighlight">\(f(x)\)</span> 的一階導數 <span class="math notranslate nohighlight">\(f'(x)\)</span> 後，我們也可以將 <span class="math notranslate nohighlight">\(f'(x)\)</span> 視為一新的函數再去計算其導數，此時，我們等同於計算 <span class="math notranslate nohighlight">\(f(x)\)</span> 的二階導數</p>
<div class="math notranslate nohighlight">
\[
f''(x) = \frac{\text{d}^2 f(x)}{\text{d} x^2} = \frac{\text{d} f'(x)}{\text{d} x}.
\]</div>
</div>
<div class="section" id="id13">
<h3><span class="section-number">1.3.2. </span>微分的規則<a class="headerlink" href="#id13" title="Permalink to this headline">¶</a></h3>
<p>前一小節的表格，呈現的都是一些較為簡單形式的函數，面對實務的問題，研究者常須處理較為複雜的函數，這時，我們會需要一些微分的規則。令 <span class="math notranslate nohighlight">\(f(x)\)</span> 與 <span class="math notranslate nohighlight">\(g(x)\)</span> 表示兩定義於 <span class="math notranslate nohighlight">\(x\)</span> 此變數之函數，假設 <span class="math notranslate nohighlight">\(f(x)\)</span> 與 <span class="math notranslate nohighlight">\(g(x)\)</span> 皆為可微分之函數，則我們有以下的規則</p>
<ul class="simple">
<li><p><strong>線性規則</strong>：<span class="math notranslate nohighlight">\(\frac{\text{d} }{\text{d}x} ( a f(x) + b g(x)) = a f'(x) + b g'(x)\)</span>。</p></li>
<li><p><strong>乘法規則</strong>：<span class="math notranslate nohighlight">\(\frac{\text{d} }{\text{d}x} (f(x) g(x)) = f'(x) g(x) + f(x) g'(x)\)</span>。</p></li>
<li><p><strong>除法規則</strong>：<span class="math notranslate nohighlight">\(\frac{\text{d} }{\text{d}x} (f(x)/g(x)) = \frac{f'(x) g(x) - f(x) g'(x)}{[g(x)]^2}\)</span>（<span class="math notranslate nohighlight">\(g(x)\)</span> 不可為0）。</p></li>
</ul>
<p>除此之外，<strong>連鎖規則</strong>（chain rule）亦為一相當重要的手法。令 <span class="math notranslate nohighlight">\(u(x)\)</span> 表示一定義於 <span class="math notranslate nohighlight">\(x\)</span> 變數的函數，其輸出為 <span class="math notranslate nohighlight">\(u\)</span>，而 <span class="math notranslate nohighlight">\(f(u)\)</span> 表示一定義於變數 <span class="math notranslate nohighlight">\(u\)</span> 之函數，其輸出為 <span class="math notranslate nohighlight">\(y\)</span>。考慮一組成函數（composition function）<span class="math notranslate nohighlight">\(h\)</span>，其建構方式為<span class="math notranslate nohighlight">\(h =f \circ u\)</span>，意思是，<span class="math notranslate nohighlight">\(h(x) = f(u(x))\)</span>。根據連鎖規則，<span class="math notranslate nohighlight">\(h\)</span> 的一階導數可透過以下的公式計算</p>
<div class="math notranslate nohighlight">
\[
h'(x) =  u'(x) f'(u)  = \frac{\text{d} u(x)}{\text{d}x} \frac{\text{d} f(u)}{\text{d}u}.
\]</div>
</div>
<div class="section" id="id14">
<h3><span class="section-number">1.3.3. </span>多變數函數的微分<a class="headerlink" href="#id14" title="Permalink to this headline">¶</a></h3>
<p>在統計的問題中，研究者常須處理多變數的實函數，意即，一函數<span class="math notranslate nohighlight">\(f\)</span> 其定義於 <span class="math notranslate nohighlight">\(x_1,x_2,...,x_N\)</span>，並透過一轉換將此 <span class="math notranslate nohighlight">\(N\)</span> 個變數送到一實數空間。在面對此類函數時，我們需要利用<strong>偏微分</strong>（partial differentiation）的技術，計算 <span class="math notranslate nohighlight">\(f(x)=f(x_1,x_2,...,x_N)\)</span> 於各 <span class="math notranslate nohighlight">\(x_n\)</span> 方向上的<strong>偏導數</strong>（partial derivative），其定義為</p>
<div class="math notranslate nohighlight">
\[
\frac{\partial  f(x)}{\partial x_n}  = \lim_{\Delta x_n \to 0} \frac{f(x_1,...,x_n + \Delta x_n,...,x_N) - f(x_1,...,x_n,...,x_N)}{\Delta x_n}.
\]</div>
<p>在實作上，計算 <span class="math notranslate nohighlight">\(\frac{\partial f(x)}{\partial x_n}\)</span>時，僅須將 <span class="math notranslate nohighlight">\(f(x)\)</span> 視為 <span class="math notranslate nohighlight">\(x_n\)</span> 的函數，其它的變數視為常數即可。</p>
<p>在獲得 <span class="math notranslate nohighlight">\(f(x)\)</span> 對於每個 <span class="math notranslate nohighlight">\(x_n\)</span> 的偏導數後，我們可以將這些導數收集起來排成一 <span class="math notranslate nohighlight">\(N\)</span> 維之向量，即</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\nabla f(x) =
\underbrace{\begin{pmatrix}
\frac{\partial  f(x)}{\partial x_1} \\
\frac{\partial  f(x)}{\partial x_2} \\
\vdots \\
\frac{\partial  f(x)}{\partial x_N} \\
\end{pmatrix}}_{N \times 1}.
\end{split}\]</div>
<p>我們將 <span class="math notranslate nohighlight">\(\nabla f(x)\)</span> 稱作<strong>梯度</strong>（gradient），其在了解多變數函數時，提供了相當重要的訊息：</p>
<ol class="simple">
<li><p>梯度的第 <span class="math notranslate nohighlight">\(n\)</span> 個成分，表徵了該函數於 <span class="math notranslate nohighlight">\(x_n\)</span> 方向上切線的斜率訊息。</p></li>
<li><p>給定一具體的方向 <span class="math notranslate nohighlight">\(d\)</span>，則該函數於方向 <span class="math notranslate nohighlight">\(d\)</span> 的方向導數（directional derivative）可以寫為 <span class="math notranslate nohighlight">\(\langle \nabla f(x),d/||d|| \rangle\)</span>。</p></li>
</ol>
<p>除了前述梯度的運算符號 <span class="math notranslate nohighlight">\(\nabla\)</span> 外，有時，多變項函數之微分會使用以下之符號表示</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\frac{\partial f(x)}{\partial x} =
\underbrace{\begin{pmatrix}
\frac{\partial  f(x)}{\partial x_1} \\
\frac{\partial  f(x)}{\partial x_2} \\
\vdots \\
\frac{\partial  f(x)}{\partial x_N} \\
\end{pmatrix}}_{N \times 1},
\end{split}\]</div>
<p>或是</p>
<div class="math notranslate nohighlight">
\[
\frac{\partial f(x)}{\partial x^T} =
\underbrace{\begin{pmatrix}
\frac{\partial  f(x)}{\partial x_1} &amp;
\frac{\partial  f(x)}{\partial x_2} &amp; \cdots &amp;
\frac{\partial  f(x)}{\partial x_N}
\end{pmatrix}}_{1 \times N}.
\]</div>
<p>這裡，<span class="math notranslate nohighlight">\(\frac{\partial f(x)}{\partial x}\)</span> 與 <span class="math notranslate nohighlight">\(\frac{\partial f(x)}{\partial x^T}\)</span> 的差別在於，前者對於 <span class="math notranslate nohighlight">\(x\)</span> 此直行向量微分，而後者則對於 <span class="math notranslate nohighlight">\(x^T\)</span> 此橫列向量微分。一般來說，梯度的運算符號 <span class="math notranslate nohighlight">\(\nabla\)</span> 僅適用於純量之函數，而 <span class="math notranslate nohighlight">\(\frac{\partial f(x)}{\partial x}\)</span> 與 <span class="math notranslate nohighlight">\(\frac{\partial f(x)}{\partial x^T}\)</span> 此符號較廣之應用範疇，有興趣之讀者可以參考 <a class="reference external" href="http://www2.imm.dtu.dk/pubdb/pubs/3274-full.html">The Matrix Cookbook</a> 之第二章。</p>
<p>多變數函數的微分，若透過矩陣微積（matrix calculus）分中的<a class="reference external" href="https://en.wikipedia.org/wiki/Matrix_calculus#Scalar-by-vector_identities">純量對向量微分之規則</a>，可以相當省力的獲得。令 <span class="math notranslate nohighlight">\(x\)</span> 表示一 <span class="math notranslate nohighlight">\(N\)</span> 維之向量，<span class="math notranslate nohighlight">\(A\)</span> 與 <span class="math notranslate nohighlight">\(b\)</span> 分別表示 <span class="math notranslate nohighlight">\(N \times N\)</span> 之矩陣與 <span class="math notranslate nohighlight">\(N\)</span> 維之向量，<span class="math notranslate nohighlight">\(c\)</span> 表示一純量，<span class="math notranslate nohighlight">\(A\)</span>、<span class="math notranslate nohighlight">\(b\)</span>、以及 <span class="math notranslate nohighlight">\(c\)</span> 皆與 <span class="math notranslate nohighlight">\(x\)</span> 無關。在這邊，我們將簡單列出幾個基本的規則：</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>函數名稱</p></th>
<th class="head"><p>函數形式</p></th>
<th class="head"><p>梯度</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>常數函數</p></td>
<td><p><span class="math notranslate nohighlight">\(f(x)=c\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\nabla f(x)=\underbrace{0}_{N \times 1}\)</span></p></td>
</tr>
<tr class="row-odd"><td><p>線性函數</p></td>
<td><p><span class="math notranslate nohighlight">\(f(x)=b^Tx\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\nabla  f(x)=\underbrace{b}_{N \times 1}\)</span></p></td>
</tr>
<tr class="row-even"><td><p>二項式函數（<span class="math notranslate nohighlight">\(A\)</span>非對稱）</p></td>
<td><p><span class="math notranslate nohighlight">\(f(x)=x^TAx\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\nabla f(x)=\underbrace{(A + A^T)}_{N \times N} x\)</span></p></td>
</tr>
<tr class="row-odd"><td><p>二項式函數（<span class="math notranslate nohighlight">\(A\)</span>對稱）</p></td>
<td><p><span class="math notranslate nohighlight">\(f(x)=x^TAx\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\nabla f(x)=\underbrace{2A}_{N \times N} x\)</span></p></td>
</tr>
</tbody>
</table>
<p>另外，當 <span class="math notranslate nohighlight">\(f(x)\)</span> 與 <span class="math notranslate nohighlight">\(g(x)\)</span> 皆為 <span class="math notranslate nohighlight">\(x\)</span> 的純量函數時，我們一樣有線性規則、乘法規則、以及除法規則：</p>
<ul class="simple">
<li><p><strong>線性規則</strong>：<span class="math notranslate nohighlight">\(\nabla ( a f(x) + b g(x)) = a \nabla f(x) + b \nabla g(x)\)</span>。</p></li>
<li><p><strong>乘法規則</strong>：<span class="math notranslate nohighlight">\(\nabla (f(x) g(x)) = g(x) \nabla f(x)  + f(x) \nabla g(x)\)</span>。</p></li>
<li><p><strong>除法規則</strong>：<span class="math notranslate nohighlight">\(\nabla  (f(x)/g(x)) = \frac{ g(x) \nabla f(x) - f(x) \nabla g(x)}{[g(x)]^2}\)</span>（<span class="math notranslate nohighlight">\(g(x)\)</span> 不可為0）。</p></li>
</ul>
<p>最後，令 <span class="math notranslate nohighlight">\(u(x) = (u_1(x), u_2(x), ..., u_M(x))\)</span> 表示一向量函數，其將 <span class="math notranslate nohighlight">\(N\)</span> 維之 <span class="math notranslate nohighlight">\(x\)</span> 轉換為 <span class="math notranslate nohighlight">\(M\)</span> 維之 <span class="math notranslate nohighlight">\(u\)</span>，此時， <span class="math notranslate nohighlight">\(h(x) = f(u(x))\)</span> 此一組合函數之梯度為</p>
<div class="math notranslate nohighlight">
\[
\underbrace{\nabla_x h(x)}_{N \times 1} =
\underbrace{J_{ux} ^T }_{N \times M}
\underbrace{\nabla_{u} f(u)}_{M \times 1}
\]</div>
<p>這裡，<span class="math notranslate nohighlight">\(J_{ux}\)</span> 表示對於 <span class="math notranslate nohighlight">\(u(x)\)</span> 此轉換之 <span class="math notranslate nohighlight">\(M \times N\)</span> 雅可比矩陣（Jacobian matrix），其定義為</p>
<div class="math notranslate nohighlight">
\[\begin{split}
J_{ux} = \frac{\partial u(x)}{ \partial x^T} =
\underbrace{\begin{pmatrix}
\frac{\partial  u_1(x)}{\partial x_1} &amp; \frac{\partial  u_1(x)}{\partial x_2} &amp; \cdots &amp; \frac{\partial  u_1(x)}{\partial x_N} \\
\frac{\partial  u_2(x)}{\partial x_1} &amp; \frac{\partial  u_2(x)}{\partial x_2} &amp; \cdots &amp; \frac{\partial  u_2(x)}{\partial x_N} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots  \\
\frac{\partial  u_M(x)}{\partial x_1} &amp; \frac{\partial  u_M(x)}{\partial x_2} &amp; \cdots &amp; \frac{\partial  u_M(x)}{\partial x_N} \\
\end{pmatrix}}_{M \times N}.
\end{split}\]</div>
<p>前式之結果，可視為<strong>連鎖規則</strong>應用於矩陣微積分之拓展。</p>
<p>除了前述之一階導數外，二階導數在統計建模的理論中亦扮演重要的角色。令 <span class="math notranslate nohighlight">\(f(x)=f(x_1,x_2,...,x_N)\)</span> 表示一定義於 <span class="math notranslate nohighlight">\(N\)</span> 維向量 <span class="math notranslate nohighlight">\(x\)</span> 之純量函數，則 <span class="math notranslate nohighlight">\(f\)</span> 對於 <span class="math notranslate nohighlight">\(x\)</span> 之 <span class="math notranslate nohighlight">\(N \times N\)</span> 二階導數矩陣，或稱黑塞矩陣為：</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\nabla^2 f(x) = \frac{\partial^2 f(x)}{\partial x \partial x^T} =
\underbrace{\begin{pmatrix}
\frac{\partial^2 f(x)}{\partial x_1 \partial x_1} &amp; \frac{\partial^2 f(x)}{\partial x_1 \partial x_2} &amp; \cdots &amp; \frac{\partial^2 f(x)}{\partial x_1 \partial x_N} \\
\frac{\partial^2 f(x)}{\partial x_2 \partial x_1} &amp; \frac{\partial^2 f(x)}{\partial x_2 \partial x_2} &amp; \cdots &amp; \frac{\partial^2 f(x)}{\partial x_2 \partial x_N} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
\frac{\partial^2 f(x)}{\partial x_N \partial x_1} &amp; \frac{\partial^2 f(x)}{\partial x_N \partial x_2} &amp; \cdots &amp; \frac{\partial^2 f(x)}{\partial x_N \partial x_N}
\end{pmatrix}}_{N \times N}
\end{split}\]</div>
</div>
<div class="section" id="id15">
<h3><span class="section-number">1.3.4. </span>泰勒之定理<a class="headerlink" href="#id15" title="Permalink to this headline">¶</a></h3>
<p>對於一連續可微之函數，我們可透過泰勒之定理（Taylor’s theorem），於其局部進行逼近。令 <span class="math notranslate nohighlight">\(f(x)=f(x_1,x_2,...,x_N)\)</span> 表示一定義於 <span class="math notranslate nohighlight">\(N\)</span> 維向量 <span class="math notranslate nohighlight">\(x\)</span> 之純量函數，則在 <span class="math notranslate nohighlight">\(x = x^*\)</span> 的附近，我們可以考慮以下之線性逼近：</p>
<div class="math notranslate nohighlight">
\[
f(x) \approx f(x^*) + \underbrace{(x - x^*)^T}_{1 \times N} \underbrace{\nabla f(x^*)}_{N \times 1}
\]</div>
<p>或是二次式之逼近</p>
<div class="math notranslate nohighlight">
\[
f(x) \approx f(x^*) + (x - x^*)^T \nabla f(x^*) + \frac{1}{2} \underbrace{(x - x^*)^T}_{1 \times N} \underbrace{\nabla^2 f(x^*)}_{N \times N} \underbrace{(x - x^*)}_{N \times 1}
\]</div>
<p>此逼近的意涵在於，如果我們僅聚焦於一連續可微函數局部的表面（local surface），則其表現會與線性函數、或是二次函數相當靠近。</p>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./notebook"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="../intro.html" title="previous page">關於「統計建模技法」</a>
    <a class='right-next' id="next-link" href="linear-regression.html" title="next page"><span class="section-number">2. </span>線性迴歸</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Po-Hsien Huang<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    <script src="../_static/js/index.js"></script>
    
  </body>
</html>