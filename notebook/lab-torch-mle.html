

<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>8. Lab: 最大概似估計 &#8212; 統計建模技法</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.min.css" integrity="sha384-KA6wR/X5RY4zFAHpv/CnoG2UW1uogYfdnP67Uv7eULvTveboZJg0qUpmJZb5VqzN" crossorigin="anonymous">
    <link href="../_static/css/index.css" rel="stylesheet">
    <link rel="stylesheet" href="../_static/sphinx-book-theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyter-sphinx.css" />
    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/sphinx-book-theme.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/mystnb.js"></script>
    <script src="../_static/sphinx-book-theme.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.18.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="9. 真實分數模型" href="true-score-model.html" />
    <link rel="prev" title="7. 最大概似法" href="maximum-likelihood.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="docsearch:language" content="en">



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  
  <h1 class="site-logo" id="site-title">統計建模技法</h1>
  
</a>
</div>

<form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>

<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <ul class="current nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="math-prerequisite.html">
   1. 先備數學知識
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="linear-regression.html">
   2. 線性迴歸
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lab-torch-tensor.html">
   3. Lab: 張量與線性代數
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="logistic-regression.html">
   4. 邏輯斯迴歸
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lab-torch-diff-opt.html">
   5. Lab: 數值微分與優化
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="probability-distribution.html">
   6. 機率分佈
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="maximum-likelihood.html">
   7. 最大概似法
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   8. Lab: 最大概似估計
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="true-score-model.html">
   9. 真實分數模型
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="factor-analysis.html">
   10. 因素分析
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="item-response-theory.html">
   11. 試題反應理論
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="mixture-modeling.html">
   12. 混合建模
  </a>
 </li>
</ul>

</nav>

 <!-- To handle the deprecated key -->

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        <div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    
    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/notebook/lab-torch-mle.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
    
</div>
        <!-- Source interaction buttons -->


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/psyphh/tism/blob/master/tism/notebook/lab-torch-mle.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="Launch Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="../_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        
    </div>
</div>

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#torch">
   8.1.
   <code class="docutils literal notranslate">
    <span class="pre">
     torch
    </span>
   </code>
   分配物件
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     8.1.1. 分配物件之基礎
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id2">
     8.1.2. 分配物件之形狀
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id3">
   8.2. 最大概似估計法
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id4">
     8.2.1. 建立概似函數
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id5">
     8.2.2. 進行優化
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id6">
     8.2.3. 多元常態分配之最大概似估計
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id7">
   8.3. 實徵範例
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id8">
     8.3.1. 產生邏吉斯迴歸資料
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id9">
     8.3.2. 建立一進行邏吉斯迴歸分析之物件
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id10">
     8.3.3. 計算模型參數
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id11">
     8.3.4. 計算參數估計標準誤
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id12">
     8.3.5. 練習
    </a>
   </li>
  </ul>
 </li>
</ul>

        </nav>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="lab">
<h1><span class="section-number">8. </span>Lab: 最大概似估計<a class="headerlink" href="#lab" title="Permalink to this headline">¶</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="torch">
<h2><span class="section-number">8.1. </span><code class="docutils literal notranslate"><span class="pre">torch</span></code> 分配物件<a class="headerlink" href="#torch" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id1">
<h3><span class="section-number">8.1.1. </span>分配物件之基礎<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">torch.distribution</span></code> 內建了許多機率分配物件（見<a class="reference external" href="https://pytorch.org/docs/stable/distributions.html">官方網頁</a>），而分配物件可供使用者</p>
<ol class="simple">
<li><p>產生隨機樣本。</p></li>
<li><p>給定實現值計算可能性或機率值。</p></li>
<li><p>給定上界計算累積機率值（並非每個分配都可以）。</p></li>
</ol>
<p>在產生一分配物件時，我們需給定該分配的參數。以常態分配為例，其參數包括了平均數與變異數，此兩參數亦稱作位置（location）參數與尺度（scale）參數</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch.distributions</span> <span class="kn">import</span> <span class="n">Normal</span>
<span class="n">normal</span> <span class="o">=</span> <span class="n">Normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>再以Binomial分配為例，其參數為嘗試次數與成功之機率（也可以使用對數勝率來設定）</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch.distributions</span> <span class="kn">import</span> <span class="n">Binomial</span>
<span class="n">binomial</span> <span class="o">=</span> <span class="n">Binomial</span><span class="p">(</span><span class="n">total_count</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="n">probs</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>我們可以透過對分配物件的列印，以了解其內部之參數設定：</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">normal</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">binomial</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>Normal(loc: 0.0, scale: 1.0)
Binomial(total_count: 10.0, probs: 0.5, logits: 0.0)
</pre></div>
</div>
</div>
</div>
<p>對於已建立之分配物件，我們可以利用其<code class="docutils literal notranslate"><span class="pre">.sample()</span></code>方法來產生隨機變數</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;random sample with shape ():</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span>
      <span class="n">normal</span><span class="o">.</span><span class="n">sample</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;random sample with shape (3,):</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span>
      <span class="n">normal</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">sample_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;random sample with shape (2,3):</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span>
      <span class="n">normal</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">sample_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>random sample with shape ():
 tensor(0.2698)
random sample with shape (3,):
 tensor([-0.9109,  0.7689,  0.6283])
random sample with shape (2,3):
 tensor([[0.4545, 1.7240, 0.7896],
        [0.0286, 0.2081, 1.5501]])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;random sample with shape ():</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span>
      <span class="n">binomial</span><span class="o">.</span><span class="n">sample</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;random sample with shape (3,):</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span>
      <span class="n">binomial</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">sample_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;random sample with shape (2,3):</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span>
      <span class="n">binomial</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">sample_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>random sample with shape ():
 tensor(5.)
random sample with shape (3,):
 tensor([7., 4., 6.])
random sample with shape (2,3):
 tensor([[3., 1., 6.],
        [3., 7., 5.]])
</pre></div>
</div>
</div>
</div>
<p>從前述的例子，我們可以看到 <code class="docutils literal notranslate"><span class="pre">sample_shape</span></code> 可用於設定產生樣本之個數與樣本張量之排列形狀。</p>
<p>給定一組實現值，<code class="docutils literal notranslate"><span class="pre">log_prob()</span></code>可用於計算該實現之對數可能性或機率</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;log-likelihood given value with shape ():</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span>
      <span class="n">normal</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">])),</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;log-likelihood given value with (3,):</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span>
      <span class="n">normal</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="o">.</span><span class="mi">5</span><span class="p">])),</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;log-likelihood given value with (2,3):</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span>
      <span class="n">normal</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="o">.</span><span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">]])))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>log-likelihood given value with shape ():
 tensor([-0.9189]) 

log-likelihood given value with (3,):
 tensor([-1.4189, -0.9189, -1.0439]) 

log-likelihood given value with (2,3):
 tensor([[-1.4189, -0.9189, -1.0439],
        [-2.9189, -1.4189, -5.4189]])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;log-probability given value with shape ():</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span>
      <span class="n">binomial</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mi">5</span><span class="p">])),</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;log-probability given value with (3,):</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span>
      <span class="n">binomial</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">7</span><span class="p">])),</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;log-probability given value with (2,3):</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span>
      <span class="n">binomial</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">7</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">]])))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>log-probability given value with shape ():
 tensor([-1.4020]) 

log-probability given value with (3,):
 tensor([-1.4020, -2.1440, -2.1440]) 

log-probability given value with (2,3):
 tensor([[-1.4020, -2.1440, -2.1440],
        [-3.1248, -6.9315, -6.9315]])
</pre></div>
</div>
</div>
</div>
<p>在給定上界之數值，常態分配之<code class="docutils literal notranslate"><span class="pre">.cdf()</span></code> 可用於計算該上界數值所對應之累積機率數值</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;cumulative probability given value with shape ():</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span>
      <span class="n">normal</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">])),</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;cumulative probability given value with (3,):</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span>
      <span class="n">normal</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="o">.</span><span class="mi">5</span><span class="p">])),</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;cumulative probability given value with (2,3):</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span>
      <span class="n">normal</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="o">.</span><span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">]])))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>cumulative probability given value with shape ():
 tensor([0.5000]) 

cumulative probability given value with (3,):
 tensor([0.1587, 0.5000, 0.6915]) 

cumulative probability given value with (2,3):
 tensor([[0.1587, 0.5000, 0.6915],
        [0.0228, 0.8413, 0.9987]])
</pre></div>
</div>
</div>
</div>
<p>不過，binomial分配並無 <code class="docutils literal notranslate"><span class="pre">cdf()</span></code> 方法可評估累積機率值。</p>
</div>
<div class="section" id="id2">
<h3><span class="section-number">8.1.2. </span>分配物件之形狀<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">pytorch</span></code> 分配物件之設計，乃參考 <code class="docutils literal notranslate"><span class="pre">tensorflow_probability</span></code>此套件，而分配物件在形狀上，牽涉到三類型之形狀：</p>
<ol class="simple">
<li><p>樣本形狀（sample shape）：為用於描述獨立且具有相同分配隨機樣本之形狀，先前產生隨機樣本時，所設定的 <code class="docutils literal notranslate"><span class="pre">sample_shape</span></code> 即為樣本形狀。</p></li>
<li><p>批次形狀（batch shape）：為用於描述獨立，但不具有相同分配隨機樣本之形狀，其可以透過模型參數之形狀進行設定。</p></li>
<li><p>事件形狀（event shape）：為用於描述多變量分配之形狀，各變數間可能不具有統計獨立之特性。</p></li>
</ol>
<p>先前產生的常態分配，其在 <code class="docutils literal notranslate"><span class="pre">batch_shape</span></code> 與 <code class="docutils literal notranslate"><span class="pre">event_shape</span></code> 上，皆為純量，故其數值為0-d之張量。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch.distributions</span> <span class="kn">import</span> <span class="n">Normal</span>
<span class="n">normal</span> <span class="o">=</span> <span class="n">Normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">normal</span><span class="o">.</span><span class="n">batch_shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">normal</span><span class="o">.</span><span class="n">event_shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>torch.Size([])
torch.Size([])
</pre></div>
</div>
</div>
</div>
<p>接下來，我們設定一批次形狀為 <code class="docutils literal notranslate"><span class="pre">[2]</span></code> 之常態分配物件：</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">normal_batch</span> <span class="o">=</span> <span class="n">Normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">]),</span>
                      <span class="n">scale</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">normal_batch</span><span class="o">.</span><span class="n">batch_shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">normal_batch</span><span class="o">.</span><span class="n">event_shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>torch.Size([2])
torch.Size([])
</pre></div>
</div>
</div>
</div>
<p>該分配可產生一形狀為 <code class="docutils literal notranslate"><span class="pre">[2]</span></code> 之常態隨機變數，第一個元素的平均數為0，變異數為1，第二個元素的平均數為1，變異數為1.5。接著，我們從該分配中產生不同樣本形狀之隨機樣本</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;random sample with sample_shape ():</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span>
      <span class="n">normal_batch</span><span class="o">.</span><span class="n">sample</span><span class="p">(),</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;random sample with sample_shape (3,):</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span>
      <span class="n">normal_batch</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">sample_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,)),</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;random sample with sample_shape (2,3):</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span>
      <span class="n">normal_batch</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">sample_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>random sample with sample_shape ():
 tensor([-1.6585,  0.1276]) 

random sample with sample_shape (3,):
 tensor([[-0.1022,  0.8982],
        [ 1.0493, -0.4047],
        [-1.4000,  0.3433]]) 

random sample with sample_shape (2,3):
 tensor([[[ 0.2083,  2.3997],
         [ 0.7514,  3.9110],
         [ 0.7250, -1.1003]],

        [[-0.1627,  1.5103],
         [ 1.0629,  0.2144],
         [ 1.0211,  0.1678]]])
</pre></div>
</div>
</div>
</div>
<p>我們可以看見，產生樣本的張量尺寸為 <code class="docutils literal notranslate"><span class="pre">sample_size</span> <span class="pre">+</span> <span class="pre">batch_size</span></code>，尺寸的最後一個維度皆為2。</p>
<p>當分配物件的 <code class="docutils literal notranslate"><span class="pre">batch_shape</span></code> 為 <code class="docutils literal notranslate"><span class="pre">[2]</span></code> 時，則在評估其對數機率時若僅輸入 <code class="docutils literal notranslate"><span class="pre">[0]</span></code>，則 <code class="docutils literal notranslate"><span class="pre">[0]</span></code> 會被廣播為 <code class="docutils literal notranslate"><span class="pre">[0,</span> <span class="pre">0]</span></code> 評估，而 <code class="docutils literal notranslate"><span class="pre">[[0],</span> <span class="pre">[0]]</span></code> 會被廣播為 <code class="docutils literal notranslate"><span class="pre">[[0,</span> <span class="pre">0],</span> <span class="pre">[0,</span> <span class="pre">0]]</span></code>。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;log-probability given value with shape ():</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span>
      <span class="n">normal_batch</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">])),</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;log-probability given value with shape (2,):</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span>
      <span class="n">normal_batch</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">])),</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;log-probability given value with shape (2,1):</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span>
      <span class="n">normal_batch</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">]])))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>log-probability given value with shape ():
 tensor([-0.9189, -1.5466]) 

log-probability given value with shape (2,):
 tensor([-0.9189, -1.5466]) 

log-probability given value with shape (2,1):
 tensor([[-0.9189, -1.5466],
        [-0.9189, -1.5466]])
</pre></div>
</div>
</div>
</div>
<p>分配物件的 <code class="docutils literal notranslate"><span class="pre">event_shape</span></code>，可透過多變量分配之參數設定。以多元常態分配為例，我們可以透過其平均數向量與共變異數矩陣設定 <code class="docutils literal notranslate"><span class="pre">event_shape</span></code></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch.distributions</span> <span class="kn">import</span> <span class="n">MultivariateNormal</span>
<span class="n">mvn</span> <span class="o">=</span> <span class="n">MultivariateNormal</span><span class="p">(</span>
    <span class="n">loc</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]),</span>
    <span class="n">scale_tril</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">cholesky</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="o">.</span><span class="mi">5</span><span class="p">]])))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">mvn</span><span class="o">.</span><span class="n">batch_shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">mvn</span><span class="o">.</span><span class="n">event_shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>torch.Size([])
torch.Size([2])
</pre></div>
</div>
</div>
</div>
<p>由於我們給定的平均數向量與共變異數矩陣適用於二維之多變量常態分配，因此，其 <code class="docutils literal notranslate"><span class="pre">event_shape</span></code> 為 <code class="docutils literal notranslate"><span class="pre">[2]</span></code>。這邊需特別注意的是，我們並非直接給定共變異數矩陣，取而代之的是，給定共變異數矩陣之 <code class="docutils literal notranslate"><span class="pre">cholesky</span></code> 拆解。</p>
<p>我們可以使用該多元常態分配來產生資料，以及評估其對數可能性數值</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;random sample with sample_shape ():</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span>
      <span class="n">mvn</span><span class="o">.</span><span class="n">sample</span><span class="p">(),</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;random sample with sample_shape (3,):</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span>
      <span class="n">mvn</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">sample_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,)),</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;random sample with sample_shape (2, 3):</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span>
      <span class="n">mvn</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">sample_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>random sample with sample_shape ():
 tensor([-0.4405,  1.3290]) 

random sample with sample_shape (3,):
 tensor([[ 1.9526,  1.6270],
        [-0.4641,  0.2635],
        [ 0.6489,  0.7619]]) 

random sample with sample_shape (2, 3):
 tensor([[[-0.3039,  0.7175],
         [-0.8998,  1.9356],
         [-0.7757, -0.2475]],

        [[ 0.8150,  1.1569],
         [ 0.3945,  0.3401],
         [ 0.6808,  0.7733]]])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;log-likelihood given value with shape (2,):</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span>
      <span class="n">mvn</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">])),</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;log-likelihood given value with shape (2,1):</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span>
      <span class="n">mvn</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>log-likelihood given value with shape (2,):
 tensor(-2.4913) 

log-likelihood given value with shape (2,1):
 tensor([-2.4913, -2.4913])
</pre></div>
</div>
</div>
</div>
<p>這邊需要別注意的是，屬於同一事件之觀測值，僅會給予一對數機率值，方便用於建立概似函數。</p>
<p>另外，也可以透過 <code class="docutils literal notranslate"><span class="pre">Independent</span></code> 此函數，將分配之 <code class="docutils literal notranslate"><span class="pre">batch_size</span></code> 重新解釋為 <code class="docutils literal notranslate"><span class="pre">event_size</span></code>，<code class="docutils literal notranslate"><span class="pre">reinterpreted_batch_ndims</span></code> 用於設定有多少個面向要從 <code class="docutils literal notranslate"><span class="pre">batch_shape</span></code> 轉為 <code class="docutils literal notranslate"><span class="pre">event_shape</span></code>（從右至左）。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch.distributions</span> <span class="kn">import</span> <span class="n">Independent</span>
<span class="n">normal_event</span> <span class="o">=</span> <span class="n">Independent</span><span class="p">(</span><span class="n">normal_batch</span><span class="p">,</span>
                           <span class="n">reinterpreted_batch_ndims</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">normal_event</span><span class="o">.</span><span class="n">batch_shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">normal_event</span><span class="o">.</span><span class="n">event_shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>torch.Size([])
torch.Size([2])
</pre></div>
</div>
</div>
</div>
<p>最後，我們也可以對多元常態分配設定 <code class="docutils literal notranslate"><span class="pre">batch_shape</span></code></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">mvn_batch</span> <span class="o">=</span> <span class="n">MultivariateNormal</span><span class="p">(</span>
    <span class="n">loc</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]]),</span>
    <span class="n">scale_tril</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">cholesky</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="mf">1.</span><span class="p">,</span> <span class="o">.</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="o">.</span><span class="mi">2</span><span class="p">,</span> <span class="o">.</span><span class="mi">5</span><span class="p">]])))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">mvn_batch</span><span class="o">.</span><span class="n">batch_shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">mvn_batch</span><span class="o">.</span><span class="n">event_shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>torch.Size([3])
torch.Size([2])
</pre></div>
</div>
</div>
</div>
<p>此分配每次產生一形狀為 <code class="docutils literal notranslate"><span class="pre">(3,</span> <span class="pre">2)</span></code> 之樣本，若進一步設定 <code class="docutils literal notranslate"><span class="pre">sample_shape</span></code>，則其產生之樣本張量形狀為 <code class="docutils literal notranslate"><span class="pre">smaple_shape</span> <span class="pre">+</span> <span class="pre">(3,</span> <span class="pre">2)</span></code>：</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;random sample with sample_shape ():</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span>
      <span class="n">mvn_batch</span><span class="o">.</span><span class="n">sample</span><span class="p">(),</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;random sample with sample_shape (3,):</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span>
      <span class="n">mvn_batch</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">sample_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,)),</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;random sample with sample_shape (2, 3):</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span>
      <span class="n">mvn_batch</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">sample_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>random sample with sample_shape ():
 tensor([[-0.9309, -0.0281],
        [ 0.7207,  1.7279],
        [ 2.9295,  2.8063]]) 

random sample with sample_shape (3,):
 tensor([[[-0.4815,  0.8738],
         [ 0.1171,  3.1073],
         [ 1.6893,  3.6577]],

        [[ 0.7583,  1.7359],
         [ 1.1660,  2.1481],
         [ 2.5310,  3.9466]],

        [[-0.6349,  2.2925],
         [ 1.0519,  1.5140],
         [ 1.2017,  3.3871]]]) 

random sample with sample_shape (2, 3):
 tensor([[[[ 0.6596,  0.5302],
          [ 1.1814,  2.8477],
          [ 1.5238,  3.9591]],

         [[ 1.7814,  0.4908],
          [ 1.2457,  2.6468],
          [ 2.2335,  2.4601]],

         [[-0.0786,  0.4249],
          [-0.3877,  1.1323],
          [ 0.5517,  1.9054]]],


        [[[ 0.0436,  0.2575],
          [-0.0291,  1.4200],
          [ 2.1859,  3.8775]],

         [[-1.0730,  0.4288],
          [-0.4893,  1.8835],
          [ 0.7624,  2.8957]],

         [[ 1.9209,  1.1603],
          [ 1.1479,  2.1773],
          [ 2.1163,  2.7304]]]])
</pre></div>
</div>
</div>
</div>
<p>關於前述三種形狀之說明，讀者亦可參考此<a class="reference external" href="https://ericmjl.github.io/blog/2019/5/29/reasoning-about-shapes-and-probability-distributions/">網誌</a>。</p>
</div>
</div>
<div class="section" id="id3">
<h2><span class="section-number">8.2. </span>最大概似估計法<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id4">
<h3><span class="section-number">8.2.1. </span>建立概似函數<a class="headerlink" href="#id4" title="Permalink to this headline">¶</a></h3>
<p>利用 <code class="docutils literal notranslate"><span class="pre">torch</span></code> 的分配物件，我們可以很容易地來建立概似函數。</p>
<p>首先，我們先以常態分配進行說明。為了產生樣本資料，我們先設定一平均數為5，標準差為4之常態分配</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">mu_true</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">5.</span><span class="p">])</span>
<span class="n">sigma_true</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">2.</span><span class="p">])</span>
<span class="n">model_normal_true</span> <span class="o">=</span> <span class="n">Normal</span><span class="p">(</span>
    <span class="n">loc</span><span class="o">=</span><span class="n">mu_true</span><span class="p">,</span>
    <span class="n">scale</span><span class="o">=</span><span class="n">sigma_true</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;normal model:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">model_normal_true</span><span class="p">,</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>normal model:
 Normal(loc: tensor([5.]), scale: tensor([2.])) 

</pre></div>
</div>
</div>
</div>
<p>接著，我們可以利用此常態分配來產生一樣本數為1000之資料，並評估該資料在平均數為5，標準差為4此常態分配下之負對數可能性（negative log-likelihood）</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">sample_size</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">model_normal_true</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">sample_shape</span><span class="o">=</span><span class="p">(</span><span class="n">sample_size</span><span class="p">,))</span>
<span class="n">loss_value</span> <span class="o">=</span> <span class="o">-</span> <span class="n">model_normal_true</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;negative likelihood value is&quot;</span><span class="p">,</span> <span class="n">loss_value</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>negative likelihood value is tensor(2.1143)
</pre></div>
</div>
</div>
</div>
<p>因此，只要在資料的形狀上可以匹配，我們即可使用分配物件的<code class="docutils literal notranslate"><span class="pre">log_prob()</span></code> 方法，再搭配 <code class="docutils literal notranslate"><span class="pre">sum()</span></code> 或是 <code class="docutils literal notranslate"><span class="pre">mean()</span></code> 來計算對數概似函數數值。</p>
</div>
<div class="section" id="id5">
<h3><span class="section-number">8.2.2. </span>進行優化<a class="headerlink" href="#id5" title="Permalink to this headline">¶</a></h3>
<p>在建立完概似函數後，我們就可以透過 <code class="docutils literal notranslate"><span class="pre">torch</span></code> 的優化器進行優化。在這邊需要特別注意的是，由於模型的參數會在優化過程中更新，因此，其必須使用一可微分之張量來儲存，並且，在每次更新完參數數值後，皆需再次產生一新的分配物件，以計算概述函數之數值</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">epochs</span> <span class="o">=</span> <span class="mi">200</span>
<span class="n">lr</span> <span class="o">=</span> <span class="mf">1.0</span>
<span class="n">mu</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.</span><span class="p">],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">sigma</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.</span><span class="p">],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">opt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">([</span><span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">],</span> <span class="n">lr</span><span class="o">=.</span><span class="mi">5</span><span class="p">)</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
    <span class="n">model_normal</span> <span class="o">=</span> <span class="n">Normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="n">mu</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">sigma</span><span class="p">)</span>
    <span class="n">loss_value</span> <span class="o">=</span> <span class="o">-</span> <span class="n">model_normal</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="n">opt</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="n">loss_value</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span> <span class="c1"># compute the gradient</span>
    <span class="n">opt</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;ML mean by gradient descent:&quot;</span><span class="p">,</span> <span class="n">mu</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;ML std by gradient descent:&quot;</span><span class="p">,</span> <span class="n">sigma</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>ML mean by gradient descent: [4.940348]
ML std by gradient descent: [2.0010803]
</pre></div>
</div>
</div>
</div>
<p>我們可以比較前述使用梯度下降法所得到的結果，與直接帶公式計算結果間的差異，可以發現兩者間的差異主要展現在小數點後3位，是絕大多數情況下可以忽略的誤差。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;ML mean by formula:&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;ML std by formula:&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">unbiased</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>ML mean by formula: 4.940206
ML std by formula: 2.003498
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="id6">
<h3><span class="section-number">8.2.3. </span>多元常態分配之最大概似估計<a class="headerlink" href="#id6" title="Permalink to this headline">¶</a></h3>
<p>多元常態分配為統計建模中常被使用之分配，因此，我們在此對該分配之參數進行最大概似法之估計。</p>
<p>多元常態分配之最大概似估計最麻煩的部分在於，共變異數矩陣是對稱正定矩陣，因此，雖然共變異矩陣中有 <span class="math notranslate nohighlight">\(P \times P\)</span> 個元素，但事實上，其僅有 <span class="math notranslate nohighlight">\(P(P+1)/2\)</span> 個能夠自由估計之參數，並且，其數值需滿足正定矩陣之要求。為了處理此困難，在進行多元常態分配之參數設定時，我們不直接設定共變異數矩陣，取而代之的是，設定該矩陣之 Cholesky 拆解，即 <code class="docutils literal notranslate"><span class="pre">scale_tril</span></code></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">mu_true</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">])</span>
<span class="n">sigma_tril_true</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">3.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span> <span class="p">[</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span> <span class="p">[</span><span class="o">.</span><span class="mi">4</span><span class="p">,</span> <span class="o">.</span><span class="mi">5</span><span class="p">,</span> <span class="o">.</span><span class="mi">5</span><span class="p">]])</span>
<span class="n">model_mvn_true</span> <span class="o">=</span> <span class="n">MultivariateNormal</span><span class="p">(</span>
    <span class="n">loc</span><span class="o">=</span><span class="n">mu_true</span><span class="p">,</span>
    <span class="n">scale_tril</span><span class="o">=</span><span class="n">sigma_tril_true</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;true mean vector: </span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">model_mvn_true</span><span class="o">.</span><span class="n">mean</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;true covariance matrix: </span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">model_mvn_true</span><span class="o">.</span><span class="n">covariance_matrix</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>true mean vector: 
 
</pre></div>
</div>
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>tensor([-1.,  0.,  1.])
true covariance matrix: 
 tensor([[9.0000, 6.0000, 1.2000],
        [6.0000, 5.0000, 1.3000],
        [1.2000, 1.3000, 0.6600]])
</pre></div>
</div>
</div>
</div>
<p>前一程式碼所展示的共變異數矩陣，可透過以下的公式獲得</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">sigma_tril_true</span> <span class="o">@</span> <span class="n">sigma_tril_true</span><span class="o">.</span><span class="n">t</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>tensor([[9.0000, 6.0000, 1.2000],
        [6.0000, 5.0000, 1.3000],
        [1.2000, 1.3000, 0.6600]])
</pre></div>
</div>
</div>
</div>
<p>前式可以確保所得到的共變異數矩陣為對稱矩陣，另外，如果說給定的對角線元素為正的，則可以進一步確保該共變異數矩陣為對稱正定矩陣。</p>
<p>接著，我們就可以利用該分配物件來產生資料、計算概似函數數值、以及計算最大概似估計值。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">sample_size</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">model_mvn_true</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">sample_shape</span><span class="o">=</span><span class="p">(</span><span class="n">sample_size</span><span class="p">,))</span>
<span class="n">loss_value</span> <span class="o">=</span> <span class="o">-</span><span class="n">model_mvn_true</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;negative likelihood value is&quot;</span><span class="p">,</span> <span class="n">loss_value</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>negative likelihood value is tensor(4.7027)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">epochs</span> <span class="o">=</span> <span class="mi">500</span>
<span class="n">lr</span> <span class="o">=</span> <span class="o">.</span><span class="mi">1</span>
<span class="n">mu</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span>
    <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">sigma_tril</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span>
    <span class="p">[[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">]],</span>
    <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">opt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">([</span><span class="n">mu</span><span class="p">,</span> <span class="n">sigma_tril</span><span class="p">],</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
    <span class="n">model_mvn</span> <span class="o">=</span> <span class="n">MultivariateNormal</span><span class="p">(</span>
    <span class="n">loc</span><span class="o">=</span><span class="n">mu</span><span class="p">,</span>
    <span class="n">scale_tril</span><span class="o">=</span><span class="n">sigma_tril</span><span class="p">)</span>
    <span class="n">loss_value</span> <span class="o">=</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">model_mvn</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
    <span class="n">opt</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="n">loss_value</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span> <span class="c1"># compute the gradient</span>
    <span class="n">opt</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;ML mean by gradient descent: </span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">mu</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;ML covariance by gradient descent: </span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">sigma_tril</span> <span class="o">@</span> <span class="n">sigma_tril</span><span class="o">.</span><span class="n">t</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>ML mean by gradient descent: 
 tensor([-0.9867,  0.0500,  1.0333], requires_grad=True)
ML covariance by gradient descent: 
 tensor([[8.8861, 5.9122, 1.1475],
        [5.9122, 4.9496, 1.2802],
        [1.1475, 1.2802, 0.6796]], grad_fn=&lt;MmBackward&gt;)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">sample_mean</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">sample_moment2</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">t</span><span class="p">()</span> <span class="o">@</span> <span class="n">x</span><span class="p">)</span> <span class="o">/</span> <span class="n">sample_size</span>
<span class="n">sample_cov</span> <span class="o">=</span> <span class="n">sample_moment2</span> <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">ger</span><span class="p">(</span><span class="n">sample_mean</span><span class="p">,</span> <span class="n">sample_mean</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;ML mean by formula: </span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">sample_mean</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;ML covariance by formula: </span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">sample_cov</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>ML mean by formula: 
 tensor([-0.9867,  0.0500,  1.0333])
ML covariance by formula: 
 tensor([[8.8861, 5.9122, 1.1475],
        [5.9122, 4.9496, 1.2802],
        [1.1475, 1.2802, 0.6796]])
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="id7">
<h2><span class="section-number">8.3. </span>實徵範例<a class="headerlink" href="#id7" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id8">
<h3><span class="section-number">8.3.1. </span>產生邏吉斯迴歸資料<a class="headerlink" href="#id8" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">246437</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;torch._C.Generator at 0x7fc880afc1d0&gt;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch.distributions</span> <span class="kn">import</span> <span class="n">Bernoulli</span>
<span class="k">def</span> <span class="nf">generate_data</span><span class="p">(</span><span class="n">n_sample</span><span class="p">,</span>
                  <span class="n">weight</span><span class="p">,</span>
                  <span class="n">bias</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
                  <span class="n">mean_feature</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
                  <span class="n">std_feature</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
                  <span class="n">dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">):</span>
    <span class="n">weight</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">dtype</span><span class="p">)</span>
    <span class="n">n_feature</span> <span class="o">=</span> <span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">mean</span> <span class="o">=</span> <span class="n">mean_feature</span><span class="p">,</span>
                     <span class="n">std</span> <span class="o">=</span> <span class="n">std_feature</span><span class="p">,</span>
                     <span class="n">size</span> <span class="o">=</span> <span class="p">(</span><span class="n">n_sample</span><span class="p">,</span> <span class="n">n_feature</span><span class="p">),</span>
                     <span class="n">dtype</span> <span class="o">=</span> <span class="n">dtype</span><span class="p">)</span>
    <span class="n">weight</span> <span class="o">=</span> <span class="n">weight</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">logit</span> <span class="o">=</span> <span class="n">bias</span> <span class="o">+</span> <span class="n">x</span> <span class="o">@</span> <span class="n">weight</span>
    <span class="n">bernoulli</span> <span class="o">=</span> <span class="n">Bernoulli</span><span class="p">(</span><span class="n">logits</span> <span class="o">=</span> <span class="n">logit</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">bernoulli</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># run generate_data</span>
<span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">generate_data</span><span class="p">(</span><span class="n">n_sample</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">,</span>
                     <span class="n">weight</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
                     <span class="n">bias</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
                     <span class="n">mean_feature</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
                     <span class="n">std_feature</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
                     <span class="n">dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="id9">
<h3><span class="section-number">8.3.2. </span>建立一進行邏吉斯迴歸分析之物件<a class="headerlink" href="#id9" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># define a class to fit logistic regression</span>
<span class="k">class</span> <span class="nc">LogisticRegression</span><span class="p">():</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">dtype</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">x</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">def</span> <span class="nf">log_lik</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">weight</span><span class="p">):</span>
        <span class="n">logit</span> <span class="o">=</span> <span class="n">bias</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">x</span> <span class="o">@</span> <span class="n">weight</span>
        <span class="n">bernoulli</span> <span class="o">=</span> <span class="n">Bernoulli</span><span class="p">(</span><span class="n">logits</span> <span class="o">=</span> <span class="n">logit</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">bernoulli</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">optimizer</span> <span class="o">=</span> <span class="s2">&quot;LBFGS&quot;</span><span class="p">,</span>
            <span class="n">epochs</span> <span class="o">=</span> <span class="mi">200</span><span class="p">,</span> <span class="n">lr</span> <span class="o">=</span> <span class="o">.</span><span class="mi">1</span><span class="p">,</span> <span class="n">tol</span> <span class="o">=</span> <span class="mi">10</span><span class="o">**</span><span class="p">(</span><span class="o">-</span><span class="mi">7</span><span class="p">)):</span>
        <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">dtype</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">dtype</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">y</span><span class="o">.</span><span class="n">dtype</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">:</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">dtype</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">x</span> <span class="o">=</span> <span class="n">x</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y</span> <span class="o">=</span> <span class="n">y</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_sample</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_feature</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">bias</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,),</span>
                           <span class="n">dtype</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
                           <span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
        <span class="n">weight</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_feature</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
                             <span class="n">dtype</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
                             <span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">optimizer</span> <span class="o">==</span> <span class="s2">&quot;LBFGS&quot;</span><span class="p">:</span>
            <span class="n">opt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">LBFGS</span><span class="p">([</span><span class="n">bias</span><span class="p">,</span> <span class="n">weight</span><span class="p">],</span>
                                    <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span> <span class="n">max_iter</span> <span class="o">=</span> <span class="n">epochs</span><span class="p">,</span>
                                    <span class="n">tolerance_grad</span> <span class="o">=</span> <span class="n">tol</span><span class="p">,</span>
                                    <span class="n">line_search_fn</span> <span class="o">=</span> <span class="s2">&quot;strong_wolfe&quot;</span><span class="p">)</span>
            <span class="k">def</span> <span class="nf">closure</span><span class="p">():</span>
                <span class="n">opt</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
                <span class="n">loss_value</span> <span class="o">=</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_lik</span><span class="p">(</span><span class="n">bias</span><span class="p">,</span> <span class="n">weight</span><span class="p">)</span>
                <span class="n">loss_value</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
                <span class="k">return</span> <span class="n">loss_value</span>
            <span class="n">opt</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">closure</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">opt</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">)([</span><span class="n">bias</span><span class="p">,</span> <span class="n">weight</span><span class="p">],</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
                <span class="n">opt</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
                <span class="n">loss_value</span> <span class="o">=</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_lik</span><span class="p">(</span><span class="n">bias</span><span class="p">,</span> <span class="n">weight</span><span class="p">)</span>
                <span class="n">loss_value</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
                <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                    <span class="n">grad_max</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">bias</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span>
                                   <span class="n">weight</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
                <span class="k">if</span> <span class="p">(</span><span class="n">grad_max</span> <span class="o">&lt;</span> <span class="n">tol</span><span class="p">):</span>
                    <span class="k">break</span>
                <span class="n">opt</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        <span class="c1"># print(opt.state_dict())</span>
        <span class="k">return</span> <span class="bp">self</span>
    <span class="k">def</span> <span class="nf">vcov</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">torch.autograd.functional</span> <span class="kn">import</span> <span class="n">hessian</span>
        <span class="n">bias</span><span class="p">,</span> <span class="n">weight</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">hessian</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_lik</span><span class="p">,</span> <span class="p">(</span><span class="n">bias</span><span class="p">,</span> <span class="n">weight</span><span class="p">))</span>
        <span class="n">fisher_obs</span> <span class="o">=</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">h</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span><span class="n">h</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">dim</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)],</span> <span class="n">dim</span> <span class="o">=</span> <span class="mi">1</span><span class="p">),</span>
                                <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">h</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">dim</span> <span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">dim</span> <span class="o">=</span><span class="mi">1</span><span class="p">),</span>
                                           <span class="n">h</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()],</span> <span class="n">dim</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)],</span>
                               <span class="n">dim</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>

        <span class="n">vcov</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">fisher_obs</span><span class="p">)</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">n_sample</span>
        <span class="k">return</span> <span class="n">vcov</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="id10">
<h3><span class="section-number">8.3.3. </span>計算模型參數<a class="headerlink" href="#id10" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># fit logistic model</span>
<span class="n">model_lr</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">()</span>
<span class="n">model_lr</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">optimizer</span> <span class="o">=</span> <span class="s2">&quot;LBFGS&quot;</span><span class="p">,</span> <span class="n">epochs</span> <span class="o">=</span> <span class="mi">2000</span><span class="p">,</span> <span class="n">lr</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model_lr</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model_lr</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>[3.73765684]
[[-6.32144761]
 [ 3.74170747]
 [-0.05765073]]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># fit logistic model via sklearn</span>
<span class="c1"># please install sklearn first</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">linear_model</span>
<span class="n">model_lr_sklearn</span> <span class="o">=</span> <span class="n">linear_model</span><span class="o">.</span><span class="n">LogisticRegression</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span>
<span class="n">model_lr_sklearn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model_lr_sklearn</span><span class="o">.</span><span class="n">intercept_</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model_lr_sklearn</span><span class="o">.</span><span class="n">coef_</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>[3.736656]
[[-6.31995124  3.74083793 -0.05764225]]
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="id11">
<h3><span class="section-number">8.3.4. </span>計算參數估計標準誤<a class="headerlink" href="#id11" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">vcov</span> <span class="o">=</span> <span class="n">model_lr</span><span class="o">.</span><span class="n">vcov</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">vcov</span><span class="o">.</span><span class="n">diagonal</span><span class="p">()</span><span class="o">.</span><span class="n">sqrt</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>tensor([2.0433, 1.1524, 0.6945, 0.1204], dtype=torch.float64)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># fit logistic model via statsmodels</span>
<span class="c1"># please install statsmodels first</span>
<span class="kn">import</span> <span class="nn">statsmodels.api</span> <span class="k">as</span> <span class="nn">sm</span>
<span class="n">model_lr_sm</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">Logit</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">sm</span><span class="o">.</span><span class="n">add_constant</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">numpy</span><span class="p">()))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model_lr_sm</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>Optimization terminated successfully.
         Current function value: 0.032809
         Iterations 13
                           Logit Regression Results                           
==============================================================================
Dep. Variable:                      y   No. Observations:                 1000
Model:                          Logit   Df Residuals:                      996
Method:                           MLE   Df Model:                            3
Date:                Wed, 11 Nov 2020   Pseudo R-squ.:                  0.9211
Time:                        10:10:40   Log-Likelihood:                -32.809
converged:                       True   LL-Null:                       -415.71
Covariance Type:            nonrobust   LLR p-value:                1.133e-165
==============================================================================
                 coef    std err          z      P&gt;|z|      [0.025      0.975]
------------------------------------------------------------------------------
const          3.7373      2.043      1.829      0.067      -0.267       7.742
x1            -6.3211      1.152     -5.485      0.000      -8.580      -4.063
x2             3.7415      0.694      5.388      0.000       2.380       5.103
x3            -0.0577      0.120     -0.479      0.632      -0.294       0.178
==============================================================================

Possibly complete quasi-separation: A fraction 0.81 of observations can be
perfectly predicted. This might indicate that there is complete
quasi-separation. In this case some parameters will not be identified.
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="id12">
<h3><span class="section-number">8.3.5. </span>練習<a class="headerlink" href="#id12" title="Permalink to this headline">¶</a></h3>
<ol class="simple">
<li><p>請建立一類型，其可以使用最大概似法，執行線性回歸分析。該模型假設給定 <span class="math notranslate nohighlight">\(x_n\)</span>，<span class="math notranslate nohighlight">\(y_n\)</span> 的條件分佈為 <span class="math notranslate nohighlight">\(\text{Normal}(w_0 + \sum_{p=1}^P w_p x_{np}, \sigma_{\epsilon}^2)\)</span>。</p></li>
<li><p>請在前述的類型中，加入一摘要方法（<code class="docutils literal notranslate"><span class="pre">summary()</span></code>），該方法可以列印出參數估計的假設檢定與信賴區間。</p></li>
<li><p>請建立一類型，其可以估計多元常態分配的平均數與共變異數矩陣，並且提供各參數估計之標準誤。</p></li>
</ol>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./notebook"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="maximum-likelihood.html" title="previous page"><span class="section-number">7. </span>最大概似法</a>
    <a class='right-next' id="next-link" href="true-score-model.html" title="next page"><span class="section-number">9. </span>真實分數模型</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Po-Hsien Huang<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    <script src="../_static/js/index.js"></script>
    
  </body>
</html>