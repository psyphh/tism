{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "Lab: `tensoflow` 範例\n",
    "================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-05T06:12:35.746887Z",
     "iopub.status.busy": "2021-01-05T06:12:35.745839Z",
     "iopub.status.idle": "2021-01-05T06:12:57.871583Z",
     "shell.execute_reply": "2021-01-05T06:12:57.872098Z"
    },
    "id": "N0okuQckPWIY"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow_probability import distributions as tfd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VC9fzjMEPnj3"
   },
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-05T06:12:57.883998Z",
     "iopub.status.busy": "2021-01-05T06:12:57.883173Z",
     "iopub.status.idle": "2021-01-05T06:12:57.887819Z",
     "shell.execute_reply": "2021-01-05T06:12:57.888260Z"
    },
    "id": "g1RplVD_Qc9Q"
   },
   "outputs": [],
   "source": [
    "# define a function to generate x and y\n",
    "def generate_linear_reg_data(\n",
    "    n_sample, weight, intercept = 0, sd_residual = 1,\n",
    "    dtype = tf.float64, seed = None):\n",
    "    weight = tf.constant(weight, dtype = dtype)\n",
    "    weight = tf.reshape(weight, shape = (-1, 1))\n",
    "    n_feature = weight.shape[0]\n",
    "    x = tf.random.normal(shape = (n_sample, n_feature),\n",
    "                         seed = seed, dtype = dtype)\n",
    "    e = tf.random.normal(shape = (n_sample, 1),\n",
    "                         seed = seed, dtype = dtype)\n",
    "    y = intercept + x @ weight + e\n",
    "    return x, y\n",
    "\n",
    "# run generate_data\n",
    "n_sample = 10000\n",
    "weight_true = [-1, 2, 0]\n",
    "dtype = tf.float64\n",
    "\n",
    "x, y = generate_linear_reg_data(\n",
    "    n_sample = n_sample, weight = weight_true,\n",
    "    intercept = 0, sd_residual = 1,\n",
    "    dtype = dtype, seed = 48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-01-05T06:12:57.892672Z",
     "iopub.status.busy": "2021-01-05T06:12:57.892018Z",
     "iopub.status.idle": "2021-01-05T06:12:58.126274Z",
     "shell.execute_reply": "2021-01-05T06:12:58.126724Z"
    },
    "id": "WvLX-d0FUSqd",
    "outputId": "82a29269-c784-4b02-d0bb-7647d8891199"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD Optimizer Converges After 45 Iterations\n",
      "intercept -0.012025053092215557\n",
      "weight [[-0.99697044]\n",
      " [ 1.99617999]\n",
      " [ 0.02433336]]\n"
     ]
    }
   ],
   "source": [
    "# start optimization\n",
    "n_feature = len(weight_true)\n",
    "learning_rate = .1\n",
    "epochs = 500\n",
    "tol = 10**(-4)\n",
    "\n",
    "optimizer = tf.optimizers.SGD(learning_rate = learning_rate)\n",
    "\n",
    "intercept = tf.Variable(tf.zeros((), dtype = dtype), \n",
    "                        name = \"intercept\")\n",
    "weight = tf.Variable(tf.zeros((n_feature, 1), dtype = dtype), \n",
    "                     name = \"weight\")\n",
    "\n",
    "for epoch in tf.range(epochs):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_hat = intercept + x @ weight\n",
    "        loss_value = tf.reduce_mean((y - y_hat)**2)\n",
    "    gradients = tape.gradient(loss_value, [intercept, weight])\n",
    "    optimizer.apply_gradients(zip(gradients, [intercept, weight]))\n",
    "    #print(weight)\n",
    "    if (tf.reduce_max(\n",
    "            [tf.reduce_mean(\n",
    "                tf.math.abs(x)) for x in gradients]).numpy()) < tol:\n",
    "        print(\"{n} Optimizer Converges After {i} Iterations\".format(\n",
    "            n=optimizer.__class__.__name__, i=epoch))\n",
    "        break\n",
    "\n",
    "print(\"intercept\", intercept.numpy())\n",
    "print(\"weight\", weight.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TZ_MZWfBhl5v"
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-05T06:12:58.136987Z",
     "iopub.status.busy": "2021-01-05T06:12:58.136307Z",
     "iopub.status.idle": "2021-01-05T06:12:58.143667Z",
     "shell.execute_reply": "2021-01-05T06:12:58.144117Z"
    },
    "id": "BMtDMypchoxa"
   },
   "outputs": [],
   "source": [
    "# define a function to generate x and y\n",
    "def generate_logistic_reg_data(\n",
    "    n_sample, weight, intercept = 0, \n",
    "    dtype = tf.float64, seed = None):\n",
    "    weight = tf.constant(weight, dtype = dtype)\n",
    "    weight = tf.reshape(weight, shape = (-1, 1))\n",
    "    n_feature = weight.shape[0]\n",
    "    x = tf.random.normal(shape = (n_sample, n_feature),\n",
    "                         seed = seed, dtype = dtype)\n",
    "    logits = intercept + x @ weight\n",
    "    y = tfd.Bernoulli(logits=logits, dtype=dtype).sample()\n",
    "    return x, y\n",
    "\n",
    "# run generate_data\n",
    "n_sample = 10000\n",
    "weight_true = [-1, 2, 0]\n",
    "dtype = tf.float64\n",
    "\n",
    "x, y = generate_logistic_reg_data(\n",
    "    n_sample = n_sample, \n",
    "    weight = weight_true,intercept = 0, \n",
    "    dtype = dtype, seed = 48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-05T06:12:58.149637Z",
     "iopub.status.busy": "2021-01-05T06:12:58.149028Z",
     "iopub.status.idle": "2021-01-05T06:12:58.151094Z",
     "shell.execute_reply": "2021-01-05T06:12:58.151522Z"
    },
    "id": "JpGdAGR2iutc"
   },
   "outputs": [],
   "source": [
    "# define a tf.Module to collect parameters\n",
    "class LinearModel(tf.Module):\n",
    "  def __init__(self, n_feature, dtype = tf.float64):\n",
    "    super().__init__()\n",
    "    self.weight = tf.Variable(tf.zeros((n_feature, 1), \n",
    "                                       dtype = dtype), \n",
    "                              name = \"weight\")\n",
    "    self.intercept = tf.Variable(tf.zeros((), dtype = dtype), \n",
    "                                 name = \"intercept\")\n",
    "  def __call__(self, x):\n",
    "    return self.intercept + x @ self.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-01-05T06:12:58.159260Z",
     "iopub.status.busy": "2021-01-05T06:12:58.158501Z",
     "iopub.status.idle": "2021-01-05T06:12:59.053314Z",
     "shell.execute_reply": "2021-01-05T06:12:59.054008Z"
    },
    "id": "nJtGDN2skY9T",
    "outputId": "531a9c38-2c8f-4c55-996b-7bb5257ae6f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD Optimizer Converges After 215 Iterations\n",
      "intercept 0.038359231456371566\n",
      "weight [[-0.99361795]\n",
      " [ 2.00713225]\n",
      " [-0.0315113 ]]\n"
     ]
    }
   ],
   "source": [
    "n_feature = len(weight_true)\n",
    "learning_rate = .5\n",
    "epochs = 500\n",
    "tol = 10**(-4)\n",
    "\n",
    "linear_model = LinearModel(n_feature, dtype)\n",
    "optimizer = tf.optimizers.SGD(learning_rate = learning_rate)\n",
    "\n",
    "for epoch in tf.range(epochs):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = linear_model(x)\n",
    "        loss_value = - tf.reduce_mean(\n",
    "            tfd.Bernoulli(logits=logits).log_prob(y))\n",
    "    gradients = tape.gradient(\n",
    "        loss_value, linear_model.trainable_variables)\n",
    "    optimizer.apply_gradients(\n",
    "        zip(gradients, linear_model.trainable_variables))\n",
    "    if (tf.reduce_max(\n",
    "            [tf.reduce_mean(\n",
    "                tf.math.abs(x)) for x in gradients]).numpy()) < tol:\n",
    "        print(\"{n} Optimizer Converges After {i} Iterations\".format(\n",
    "            n=optimizer.__class__.__name__, i=epoch))\n",
    "        break\n",
    "\n",
    "print(\"intercept\", linear_model.intercept.numpy())\n",
    "print(\"weight\", linear_model.weight.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "toH0-cITKYZo"
   },
   "source": [
    "## Factor Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-05T06:12:59.070029Z",
     "iopub.status.busy": "2021-01-05T06:12:59.068809Z",
     "iopub.status.idle": "2021-01-05T06:12:59.148943Z",
     "shell.execute_reply": "2021-01-05T06:12:59.149540Z"
    },
    "id": "8npnnKsrKX92"
   },
   "outputs": [],
   "source": [
    "def generate_fa_data(n_sample, n_factor, n_item, \n",
    "                     ld, psi = None, rho = None, \n",
    "                     dtype = tf.float64):\n",
    "    if (n_item % n_factor) != 0:\n",
    "        n_item = n_factor * (n_item // n_factor)\n",
    "    loading = np.zeros((n_item, n_factor))\n",
    "    item_per_factor = (n_item // n_factor)\n",
    "    for i in range(n_factor):\n",
    "        for j in range(i * item_per_factor,\n",
    "                       (i + 1) * item_per_factor):\n",
    "            loading[j, i] = ld\n",
    "    loading = tf.constant(loading, dtype = dtype)\n",
    "    if rho is None:\n",
    "        cor = tf.eye(n_factor, dtype = dtype)\n",
    "    else:\n",
    "        unit = tf.ones((n_factor, 1), dtype = dtype)\n",
    "        identity = tf.eye(n_factor, dtype = dtype)\n",
    "        cor = rho * (unit @ tf.transpose(unit)) + (1 - rho) * identity\n",
    "    if psi is None:\n",
    "        uniqueness = 1 - tf.linalg.diag_part(loading @ cor @ tf.transpose(loading))\n",
    "    else:\n",
    "        uniqueness = psi * tf.ones((n_item, ), dtype = dtype)\n",
    "    \n",
    "    mean = tf.zeros(n_item, dtype = dtype)\n",
    "    cov = loading @ cor @ tf.transpose(loading) + tf.linalg.diag(uniqueness)\n",
    "    dist_x = tfd.MultivariateNormalTriL(\n",
    "        loc = mean, scale_tril = tf.linalg.cholesky(cov))\n",
    "    x = dist_x.sample(n_sample)\n",
    "    return x\n",
    "\n",
    "n_sample = 10000\n",
    "n_factor = 4\n",
    "n_item = 12\n",
    "ld = .7\n",
    "dtype = tf.float64\n",
    "\n",
    "x = generate_fa_data(n_sample, n_factor, \n",
    "                     n_item, ld,\n",
    "                     dtype = dtype)\n",
    "sample_mean = tf.reduce_mean(x, axis = 0)\n",
    "sample_cov = tf.transpose(x - sample_mean) @ (x - sample_mean) / n_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-01-05T06:12:59.158480Z",
     "iopub.status.busy": "2021-01-05T06:12:59.157620Z",
     "iopub.status.idle": "2021-01-05T06:12:59.160815Z",
     "shell.execute_reply": "2021-01-05T06:12:59.161369Z"
    },
    "id": "zHW9chhhsx-s",
    "outputId": "3cacd122-b1f1-4b6e-dd1d-3068509b2958"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(12,), dtype=float64, numpy=\n",
       "array([-0.00753584, -0.00187876, -0.00568033,  0.00640062, -0.02027605,\n",
       "        0.00150894,  0.0221699 ,  0.02965379,  0.01331654, -0.02272707,\n",
       "       -0.01132167, -0.02347031])>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-05T06:12:59.169632Z",
     "iopub.status.busy": "2021-01-05T06:12:59.168866Z",
     "iopub.status.idle": "2021-01-05T06:12:59.172251Z",
     "shell.execute_reply": "2021-01-05T06:12:59.173404Z"
    },
    "id": "wffqM99mRdYu"
   },
   "outputs": [],
   "source": [
    "# define a tf.Module to coollect parameters\n",
    "class FactorModel(tf.Module):\n",
    "  def __init__(self, n_item, n_factor, \n",
    "               dtype = tf.float64):\n",
    "    super().__init__()\n",
    "    self.intercept = tf.Variable(\n",
    "        tf.zeros(n_item, dtype = dtype), name = \"intercept\")\n",
    "    self.loading = tf.Variable(\n",
    "        tf.random.uniform((n_item, n_factor), dtype = dtype), \n",
    "        name = \"loading\")\n",
    "    self.uniqueness = tf.Variable(\n",
    "        tf.fill(n_item, value = tf.constant(.2, dtype = dtype)), \n",
    "        name = \"uniqueness\")\n",
    "  def __call__(self):\n",
    "      model_mean = self.intercept\n",
    "      model_cov = self.loading @ tf.transpose(self.loading) + tf.linalg.diag(self.uniqueness)\n",
    "      return model_mean, model_cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-01-05T06:12:59.178849Z",
     "iopub.status.busy": "2021-01-05T06:12:59.178122Z",
     "iopub.status.idle": "2021-01-05T06:13:05.965500Z",
     "shell.execute_reply": "2021-01-05T06:13:05.966612Z"
    },
    "id": "W6d0DLuFYcMF",
    "outputId": "7b628ed7-f6eb-49f2-b498-d97813798802"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD Optimizer Converges After 112 Iterations\n",
      "intercept [-0.00753584 -0.00187876 -0.00568033  0.00640062 -0.02027605  0.00150894\n",
      "  0.0221699   0.02965379  0.01331654 -0.02272707 -0.01132167 -0.02347031]\n",
      "loading [[ 0.31055331  0.61526413 -0.13135377  0.06137542]\n",
      " [ 0.33408213  0.61058939 -0.11385572  0.07724464]\n",
      " [ 0.31761933  0.60357108 -0.11599456  0.05329567]\n",
      " [ 0.12770225 -0.13202705 -0.16211331  0.66349195]\n",
      " [ 0.11347517 -0.14448353 -0.16478664  0.64915067]\n",
      " [ 0.1132218  -0.13675867 -0.16407347  0.64705477]\n",
      " [ 0.24230104 -0.0420092   0.65659548  0.10148097]\n",
      " [ 0.25207928 -0.02581754  0.64480493  0.11331565]\n",
      " [ 0.25448579 -0.03213921  0.64685363  0.10958368]\n",
      " [-0.57544496  0.30693552  0.19453592  0.20522389]\n",
      " [-0.5692919   0.31433119  0.19352999  0.20114726]\n",
      " [-0.5487563   0.30090974  0.17519249  0.20209436]]\n",
      "uniqueness [0.50749634 0.48467768 0.52422564 0.50956861 0.50447733 0.53200612\n",
      " 0.49749027 0.49267242 0.51261474 0.4969636  0.50349664 0.5473236 ]\n"
     ]
    }
   ],
   "source": [
    "learning_rate = .5\n",
    "epochs = 500\n",
    "tol = 10**(-4)\n",
    "\n",
    "factor_model = FactorModel(n_item, n_factor, dtype)\n",
    "optimizer = tf.optimizers.SGD(learning_rate = learning_rate)\n",
    "\n",
    "for epoch in tf.range(epochs):\n",
    "    with tf.GradientTape() as tape:\n",
    "        model_mean, model_cov = factor_model()\n",
    "        mvn = tfd.MultivariateNormalTriL(\n",
    "            loc = model_mean, \n",
    "            scale_tril = tf.linalg.cholesky(model_cov))\n",
    "        loss_value = - tf.reduce_mean(mvn.log_prob(x))\n",
    "    gradients = tape.gradient(\n",
    "        loss_value, factor_model.trainable_variables)\n",
    "    optimizer.apply_gradients(\n",
    "        zip(gradients, factor_model.trainable_variables))\n",
    "    if (tf.reduce_max(\n",
    "            [tf.reduce_mean(\n",
    "                tf.math.abs(x)) for x in gradients]).numpy()) < tol:\n",
    "        print(\"{n} Optimizer Converges After {i} Iterations\".format(\n",
    "            n=optimizer.__class__.__name__, i=epoch))\n",
    "        break\n",
    "\n",
    "print(\"intercept\", factor_model.intercept.numpy())\n",
    "print(\"loading\", factor_model.loading.numpy())\n",
    "print(\"uniqueness\", factor_model.uniqueness.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m2MgZjN3hpwt"
   },
   "source": [
    "## Two-Parameter Logistic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-05T06:13:05.975972Z",
     "iopub.status.busy": "2021-01-05T06:13:05.975235Z",
     "iopub.status.idle": "2021-01-05T06:13:05.977667Z",
     "shell.execute_reply": "2021-01-05T06:13:05.978155Z"
    },
    "id": "Ps5_2oCmhuJB"
   },
   "outputs": [],
   "source": [
    "def generate_2pl_data(n_sample, n_factor, n_item, \n",
    "                      alpha, beta, rho, \n",
    "                      dtype = tf.float64):\n",
    "    if (n_item % n_factor) != 0:\n",
    "        n_item = n_factor * (n_item // n_factor)\n",
    "    item_per_factor = (n_item // n_factor)\n",
    "    intercept = tf.fill((n_item,), value = tf.constant(alpha, dtype = dtype))\n",
    "    loading = np.zeros((n_item, n_factor))\n",
    "    for i in range(n_factor):\n",
    "        for j in range(i * item_per_factor,\n",
    "                       (i + 1) * item_per_factor):\n",
    "            loading[j, i] = ld\n",
    "    loading = tf.constant(loading, dtype = dtype)\n",
    "    if rho is None:\n",
    "        cor = tf.eye(n_factor, dtype = dtype)\n",
    "    else:\n",
    "        unit = tf.ones((n_factor, 1), dtype = dtype)\n",
    "        identity = tf.eye(n_factor, dtype = dtype)\n",
    "        cor = rho * (unit @ tf.transpose(unit)) + (1 - rho) * identity\n",
    "    dist_eta = tfd.MultivariateNormalTriL(\n",
    "        loc = tf.zeros(n_factor, dtype = dtype), scale_tril = tf.linalg.cholesky(cor))\n",
    "    eta = dist_eta.sample(n_sample)\n",
    "    logits = intercept + eta @ tf.transpose(loading)\n",
    "    x = tfd.Bernoulli(logits=logits, dtype=dtype).sample()\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-05T06:13:05.983412Z",
     "iopub.status.busy": "2021-01-05T06:13:05.982637Z",
     "iopub.status.idle": "2021-01-05T06:13:06.001798Z",
     "shell.execute_reply": "2021-01-05T06:13:06.002237Z"
    },
    "id": "cU5w0Eg-r45W"
   },
   "outputs": [],
   "source": [
    "n_sample = 10000\n",
    "n_factor = 5\n",
    "n_item = 25\n",
    "alpha = .2\n",
    "beta = .7 \n",
    "rho = 0\n",
    "dtype = tf.float64\n",
    "x = generate_2pl_data(n_sample, n_factor, n_item, \n",
    "                      alpha, beta, rho, \n",
    "                      dtype = dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-05T06:13:06.009934Z",
     "iopub.status.busy": "2021-01-05T06:13:06.008323Z",
     "iopub.status.idle": "2021-01-05T06:13:06.011457Z",
     "shell.execute_reply": "2021-01-05T06:13:06.011941Z"
    },
    "id": "Uwl2REi6oLc_"
   },
   "outputs": [],
   "source": [
    "class TwoPLModel(tf.Module):\n",
    "    def __init__(self, n_item, n_factor, \n",
    "                 dtype = tf.float64):\n",
    "        super().__init__()\n",
    "        self.dtype = dtype\n",
    "        self.intercept = tf.Variable(\n",
    "            tf.zeros(n_item, dtype = self.dtype), name = \"intercept\")\n",
    "        self.loading = tf.Variable(\n",
    "            tf.random.uniform((n_item, n_factor), dtype = self.dtype), \n",
    "            name = \"loading\")\n",
    "    def __call__(self, x):\n",
    "        n_sample = len(x)\n",
    "        joint_prob = tfd.JointDistributionSequential([\n",
    "            tfd.Independent(\n",
    "                tfd.Normal(\n",
    "                    loc = tf.zeros((n_sample, n_factor), dtype=self.dtype),\n",
    "                    scale = 1.0), \n",
    "                reinterpreted_batch_ndims=1),\n",
    "            lambda eta: tfd.Independent(\n",
    "                tfd.Bernoulli(\n",
    "                    logits= self.intercept + eta @ tf.transpose(self.loading), \n",
    "                    dtype=self.dtype), \n",
    "                reinterpreted_batch_ndims=1)])             \n",
    "        joint_prob._to_track=self\n",
    "        return joint_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-05T06:13:06.019729Z",
     "iopub.status.busy": "2021-01-05T06:13:06.019063Z",
     "iopub.status.idle": "2021-01-05T06:13:06.071890Z",
     "shell.execute_reply": "2021-01-05T06:13:06.072390Z"
    },
    "id": "QPXjWR2rGb1S"
   },
   "outputs": [],
   "source": [
    "two_pl_model = TwoPLModel(n_item, n_factor)\n",
    "joint_prob = two_pl_model(x)\n",
    "\n",
    "def target_log_prob_fn(*eta):\n",
    "    return joint_prob.log_prob(eta + (x,))\n",
    "\n",
    "hmc=tfp.mcmc.HamiltonianMonteCarlo(\n",
    "    target_log_prob_fn = target_log_prob_fn,\n",
    "    step_size = .015,\n",
    "    num_leapfrog_steps=3)\n",
    "current_state = joint_prob.sample()[:-1]\n",
    "kernel_results = hmc.bootstrap_results(current_state)\n",
    "\n",
    "@tf.function(autograph=False,\n",
    "             experimental_compile=True)\n",
    "def one_e_step(current_state, kernel_results):\n",
    "    next_state, next_kernel_results = hmc.one_step(\n",
    "        current_state=current_state,\n",
    "        previous_kernel_results=kernel_results)\n",
    "    return next_state, next_kernel_results\n",
    "\n",
    "optimizer=tf.optimizers.RMSprop(learning_rate=.01)\n",
    "\n",
    "@tf.function(autograph=False, \n",
    "             experimental_compile=True)\n",
    "def one_m_step(current_state):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = -tf.reduce_mean(\n",
    "            target_log_prob_fn(*current_state))\n",
    "    gradients = tape.gradient(loss_value, two_pl_model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, two_pl_model.trainable_variables))\n",
    "    return loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-01-05T06:13:06.087407Z",
     "iopub.status.busy": "2021-01-05T06:13:06.086616Z",
     "iopub.status.idle": "2021-01-05T06:13:08.774563Z",
     "shell.execute_reply": "2021-01-05T06:13:08.775010Z"
    },
    "id": "cuL5oF3zLofj",
    "outputId": "c25dadf5-ecd4-45e0-9b74-86f5e9fd1865"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warm-Up Iteration:   0 Acceptance Rate: 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:    0 Acceptance Rate: 1.000 Loss: 28.280\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "num_warmup_start = 1\n",
    "num_warmup_iter = 1\n",
    "num_iters = 1\n",
    "num_accepted = 0\n",
    "loss_history = np.zeros([num_iters])\n",
    "tStart = time.time()\n",
    "# Run warm-up stage.\n",
    "for t in range(num_warmup_start):\n",
    "    current_state, kernel_results = one_e_step(\n",
    "        current_state, kernel_results)\n",
    "    num_accepted += kernel_results.is_accepted.numpy().prod()\n",
    "    if t % 500 == 0:\n",
    "        print(\"Warm-Up Iteration: {:>3} Acceptance Rate: {:.3f}\".format(\n",
    "            t, num_accepted / (t + 1)))\n",
    "num_accepted = 0  # reset acceptance rate counter\n",
    "\n",
    "# Run training.\n",
    "for t in range(num_iters):\n",
    "    for _ in range(num_warmup_iter):\n",
    "        current_state, kernel_results = one_e_step(current_state, kernel_results)\n",
    "    loss_value = one_m_step(current_state)\n",
    "    num_accepted += kernel_results.is_accepted.numpy().prod()\n",
    "    loss_history[t] = loss_value.numpy()\n",
    "    if t % 50 == 0:\n",
    "        print(\"Iteration: {:>4} Acceptance Rate: {:.3f} Loss: {:.3f}\".format(\n",
    "            t, num_accepted / (t + 1), loss_history[t]))\n",
    "tEnd = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-01-05T06:13:08.786767Z",
     "iopub.status.busy": "2021-01-05T06:13:08.786009Z",
     "iopub.status.idle": "2021-01-05T06:13:08.788626Z",
     "shell.execute_reply": "2021-01-05T06:13:08.789079Z"
    },
    "id": "BU2I5EgqMlqc",
    "outputId": "1070f273-97c7-4023-dd9d-acfc070bfc0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.686702251434326\n",
      "[0.03 0.03 0.03 0.03 0.03 0.03 0.03 0.03 0.03 0.03 0.03 0.03 0.03 0.03\n",
      " 0.03 0.03 0.03 0.03 0.03 0.03 0.03 0.03 0.03 0.03 0.03]\n",
      "[[ 0.1   0.38  0.71  0.34  0.82]\n",
      " [ 0.6   0.18  0.33  0.78  0.04]\n",
      " [ 0.63  0.63  0.13  0.31  0.71]\n",
      " [ 0.24  0.46  0.32  0.33  0.52]\n",
      " [ 0.69  0.04  0.41  0.66  0.05]\n",
      " [ 0.36  0.24  0.09  0.29  0.88]\n",
      " [ 0.83  0.44  0.64  0.25  0.43]\n",
      " [ 0.69  0.5   0.49  0.26  0.28]\n",
      " [ 0.37  0.11  0.21  0.66  0.78]\n",
      " [ 0.63  0.24  0.7   0.84  0.14]\n",
      " [ 0.83  0.76  0.65  0.07  0.6 ]\n",
      " [ 0.71  0.78  0.15  0.85  0.88]\n",
      " [ 0.04  0.11  0.05  0.72  0.88]\n",
      " [ 0.11  0.44  0.24  0.46  0.41]\n",
      " [ 0.09  0.28  0.8   0.88  0.92]\n",
      " [ 0.13  0.87  0.79  0.06  0.03]\n",
      " [ 0.22  0.97  0.92  0.3   0.15]\n",
      " [ 0.3   0.4   0.27  0.71  0.56]\n",
      " [ 0.05  0.26  0.07  0.65  0.05]\n",
      " [ 0.65  0.4   0.42 -0.01  0.23]\n",
      " [ 0.78  0.29  0.47  0.64  0.62]\n",
      " [ 0.06  0.58  0.7   0.21  0.1 ]\n",
      " [ 0.13  0.52  0.03 -0.02  0.72]\n",
      " [ 0.94  0.63  0.16  0.09  0.95]\n",
      " [ 0.04  0.47  0.62  0.66  0.13]]\n"
     ]
    }
   ],
   "source": [
    "print(tEnd - tStart)\n",
    "print(np.around(two_pl_model.trainable_variables[0].numpy(), decimals=2))\n",
    "print(np.around(two_pl_model.trainable_variables[1].numpy(), decimals=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PD-1UVbZcO9l",
    "outputId": "fad76292-5e31-4226-e416-5a1ff355c3d4",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Grade Response Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-01-05T06:13:08.797682Z",
     "iopub.status.busy": "2021-01-05T06:13:08.796263Z",
     "iopub.status.idle": "2021-01-05T06:13:08.801580Z",
     "shell.execute_reply": "2021-01-05T06:13:08.802036Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_cd(n_category, dtype):\n",
    "    c1 = tf.linalg.diag(\n",
    "        tf.fill([n_category - 1],\n",
    "                tf.constant([1], dtype = dtype)),\n",
    "        k = 0, num_rows= n_category - 1, num_cols= n_category)\n",
    "    c2 = tf.linalg.diag(\n",
    "        tf.fill([n_category - 1],\n",
    "            tf.constant([1], dtype = dtype)),\n",
    "        k = 1, num_rows= n_category - 1, num_cols= n_category)\n",
    "    c = c1 - c2\n",
    "    d = tf.squeeze(tf.linalg.diag(\n",
    "        tf.constant([1], dtype = dtype),\n",
    "        k = n_category - 1, num_rows= 1, num_cols= n_category))\n",
    "    return c, d\n",
    "\n",
    "def grm_irf(eta, intercept, loading, c, d):\n",
    "    tau = tf.expand_dims(eta @ tf.transpose(loading), axis = 2) + intercept\n",
    "    probs = tf.math.sigmoid(tau) @ c + d\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-01-05T06:13:08.813401Z",
     "iopub.status.busy": "2021-01-05T06:13:08.812223Z",
     "iopub.status.idle": "2021-01-05T06:13:08.814907Z",
     "shell.execute_reply": "2021-01-05T06:13:08.815317Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def generate_grm_data(n_sample, n_factor, n_item,\n",
    "                      nu, ld, rho,\n",
    "                      dtype = tf.float64):\n",
    "    if (n_item % n_factor) != 0:\n",
    "        n_item = n_factor * (n_item // n_factor)\n",
    "    item_per_factor = (n_item // n_factor)\n",
    "    n_category = len(nu) + 1\n",
    "    intercept = tf.tile(tf.constant([nu], dtype = dtype),\n",
    "                        multiples = [n_item, 1])\n",
    "    loading = np.zeros((n_item, n_factor))\n",
    "    for i in range(n_factor):\n",
    "        for j in range(i * item_per_factor,\n",
    "                       (i + 1) * item_per_factor):\n",
    "            loading[j, i] = ld\n",
    "    loading = tf.constant(loading, dtype = dtype)\n",
    "    if rho is None:\n",
    "        cor = tf.eye(n_factor, dtype = dtype)\n",
    "    else:\n",
    "        unit = tf.ones((n_factor, 1), dtype = dtype)\n",
    "        identity = tf.eye(n_factor, dtype = dtype)\n",
    "        cor = rho * (unit @ tf.transpose(unit)) + (1 - rho) * identity\n",
    "    dist_eta = tfd.MultivariateNormalTriL(\n",
    "        loc = tf.zeros(n_factor, dtype = dtype),\n",
    "        scale_tril = tf.linalg.cholesky(cor))\n",
    "    eta = dist_eta.sample(n_sample)\n",
    "    c, d = create_cd(n_category, dtype)\n",
    "    probs = grm_irf(eta, intercept, loading, c, d)\n",
    "    x = tfd.Categorical(probs=probs, dtype=dtype).sample()\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-01-05T06:13:08.820404Z",
     "iopub.status.busy": "2021-01-05T06:13:08.819777Z",
     "iopub.status.idle": "2021-01-05T06:13:08.858524Z",
     "shell.execute_reply": "2021-01-05T06:13:08.859117Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_sample = 10000\n",
    "n_factor = 5\n",
    "n_item = 15\n",
    "n_category = 3\n",
    "nu = [-.5, .5]\n",
    "ld = .7\n",
    "rho = 0\n",
    "dtype = tf.float64\n",
    "x = generate_grm_data(n_sample, n_factor, n_item,\n",
    "                      nu, ld, rho, dtype = dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-01-05T06:13:08.867823Z",
     "iopub.status.busy": "2021-01-05T06:13:08.867141Z",
     "iopub.status.idle": "2021-01-05T06:13:08.869294Z",
     "shell.execute_reply": "2021-01-05T06:13:08.869920Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class GRM(tf.Module):\n",
    "    def __init__(self, n_item,\n",
    "                 n_factor, n_category,\n",
    "                 dtype = tf.float64):\n",
    "        super().__init__()\n",
    "        self.n_item = n_item\n",
    "        self.n_factor = n_factor\n",
    "        self.n_category = n_category\n",
    "        self.dtype = dtype\n",
    "        self.intercept = tf.Variable(\n",
    "            tf.tile(tf.sort(tf.random.uniform((1, self.n_category - 1),\n",
    "                  minval = -1, maxval = 1,\n",
    "                  dtype = self.dtype)), multiples = [self.n_item, 1]), name = \"intercept\")\n",
    "        self.loading = tf.Variable(\n",
    "            tf.random.uniform((self.n_item, self.n_factor), dtype = self.dtype),\n",
    "            name = \"loading\")\n",
    "    def __call__(self, x):\n",
    "        n_sample = len(x)\n",
    "        c, d = create_cd(self.n_category, self.dtype)\n",
    "        joint_prob = tfd.JointDistributionSequential([\n",
    "            tfd.Independent(\n",
    "                tfd.Normal(\n",
    "                    loc = tf.zeros((n_sample, n_factor), dtype=self.dtype),\n",
    "                    scale = 1.0),\n",
    "                reinterpreted_batch_ndims=1),\n",
    "            lambda eta: tfd.Independent(\n",
    "                tfd.Categorical(\n",
    "                    probs = grm_irf(eta, self.intercept, self.loading, c, d),\n",
    "                        dtype = self.dtype),\n",
    "                reinterpreted_batch_ndims=1)])\n",
    "        joint_prob._to_track=self\n",
    "        return joint_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-01-05T06:13:08.877408Z",
     "iopub.status.busy": "2021-01-05T06:13:08.874346Z",
     "iopub.status.idle": "2021-01-05T06:13:08.881258Z",
     "shell.execute_reply": "2021-01-05T06:13:08.881706Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "grm = GRM(n_item, n_factor, n_category)\n",
    "joint_prob = grm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-01-05T06:13:08.890061Z",
     "iopub.status.busy": "2021-01-05T06:13:08.889300Z",
     "iopub.status.idle": "2021-01-05T06:13:08.983116Z",
     "shell.execute_reply": "2021-01-05T06:13:08.983702Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def target_log_prob_fn(*eta):\n",
    "    return joint_prob.log_prob(eta + (x,))\n",
    "\n",
    "hmc=tfp.mcmc.HamiltonianMonteCarlo(\n",
    "    target_log_prob_fn = target_log_prob_fn,\n",
    "    step_size = .015,\n",
    "    num_leapfrog_steps=3)\n",
    "current_state = joint_prob.sample()[:-1]\n",
    "kernel_results = hmc.bootstrap_results(current_state)\n",
    "\n",
    "def one_e_step(current_state, kernel_results):\n",
    "    next_state, next_kernel_results = hmc.one_step(\n",
    "        current_state=current_state,\n",
    "        previous_kernel_results=kernel_results)\n",
    "    return next_state, next_kernel_results\n",
    "\n",
    "optimizer=tf.optimizers.RMSprop(learning_rate=.01)\n",
    "\n",
    "def one_m_step(current_state):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = -tf.reduce_mean(\n",
    "            target_log_prob_fn(*current_state))\n",
    "    gradients = tape.gradient(loss_value, grm.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, grm.trainable_variables))\n",
    "    return loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-01-05T06:13:08.991409Z",
     "iopub.status.busy": "2021-01-05T06:13:08.990688Z",
     "iopub.status.idle": "2021-01-05T06:13:09.482228Z",
     "shell.execute_reply": "2021-01-05T06:13:09.483132Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warm-Up Iteration:   0 Acceptance Rate: 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:    0 Acceptance Rate: 1.000 Loss: 29.825\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "num_warmup_start = 1\n",
    "num_warmup_iter = 1\n",
    "num_iters = 1\n",
    "num_accepted = 0\n",
    "loss_history = np.zeros([num_iters])\n",
    "tStart = time.time()\n",
    "# Run warm-up stage.\n",
    "for t in range(num_warmup_start):\n",
    "    current_state, kernel_results = one_e_step(\n",
    "        current_state, kernel_results)\n",
    "    num_accepted += kernel_results.is_accepted.numpy().prod()\n",
    "    if t % 500 == 0:\n",
    "        print(\"Warm-Up Iteration: {:>3} Acceptance Rate: {:.3f}\".format(\n",
    "            t, num_accepted / (t + 1)))\n",
    "num_accepted = 0  # reset acceptance rate counter\n",
    "\n",
    "# Run training.\n",
    "for t in range(num_iters):\n",
    "    for _ in range(num_warmup_iter):\n",
    "        current_state, kernel_results = one_e_step(current_state, kernel_results)\n",
    "    loss_value = one_m_step(current_state)\n",
    "    num_accepted += kernel_results.is_accepted.numpy().prod()\n",
    "    loss_history[t] = loss_value.numpy()\n",
    "    if t % 50 == 0:\n",
    "        print(\"Iteration: {:>4} Acceptance Rate: {:.3f} Loss: {:.3f}\".format(\n",
    "            t, num_accepted / (t + 1), loss_history[t]))\n",
    "tEnd = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-01-05T06:13:09.490815Z",
     "iopub.status.busy": "2021-01-05T06:13:09.489341Z",
     "iopub.status.idle": "2021-01-05T06:13:09.494967Z",
     "shell.execute_reply": "2021-01-05T06:13:09.495903Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48525071144104004\n",
      "[[-0.62 -0.38]\n",
      " [-0.62 -0.38]\n",
      " [-0.62 -0.38]\n",
      " [-0.62 -0.38]\n",
      " [-0.62 -0.38]\n",
      " [-0.62 -0.38]\n",
      " [-0.62 -0.38]\n",
      " [-0.62 -0.38]\n",
      " [-0.62 -0.38]\n",
      " [-0.62 -0.38]\n",
      " [-0.62 -0.38]\n",
      " [-0.62 -0.38]\n",
      " [-0.62 -0.38]\n",
      " [-0.62 -0.38]\n",
      " [-0.62 -0.38]]\n",
      "[[0.76 0.92 0.11 0.27 0.08]\n",
      " [0.85 0.13 0.85 0.31 0.09]\n",
      " [0.26 0.39 0.24 0.64 0.07]\n",
      " [0.12 0.16 0.18 0.68 0.42]\n",
      " [0.33 0.01 0.72 0.43 0.46]\n",
      " [0.46 0.31 0.82 0.77 0.54]\n",
      " [0.31 0.67 0.37 0.55 0.67]\n",
      " [0.77 0.39 0.33 0.66 0.19]\n",
      " [0.37 0.35 0.77 0.52 0.83]\n",
      " [0.33 0.77 0.81 0.77 0.26]\n",
      " [0.22 0.67 0.55 0.53 0.85]\n",
      " [0.66 0.56 0.45 0.3  0.36]\n",
      " [0.24 0.52 0.11 0.78 0.59]\n",
      " [0.55 0.94 0.8  0.38 0.76]\n",
      " [0.84 0.95 0.4  0.38 0.42]]\n"
     ]
    }
   ],
   "source": [
    "print(tEnd - tStart)\n",
    "print(np.around(grm.trainable_variables[0].numpy(), decimals=2))\n",
    "print(np.around(grm.trainable_variables[1].numpy(), decimals=2))\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "lab-tf-example.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}