{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "Lab: `pyro`簡介\n",
    "================\n",
    "在 `colab` 上，請先使用以下指定安裝 `pyro`\n",
    "\n",
    "`!pip3 install pyro-ppl`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch\n",
    "import pyro"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## `pyro` 產生隨機資料\n",
    "\n",
    "`pyro` 產生隨機資料的方式與 `torch.distribution` 很類似，但其主要透過 `pyro.sample` 進行抽樣，且每次的抽樣，都可以對該隨機變數設定一名稱。在以下的例子中，我們先後產生滿足邏輯斯迴歸架構之 `data_x` 與 `data_y`："
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "torch.manual_seed(246437)\n",
    "n_sample = 10000\n",
    "n_feature = 3\n",
    "data_x = pyro.sample(\"data_x\", pyro.distributions.MultivariateNormal(\n",
    "            loc = torch.zeros(n_sample, n_feature),\n",
    "            scale_tril = torch.eye(n_feature)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0063, 0.0103, 0.0074])\n",
      "tensor([[ 1.0085,  0.0217,  0.0029],\n",
      "        [ 0.0217,  0.9884, -0.0095],\n",
      "        [ 0.0029, -0.0095,  0.9971]])\n"
     ]
    }
   ],
   "source": [
    "mu_x = data_x.mean(axis = 0)\n",
    "sigma_x = (data_x - data_x.mean(axis = 0)).T @ (data_x - data_x.mean(axis = 0)) / n_sample\n",
    "print(mu_x)\n",
    "print(sigma_x)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "weight_true = torch.tensor([[10.], [5.], [-5.]])\n",
    "intercept_true = torch.tensor(-5.)\n",
    "data_y = pyro.sample(\"data_y\", pyro.distributions.Bernoulli(\n",
    "    logits = intercept_true + data_x @ weight_true))\n",
    "data = {\"y\":data_y, \"x\":data_x}\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## `pyro` 對邏輯斯回歸進行最大概似法估計"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "使用 `pyro` 進行最大概似法估計，最簡單的方法是透過 `pyro.infer.SVI` 此物件進行，該物件主要用於進行變分推論（variational inference），在使用 `pyro.infer.SVI` 時，使用者需設定一模型（`model`）之機率分佈，以及一指引（`guide`）之機率分佈，由於我們在這邊使用最大概似法，因此，將指引設為什麼都沒做的函數。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def model_lr(data):\n",
    "    weight = pyro.param(\"weight\", torch.zeros((3,1)))\n",
    "    intercept = pyro.param(\"intercept\", torch.zeros(()))\n",
    "    logits = intercept + data[\"x\"] @ weight\n",
    "    y = pyro.sample(\"y\", pyro.distributions.Bernoulli(logits = logits),\n",
    "                    obs = data[\"y\"])\n",
    "    return y\n",
    "\n",
    "def guide_lr(data):\n",
    "    pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "接著，我們就可以使用 `pyro.infer.SVI` 來進行優化。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter 0]  loss: 6931.4731\n",
      "[iter 50]  loss: 984.7116\n",
      "[iter 100]  loss: 969.8328\n",
      "[iter 150]  loss: 967.9623\n",
      "[iter 200]  loss: 967.8027\n"
     ]
    }
   ],
   "source": [
    "lr = 50. / n_sample\n",
    "n_steps = 201\n",
    "\n",
    "pyro.clear_param_store()\n",
    "optimizer = pyro.optim.SGD({\"lr\": lr})\n",
    "svi = pyro.infer.SVI(model_lr, guide_lr, optimizer,\n",
    "                     loss=pyro.infer.Trace_ELBO())\n",
    "\n",
    "for step in range(n_steps):\n",
    "    loss = svi.step(data)\n",
    "    if step % 50 == 0:\n",
    "        print('[iter {}]  loss: {:.4f}'.format(step, loss))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight\n",
      "intercept\n",
      "tensor([[10.1213],\n",
      "        [ 5.0705],\n",
      "        [-5.0297]], requires_grad=True)\n",
      "tensor(-5.0715, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for name in pyro.get_param_store():\n",
    "    print(name)\n",
    "\n",
    "print(pyro.param(\"weight\"))\n",
    "print(pyro.param(\"intercept\"))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## `pyro` 對因素分析模型進行最大概似法估計\n",
    "以下程式碼用於產生因素分析之資料"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_fa_model(n_factor, n_item, ld, psi = None, rho = None):\n",
    "    if (n_item % n_factor) != 0:\n",
    "        n_item = n_factor * (n_item // n_factor)\n",
    "    loading = torch.zeros((n_item, n_factor))\n",
    "    item_per_factor = (n_item // n_factor)\n",
    "    for i in range(n_factor):\n",
    "        for j in range(i * item_per_factor,\n",
    "                       (i + 1) * item_per_factor):\n",
    "            loading[j, i] = ld\n",
    "    if rho is None:\n",
    "        cor = torch.eye(n_factor)\n",
    "    else:\n",
    "        unit = torch.ones((n_factor, 1))\n",
    "        identity = torch.eye(n_factor)\n",
    "        cor = rho * (unit @ unit.T) + (1 - rho) * identity\n",
    "    if psi is None:\n",
    "        uniqueness = 1 - torch.diagonal(loading @ cor @ loading.T)\n",
    "    else:\n",
    "        uniqueness = psi * torch.ones((n_item, ))\n",
    "    return loading, uniqueness, cor\n",
    "\n",
    "def generate_fa_data(n_sample, loading, uniqueness, cor):\n",
    "    n_item = loading.size()[0]\n",
    "    mean = torch.zeros((n_item, ))\n",
    "    cov = loading @ cor @ loading.T + torch.diag_embed(uniqueness)\n",
    "    mvn = torch.distributions.MultivariateNormal(\n",
    "        loc = mean, scale_tril = torch.cholesky(cov))\n",
    "    data = mvn.sample((n_sample,))\n",
    "    return data\n",
    "\n",
    "torch.manual_seed(246437)\n",
    "n_factor = 4\n",
    "n_item = 12\n",
    "n_sample = 10000\n",
    "loading_true, uniqueness_true, cor_true = create_fa_model(n_factor, n_item, ld = .7)\n",
    "data = generate_fa_data(n_sample,\n",
    "                        loading = loading_true,\n",
    "                        uniqueness = uniqueness_true,\n",
    "                        cor = cor_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "接著，我們設定觀察變項之邊際分佈。這邊，我們在模型設定時，使用了 `pyro.plate` 來進行重複之設定。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def model_fa(data):\n",
    "    loading = pyro.param(\"loading\", 0.5 * loading_true)\n",
    "    uniqueness = pyro.param(\"uniqueness\", 0.5 * uniqueness_true)\n",
    "    loading_mask = 1 *  (loading_true != 0)\n",
    "    with pyro.plate(\"data\", data.size(0)):\n",
    "        pyro.sample(\"x\", pyro.distributions.MultivariateNormal(\n",
    "            loc = torch.zeros((loading.size()[0], )),\n",
    "            scale_tril = torch.cholesky(\n",
    "                (loading * loading_mask) @ (loading * loading_mask).T + torch.diag_embed(uniqueness))),\n",
    "            obs=data)\n",
    "\n",
    "def guide_fa(data):\n",
    "    pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter 0]  loss: 189637.8906\n",
      "[iter 50]  loss: 156899.3438\n",
      "[iter 100]  loss: 156943.4688\n",
      "[iter 150]  loss: 156944.6719\n",
      "[iter 200]  loss: 156944.6719\n"
     ]
    }
   ],
   "source": [
    "lr = 1. / n_sample\n",
    "n_steps = 201\n",
    "pyro.clear_param_store()\n",
    "optimizer = pyro.optim.SGD({\"lr\": lr})\n",
    "svi = pyro.infer.SVI(model_fa, guide_fa, optimizer, loss=pyro.infer.Trace_ELBO())\n",
    "\n",
    "for step in range(n_steps):\n",
    "    loss = svi.step(data)\n",
    "    if step % 50 == 0:\n",
    "        print('[iter {}]  loss: {:.4f}'.format(step, loss))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6992, 0.0000, 0.0000, 0.0000],\n",
      "        [0.6954, 0.0000, 0.0000, 0.0000],\n",
      "        [0.6993, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.7133, 0.0000, 0.0000],\n",
      "        [0.0000, 0.7040, 0.0000, 0.0000],\n",
      "        [0.0000, 0.7090, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.7618, 0.0000],\n",
      "        [0.0000, 0.0000, 0.6650, 0.0000],\n",
      "        [0.0000, 0.0000, 0.6700, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.6963],\n",
      "        [0.0000, 0.0000, 0.0000, 0.7116],\n",
      "        [0.0000, 0.0000, 0.0000, 0.7105]], requires_grad=True)\n",
      "tensor([0.5055, 0.5043, 0.5135, 0.5078, 0.5059, 0.5122, 0.5224, 0.5030, 0.5064,\n",
      "        0.5262, 0.4993, 0.5094], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(pyro.param(\"loading\"))\n",
    "print(pyro.param(\"uniqueness\"))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "前述設定的模型中，我們在設定模型與指引時，皆直接將樣本資料視為函數的輸入，事實上，此給定的動作可以事後在使用 `pyro.poutine.condition` 進行。\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def model_fa():\n",
    "    loading = pyro.param(\"loading\", 0.5 * loading_true)\n",
    "    uniqueness = pyro.param(\"uniqueness\", 0.5 * uniqueness_true)\n",
    "    loading_mask = 1 *  (loading_true != 0)\n",
    "    with pyro.plate(\"data\", data.size(0)):\n",
    "        pyro.sample(\"x\", pyro.distributions.MultivariateNormal(\n",
    "            loc = torch.zeros((loading.size()[0], )),\n",
    "            scale_tril = torch.cholesky(\n",
    "                (loading * loading_mask) @ (loading * loading_mask).T + torch.diag_embed(uniqueness))))\n",
    "\n",
    "def guide_fa():\n",
    "    pass\n",
    "\n",
    "\n",
    "model_fa_cond = pyro.poutine.condition(model_fa, data={\"x\": data})\n",
    "guide_fa_cond = pyro.poutine.condition(guide_fa, data={\"x\": data})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "接著，我們可以把 `model_fa_cond` 與 `guide_fa_cond` 丟到 `pyro.infer.SVI` 進行優化。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter 0]  loss: 189637.8906\n",
      "[iter 50]  loss: 156899.3438\n",
      "[iter 100]  loss: 156943.4688\n",
      "[iter 150]  loss: 156944.6719\n",
      "[iter 200]  loss: 156944.6719\n"
     ]
    }
   ],
   "source": [
    "lr = 1. / n_sample\n",
    "n_steps = 201\n",
    "pyro.clear_param_store()\n",
    "optimizer = pyro.optim.SGD({\"lr\": lr})\n",
    "svi = pyro.infer.SVI(model_fa_cond, guide_fa_cond, optimizer, loss=pyro.infer.Trace_ELBO())\n",
    "\n",
    "for step in range(n_steps):\n",
    "    loss = svi.step()\n",
    "    if step % 50 == 0:\n",
    "        print('[iter {}]  loss: {:.4f}'.format(step, loss))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6992, 0.0000, 0.0000, 0.0000],\n",
      "        [0.6954, 0.0000, 0.0000, 0.0000],\n",
      "        [0.6993, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.7133, 0.0000, 0.0000],\n",
      "        [0.0000, 0.7040, 0.0000, 0.0000],\n",
      "        [0.0000, 0.7090, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.7618, 0.0000],\n",
      "        [0.0000, 0.0000, 0.6650, 0.0000],\n",
      "        [0.0000, 0.0000, 0.6700, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.6963],\n",
      "        [0.0000, 0.0000, 0.0000, 0.7116],\n",
      "        [0.0000, 0.0000, 0.0000, 0.7105]], requires_grad=True)\n",
      "tensor([0.5055, 0.5043, 0.5135, 0.5078, 0.5059, 0.5122, 0.5224, 0.5030, 0.5064,\n",
      "        0.5262, 0.4993, 0.5094], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(pyro.param(\"loading\"))\n",
    "print(pyro.param(\"uniqueness\"))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 利用隨機 EM 進行最大概似法"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def joint_model():\n",
    "    loading = pyro.param(\"loading\", 0.7 * loading_true)\n",
    "    uniqueness = pyro.param(\"uniqueness\", 0.7 * uniqueness_true)\n",
    "    loading_mask = 1 *  (loading_true != 0)\n",
    "    with pyro.plate(\"sample_plate\", n_sample):\n",
    "        eta = pyro.sample(\"eta\", pyro.distributions.MultivariateNormal(\n",
    "            loc = torch.zeros(n_factor),\n",
    "            scale_tril = torch.eye(n_factor)))\n",
    "        x = pyro.sample(\"x\", pyro.distributions.MultivariateNormal(\n",
    "                loc = eta @ (loading * loading_mask).T,\n",
    "                scale_tril = torch.cholesky(torch.diag(uniqueness))))\n",
    "    return x\n",
    "\n",
    "def joint_guide():\n",
    "    pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 21/21 [00:05,  4.06it/s, step size=6.11e-01, acc. prob=0.182]\n",
      "Sample: 100%|██████████| 21/21 [00:12,  1.63it/s, step size=1.16e+00, acc. prob=0.000]\n",
      "Sample: 100%|██████████| 21/21 [00:05,  3.93it/s, step size=1.09e+00, acc. prob=0.000]\n",
      "Sample: 100%|██████████| 21/21 [00:05,  3.50it/s, step size=5.61e-01, acc. prob=0.262]\n",
      "Sample: 100%|██████████| 21/21 [00:05,  3.51it/s, step size=8.48e-01, acc. prob=0.286]\n",
      "Sample: 100%|██████████| 21/21 [00:05,  3.90it/s, step size=7.55e-01, acc. prob=0.286]\n",
      "Sample: 100%|██████████| 21/21 [00:07,  2.97it/s, step size=9.04e-01, acc. prob=0.000]\n",
      "Sample: 100%|██████████| 21/21 [00:07,  2.94it/s, step size=6.45e-01, acc. prob=0.143]\n",
      "Sample: 100%|██████████| 21/21 [00:05,  3.72it/s, step size=5.67e-01, acc. prob=0.286]\n",
      "Sample: 100%|██████████| 21/21 [00:05,  4.19it/s, step size=8.66e-01, acc. prob=0.000]\n",
      "Sample: 100%|██████████| 21/21 [00:04,  4.80it/s, step size=5.73e-01, acc. prob=0.429]\n",
      "Sample: 100%|██████████| 21/21 [00:08,  2.38it/s, step size=6.52e-01, acc. prob=0.571]\n",
      "Sample: 100%|██████████| 21/21 [00:05,  3.54it/s, step size=8.03e-01, acc. prob=0.000]\n",
      "Sample: 100%|██████████| 21/21 [00:07,  2.88it/s, step size=4.83e-01, acc. prob=0.152]\n",
      "Sample: 100%|██████████| 21/21 [00:05,  3.90it/s, step size=7.79e-01, acc. prob=0.143]\n",
      "Sample: 100%|██████████| 21/21 [00:06,  3.20it/s, step size=6.14e-01, acc. prob=0.326]\n",
      "Sample: 100%|██████████| 21/21 [00:06,  3.46it/s, step size=1.09e+00, acc. prob=0.000]\n",
      "Sample: 100%|██████████| 21/21 [00:13,  1.57it/s, step size=9.61e-01, acc. prob=0.000]\n",
      "Sample: 100%|██████████| 21/21 [00:07,  2.86it/s, step size=9.20e-01, acc. prob=0.000]\n",
      "Sample: 100%|██████████| 21/21 [00:06,  3.50it/s, step size=1.14e+00, acc. prob=0.000]\n",
      "Sample: 100%|██████████| 21/21 [00:05,  3.62it/s, step size=5.28e-01, acc. prob=0.136]\n",
      "Sample: 100%|██████████| 21/21 [00:05,  3.77it/s, step size=8.98e-01, acc. prob=0.000]\n",
      "Sample: 100%|██████████| 21/21 [00:13,  1.53it/s, step size=6.37e-01, acc. prob=0.286]\n",
      "Sample: 100%|██████████| 21/21 [00:05,  3.96it/s, step size=5.23e-01, acc. prob=0.067]\n",
      "Sample: 100%|██████████| 21/21 [00:14,  1.48it/s, step size=8.63e-01, acc. prob=0.000]\n",
      "Sample: 100%|██████████| 21/21 [00:06,  3.27it/s, step size=9.68e-01, acc. prob=0.000]\n",
      "Sample: 100%|██████████| 21/21 [00:06,  3.27it/s, step size=4.94e-01, acc. prob=0.067]\n",
      "Sample: 100%|██████████| 21/21 [00:05,  3.67it/s, step size=1.13e+00, acc. prob=0.000]\n",
      "Sample: 100%|██████████| 21/21 [00:06,  3.50it/s, step size=6.92e-01, acc. prob=0.143]\n",
      "Sample: 100%|██████████| 21/21 [00:09,  2.12it/s, step size=8.17e-01, acc. prob=0.000]\n",
      "Sample: 100%|██████████| 21/21 [00:05,  3.52it/s, step size=8.26e-01, acc. prob=0.000]\n",
      "Sample: 100%|██████████| 21/21 [00:05,  3.51it/s, step size=7.44e-01, acc. prob=0.286]\n",
      "Sample: 100%|██████████| 21/21 [00:05,  3.78it/s, step size=6.77e-01, acc. prob=0.714]\n",
      "Sample: 100%|██████████| 21/21 [00:06,  3.40it/s, step size=9.23e-01, acc. prob=0.000]\n",
      "Sample: 100%|██████████| 21/21 [00:05,  3.63it/s, step size=1.01e+00, acc. prob=0.000]\n",
      "Sample: 100%|██████████| 21/21 [00:05,  3.69it/s, step size=6.26e-01, acc. prob=0.145]\n",
      "Sample: 100%|██████████| 21/21 [00:05,  3.59it/s, step size=6.90e-01, acc. prob=0.288]\n",
      "Sample: 100%|██████████| 21/21 [00:14,  1.47it/s, step size=4.81e-01, acc. prob=0.134]\n",
      "Sample: 100%|██████████| 21/21 [00:04,  4.69it/s, step size=5.88e-01, acc. prob=0.204]\n",
      "Sample: 100%|██████████| 21/21 [00:09,  2.22it/s, step size=6.28e-01, acc. prob=0.571]\n",
      "Sample: 100%|██████████| 21/21 [00:06,  3.47it/s, step size=1.08e+00, acc. prob=0.000]\n",
      "Sample: 100%|██████████| 21/21 [00:05,  3.61it/s, step size=5.75e-01, acc. prob=0.446]\n",
      "Sample: 100%|██████████| 21/21 [00:07,  2.93it/s, step size=6.57e-01, acc. prob=0.572]\n",
      "Sample: 100%|██████████| 21/21 [00:07,  2.71it/s, step size=1.10e+00, acc. prob=0.000]\n",
      "Sample: 100%|██████████| 21/21 [00:06,  3.32it/s, step size=7.65e-01, acc. prob=0.173]\n",
      "Sample: 100%|██████████| 21/21 [00:14,  1.48it/s, step size=4.76e-01, acc. prob=0.290]\n",
      "Sample: 100%|██████████| 21/21 [00:06,  3.41it/s, step size=5.56e-01, acc. prob=0.000]\n",
      "Sample: 100%|██████████| 21/21 [00:04,  4.26it/s, step size=7.14e-01, acc. prob=0.143]\n",
      "Sample: 100%|██████████| 21/21 [00:08,  2.46it/s, step size=9.73e-01, acc. prob=0.000]\n",
      "Sample: 100%|██████████| 21/21 [00:06,  3.11it/s, step size=5.07e-01, acc. prob=0.455]\n",
      "Sample: 100%|██████████| 21/21 [00:06,  3.43it/s, step size=6.92e-01, acc. prob=0.667]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter 0]  loss: 198613.4375\n",
      "[iter 5]  loss: 189835.7930\n",
      "[iter 10]  loss: 189176.4883\n",
      "[iter 15]  loss: 187921.0781\n",
      "[iter 20]  loss: 187489.3555\n",
      "[iter 25]  loss: 187088.7109\n",
      "[iter 30]  loss: 186847.2148\n",
      "[iter 35]  loss: 186926.2734\n",
      "[iter 40]  loss: 186526.2617\n",
      "[iter 45]  loss: 186567.5039\n",
      "[iter 50]  loss: 185957.7930\n"
     ]
    }
   ],
   "source": [
    "lr = .1 / n_sample\n",
    "n_steps = 51\n",
    "pyro.clear_param_store()\n",
    "\n",
    "\n",
    "for step in range(n_steps):\n",
    "    model_cond_x = pyro.poutine.condition(joint_model, data = {\"x\": data})\n",
    "    nuts_kernel = pyro.infer.NUTS(model_cond_x)\n",
    "    mcmc = pyro.infer.MCMC(nuts_kernel, num_samples=1, warmup_steps = 20)\n",
    "    mcmc.run()\n",
    "    eta = mcmc.get_samples()[\"eta\"].reshape((-1, 4))\n",
    "    model_cond_x_eta = pyro.poutine.condition(joint_model,\n",
    "                                              data = {\"x\": data,\n",
    "                                            \"eta\":eta})\n",
    "    guide_cond_x_eta = pyro.poutine.condition(joint_guide,\n",
    "                                              data = {\"x\": data,\n",
    "                                            \"eta\":eta})\n",
    "    optimizer = pyro.optim.SGD({\"lr\": lr})\n",
    "    svi = pyro.infer.SVI(model_cond_x_eta,\n",
    "                         guide_cond_x_eta,\n",
    "                         optimizer,\n",
    "                         loss=pyro.infer.Trace_ELBO())\n",
    "    loss = svi.step()\n",
    "    if step % 5 == 0:\n",
    "        print('[iter {}]  loss: {:.4f}'.format(step, loss))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6921, 0.0000, 0.0000, 0.0000],\n",
      "        [0.6881, 0.0000, 0.0000, 0.0000],\n",
      "        [0.6977, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.7109, 0.0000, 0.0000],\n",
      "        [0.0000, 0.6946, 0.0000, 0.0000],\n",
      "        [0.0000, 0.7025, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.7030, 0.0000],\n",
      "        [0.0000, 0.0000, 0.6777, 0.0000],\n",
      "        [0.0000, 0.0000, 0.6792, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.6893],\n",
      "        [0.0000, 0.0000, 0.0000, 0.7036],\n",
      "        [0.0000, 0.0000, 0.0000, 0.7068]], requires_grad=True)\n",
      "tensor([0.5105, 0.5096, 0.5107, 0.5041, 0.5122, 0.5144, 0.4749, 0.5175, 0.5219,\n",
      "        0.5299, 0.5044, 0.5082], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(pyro.param(\"loading\"))\n",
    "print(pyro.param(\"uniqueness\"))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}