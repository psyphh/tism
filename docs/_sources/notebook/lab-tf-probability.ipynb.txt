{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "name": "lab-probability.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "dw_zvvIwcvxG",
    "colab_type": "text"
   },
   "source": [
    "\n",
    "Lab III: 機率模型\n",
    "================\n",
    "此 lab 中，我們將會透過 `tensorflow-probability`（TFP）此套件，學習以下的主題。\n",
    "\n",
    "1. 認識 TFP 的分配（distribution）物件。\n",
    "\n",
    "2. 利用變項之分配，搭配自動微分獲與優化器獲得最大概似估計值。\n",
    "\n",
    "3. 了解如何將個別變項之分配物件組成聯合分配，建立複雜的機率模型。\n",
    "\n",
    "4. 應用前述之知識，建立一可進行廣義線性模型分析之類型（class）。\n",
    "\n",
    "TFP 之安裝與基礎教學，可參考 [TFP官方網頁](https://www.tensorflow.org/probability/install)。在安裝完成後，可透過以下的指令載入其與 `tensorflow`"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "7P6EpAcIcvxI",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "import tensorflow_probability as tfp\n",
    "import tensorflow as tf"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "16pj-OeWcvxM",
    "colab_type": "text"
   },
   "source": [
    "## 分配物件\n",
    "TFP 最為核心的物件為分配物件，其用於表徵一機率分配。TFP 涵蓋了許多不同的機率分配，其名單可至 [官方網頁](https://www.tensorflow.org/probability/api_docs/python/tfp/distributions) 查看。\n",
    "\n",
    "在實務上，我們常將 TFP 的分配模組儲存為 `tfd`，以便於使用，即："
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "soPSsBtfcvxN",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "tfd = tfp.distributions"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "hDHBLSrhcvxQ",
    "colab_type": "text"
   },
   "source": [
    "### 分配物件之基本操作\n",
    "\n",
    "以常態分配為例，我們可透過以下程式碼產生一表徵常態分配之物件，其平均數為0，標準差為1（尾端的小數點表示浮點數，而非整數）："
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "wB8BZgYwcvxQ",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "normal = tfd.Normal(loc=0., scale=1.)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "bDJn1AtRcvxT",
    "colab_type": "text"
   },
   "source": [
    "透過此分配物件，我們可以產生對應之隨機樣本"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "sCxas-XwcvxT",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 158
    },
    "outputId": "7998aef4-86a1-4742-e8eb-3f16a4c620ef"
   },
   "source": [
    "print(\"random sample with shape ():\\n\",\n",
    "      normal.sample())\n",
    "print(\"random sample with shape (3,):\\n\",\n",
    "      normal.sample(sample_shape=3))\n",
    "print(\"random sample with shape (2,3):\\n\",\n",
    "      normal.sample(sample_shape=(2, 3)))"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "random sample with shape ():\n",
      " tf.Tensor(-2.7912834, shape=(), dtype=float32)\n",
      "random sample with shape (3,):\n",
      " tf.Tensor([ 0.5577405  -0.2154798  -0.38732323], shape=(3,), dtype=float32)\n",
      "random sample with shape (2,3):\n",
      " tf.Tensor(\n",
      "[[-0.36690155  0.3595907  -0.21797796]\n",
      " [-0.15589115  0.8745968  -2.168889  ]], shape=(2, 3), dtype=float32)\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "uvFzPPERcvxX",
    "colab_type": "text"
   },
   "source": [
    "我們亦可給定實現值來評估其在該分配下之累積機率值："
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "LfdFM8i7cvxX",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "outputId": "e9f5e48c-db6b-4ee1-b06f-97f35319be30"
   },
   "source": [
    "print(\"cumulative probability given value with shape ():\\n\",\n",
    "      normal.cdf(value=0), \"\\n\")\n",
    "print(\"cumulative probability given value with (3,):\\n\",\n",
    "      normal.cdf(value=[-1, 0, .5]), \"\\n\")\n",
    "print(\"cumulative probability given value with (2,3):\\n\",\n",
    "      normal.cdf(value=[[-1, 0, .5], [-2, 1, 3]]))\n"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "cumulative probability given value with shape ():\n",
      " tf.Tensor(0.5, shape=(), dtype=float32) \n",
      "\n",
      "cumulative probability given value with (3,):\n",
      " tf.Tensor([0.15865526 0.5        0.69146246], shape=(3,), dtype=float32) \n",
      "\n",
      "cumulative probability given value with (2,3):\n",
      " tf.Tensor(\n",
      "[[0.15865526 0.5        0.69146246]\n",
      " [0.02275014 0.8413447  0.9986501 ]], shape=(2, 3), dtype=float32)\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "A7lMewP6cvxa",
    "colab_type": "text"
   },
   "source": [
    "或是對數機率值："
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "eUx3vyN7cvxb",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "outputId": "a988b1e4-fe00-4cd6-d7ec-efcf8d41a692"
   },
   "source": [
    "print(\"log-probability given value with shape ():\\n\",\n",
    "      normal.log_prob(value=0), \"\\n\")\n",
    "print(\"log-probability given value with (3,):\\n\",\n",
    "      normal.log_prob(value=[-1, 0, .5]), \"\\n\")\n",
    "print(\"log-probability given value with (2,3):\\n\",\n",
    "      normal.log_prob(value=[[-1, 0, .5], [-2, 1, 3]]))"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "log-probability given value with shape ():\n",
      " tf.Tensor(-0.9189385, shape=(), dtype=float32) \n",
      "\n",
      "log-probability given value with (3,):\n",
      " tf.Tensor([-1.4189385 -0.9189385 -1.0439385], shape=(3,), dtype=float32) \n",
      "\n",
      "log-probability given value with (2,3):\n",
      " tf.Tensor(\n",
      "[[-1.4189385 -0.9189385 -1.0439385]\n",
      " [-2.9189386 -1.4189385 -5.4189386]], shape=(2, 3), dtype=float32)\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "WgQ5DRsMcvxe",
    "colab_type": "text"
   },
   "source": [
    "### 分配物件之形狀\n",
    "分配物件的形狀比起張量的形狀較為複雜些，其產生的樣本共牽涉到三種形狀：\n",
    "\n",
    "1. 樣本形狀（sample shape），為在使用分配物件產生樣本時之形狀（即為前一小節使用 `.sample()` 時所設定的 `sample_shape`），其產生的資料彼此間為獨立且相同分配的（independent and identically distributed）。\n",
    "\n",
    "2. 批次形狀（batch shape），為建立分配物件時所設定的形狀（其透過參數的形狀決定），其可用於產生批次的樣本，批次樣本間彼此獨立，但其邊際分配之參數可以不同。\n",
    "\n",
    "3. 事件形狀（event shape），即多變量分配之變數形狀，如 $P$ 維多元常態分配的形狀即為 `(P,)`，在同一事件下產生的資料其變數間可為相依，且各邊際分配之參數也未必相同。\n",
    "\n",
    "而分配物件的形狀則牽涉到批次與事件兩種，可透過直接列印分配物件查看"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "lbz_r5_6cvxe",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "outputId": "dcb4e7d3-19dd-440f-8a6a-a406339a1eb0"
   },
   "source": [
    "print(normal)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "tfp.distributions.Normal(\"Normal\", batch_shape=[], event_shape=[], dtype=float32)\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "7k5_5Whkcvxh",
    "colab_type": "text"
   },
   "source": [
    "或是使用 `.batch_shape` 與 `.event_shape` 獲得："
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "zi9Xi80Bcvxh",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "outputId": "2431a2fb-1086-4150-fc71-b82e6f764327"
   },
   "source": [
    "print(normal.batch_shape)\n",
    "print(normal.event_shape)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "()\n",
      "()\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "0H3ED4Iscvxk",
    "colab_type": "text"
   },
   "source": [
    "由於之前所創立的 `normal` 其用於產生純量之常態分配隨機變數，故 `.batch_shape` 與 `.event_shape` 兩者皆為 `()`。\n",
    "\n",
    "批次形狀之設定，乃經由對分配參數形狀之推論獲得，如"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "zs7R4c4vcvxk",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "outputId": "302adb10-46b7-4a89-c409-c0f4d4adc195"
   },
   "source": [
    "normal_batch = tfd.Normal(loc=[0., 1.], scale=[1., .5])\n",
    "print(normal_batch)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "tfp.distributions.Normal(\"Normal\", batch_shape=[2], event_shape=[], dtype=float32)\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "w2Rf56rdcvxn",
    "colab_type": "text"
   },
   "source": [
    "前述分配的 `batch_shape` 為 `(2,)`，其可用於產生一組兩個來自常態分配之變數，其中一個平均數為0，變異數為1，另一個平均數為1，變異數為.5，如"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "DCDP4E6jcvxn",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "outputId": "62a52567-6e86-4314-ebd0-0fe5013efffb"
   },
   "source": [
    "print(\"random sample with sample_shape ():\\n\",\n",
    "      normal_batch.sample(), \"\\n\")\n",
    "print(\"random sample with sample_shape (3,):\\n\",\n",
    "      normal_batch.sample(sample_shape=3), \"\\n\")\n",
    "print(\"random sample with sample_shape (2,3):\\n\",\n",
    "      normal_batch.sample(sample_shape=(2,3)))"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "random sample with sample_shape ():\n",
      " tf.Tensor([0.29028732 0.7905031 ], shape=(2,), dtype=float32) \n",
      "\n",
      "random sample with sample_shape (3,):\n",
      " tf.Tensor(\n",
      "[[0.15522027 1.4582996 ]\n",
      " [0.08955304 0.751514  ]\n",
      " [0.5428438  0.72968256]], shape=(3, 2), dtype=float32) \n",
      "\n",
      "random sample with sample_shape (2,3):\n",
      " tf.Tensor(\n",
      "[[[ 0.787189    1.3647287 ]\n",
      "  [-0.41794905  0.7215868 ]\n",
      "  [ 1.7801639   1.3271374 ]]\n",
      "\n",
      " [[ 1.2106053   2.0987782 ]\n",
      "  [ 0.2064828   1.8680563 ]\n",
      "  [-0.4260123   1.0204298 ]]], shape=(2, 3, 2), dtype=float32)\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "UAY45NsFcvxq",
    "colab_type": "text"
   },
   "source": [
    "我們亦可使用所創立的 `normal_batch` 來度量輸入數值的對數機率值："
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "Bu1mmQqqcvxr",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "outputId": "dc1a0ef5-17b2-42e0-a8fb-1882003d80f0"
   },
   "source": [
    "print(\"log-probability given value with shape ():\\n\",\n",
    "      normal_batch.log_prob(0), \"\\n\")\n",
    "print(\"log-probability given value with shape (2,):\\n\",\n",
    "      normal_batch.log_prob([0, 0]), \"\\n\")\n",
    "print(\"log-probability given value with shape (2,1):\\n\",\n",
    "      normal_batch.log_prob([[0], [0]]))"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "log-probability given value with shape ():\n",
      " tf.Tensor([-0.9189385 -2.2257915], shape=(2,), dtype=float32) \n",
      "\n",
      "log-probability given value with shape (2,):\n",
      " tf.Tensor([-0.9189385 -2.2257915], shape=(2,), dtype=float32) \n",
      "\n",
      "log-probability given value with shape (2,1):\n",
      " tf.Tensor(\n",
      "[[-0.9189385 -2.2257915]\n",
      " [-0.9189385 -2.2257915]], shape=(2, 2), dtype=float32)\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "bcdAX1H-cvxt",
    "colab_type": "text"
   },
   "source": [
    "這邊我們可以觀察到，前兩者種寫法獲得一樣的數值，皆表示 `[0, 0]` 此向量於 `normal_batch` 下的對數機率。對第一種寫法來說，其輸入為純量，因此，使用到了廣播（broadcasting）的概念，將0的數值轉為 `[0,0]` 後再進行評估，第二種寫法則是較為標準，其直接輸入了 `[0,0]`，與 `normal_batch` 的 `batch_size` 相同。而第三種寫法，可以想成輸入了一 `sample_shape` 為2的資料，而每筆觀測值的0皆會透過廣播拓展為 `[0, 0]`，故回傳了每筆觀測值於 `normal_batch` 之對數機率。\n",
    "\n",
    "\n",
    "事件形狀僅適用於多變量之分配，以多元常態（multivariate normal）分配為例，其需給定一平均數向量與共變異數矩陣（在這邊，我們採用的 `tfd.MultivariateNormalTriL` 需給定的是共變異數矩陣的 Cholesky 分解）："
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "QS0enb2Acvxu",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "outputId": "3bd32b6c-4dff-4cb7-d006-590f8b8c1c74"
   },
   "source": [
    "mvn = tfd.MultivariateNormalTriL(\n",
    "    loc=[0, 1],\n",
    "    scale_tril=tf.linalg.cholesky([[1., 0.], [0., .5]]))\n",
    "print(mvn)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "tfp.distributions.MultivariateNormalTriL(\"MultivariateNormalTriL\", batch_shape=[], event_shape=[2], dtype=float32)\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "9miRrz-jcvxx",
    "colab_type": "text"
   },
   "source": [
    "我們可看到此分配物件的 `event_shape` 是 `(2)`，與此多元常態分配的維度相同，其可用於產生服從多元常態分配之資料"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "eq9IVXCTcvxx",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "outputId": "06354dc4-57ec-4b8d-90c4-ec5c0c41e00e"
   },
   "source": [
    "print(\"random sample with sample_shape ():\\n\",\n",
    "      mvn.sample(), \"\\n\")\n",
    "print(\"random sample with sample_shape (3,):\\n\",\n",
    "      mvn.sample(sample_shape=3), \"\\n\")\n",
    "print(\"random sample with sample_shape (2, 3):\\n\",\n",
    "      mvn.sample(sample_shape=(2, 3)))"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "random sample with sample_shape ():\n",
      " tf.Tensor([0.15292141 1.0594724 ], shape=(2,), dtype=float32) \n",
      "\n",
      "random sample with sample_shape (3,):\n",
      " tf.Tensor(\n",
      "[[ 0.7902455  1.3362037]\n",
      " [-1.4024737  1.4180405]\n",
      " [ 1.2346311  1.0128245]], shape=(3, 2), dtype=float32) \n",
      "\n",
      "random sample with sample_shape (2, 3):\n",
      " tf.Tensor(\n",
      "[[[-0.16803913  0.5900997 ]\n",
      "  [-0.5699143  -0.16766071]\n",
      "  [ 0.50984067  1.3133254 ]]\n",
      "\n",
      " [[ 1.1781791   1.0821702 ]\n",
      "  [-0.03046008  1.9608397 ]\n",
      "  [ 0.45752838  1.0393455 ]]], shape=(2, 3, 2), dtype=float32)\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "AWf4QF3tcvx0",
    "colab_type": "text"
   },
   "source": [
    "同樣的，該物件亦可用於評估給定數值下的對數機率："
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "KlKkABhXcvx1",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "outputId": "c48d24e6-e621-4e06-802e-cb1a26486d25"
   },
   "source": [
    "print(\"log-probability given value with shape (2,):\\n\",\n",
    "      mvn.log_prob([0, 0]), \"\\n\")\n",
    "print(\"log-probability given value with shape (2,1):\\n\",\n",
    "      mvn.log_prob([[0, 0], [0, 0]]))"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "log-probability given value with shape (2,):\n",
      " tf.Tensor(-2.4913034, shape=(), dtype=float32) \n",
      "\n",
      "log-probability given value with shape (2,1):\n",
      " tf.Tensor([-2.4913034 -2.4913034], shape=(2,), dtype=float32)\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "WZkJAJXNcvx3",
    "colab_type": "text"
   },
   "source": [
    "儘管此 `mvn` 表徵的二維之多元常態分配，其平均數與共變異數矩陣之設定，與先前 `normal_batch`是等價的，但在使用 `mvn` 評估機率時，需注意：（1）先前針對 `batch_shape` 此面向的廣播，不再適用於 `event_shape`，故 `mvn.log_prob(0)` 會產生錯誤訊息；（2）針對每筆觀測值，其計算的是在此多元常態分配下的聯合機率，因此，只會獲得一個對數機率值。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "yrFwsZ3dcvx4",
    "colab_type": "text"
   },
   "source": [
    "分配物件的 `batch_shape` 可透過 `tfd.Independent` 此物件轉為 `event_shape`，如"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "7opzhoUBcvx4",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "outputId": "58d8ff42-9ac9-43ed-ba9c-7bd1cd207210"
   },
   "source": [
    "tfd.Independent(normal_batch, reinterpreted_batch_ndims=1)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tfp.distributions.Independent 'IndependentNormal' batch_shape=[] event_shape=[2] dtype=float32>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 46
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "lpeaHvHscvx-",
    "colab_type": "text"
   },
   "source": [
    "在多變量的分配之下，前述介紹的批次形狀與事件形狀，可以合併使用："
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "MuJW9ohAcvx-",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "outputId": "8bc7ebd1-ebd1-40e7-a3a0-7cc9be4cffb2"
   },
   "source": [
    "mvn_batch = tfd.MultivariateNormalTriL(\n",
    "    loc=[[0, 1],\n",
    "         [1, 2],\n",
    "         [2, 3]],\n",
    "    scale_tril=tf.linalg.cholesky([[1., 0.], [0., .5]]))\n",
    "mvn_batch"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tfp.distributions.MultivariateNormalTriL 'MultivariateNormalTriL' batch_shape=[3] event_shape=[2] dtype=float32>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 47
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "IvwYBO60cvyA",
    "colab_type": "text"
   },
   "source": [
    "這裡，其 `batch_shape` 為 `(3)`，值得注意的是，這邊我們僅設定了一個共變異數矩陣，因此，其會透過廣播的機制，與三個平均數向量做對應。同樣的，我們可以用此 `mvn_batch` 來產生樣本資料\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "N8qw6R_pcvyB",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 826
    },
    "outputId": "7064662a-5f23-4bdc-acaf-3f8e3bc8f481"
   },
   "source": [
    "print(\"random sample with sample_shape ():\\n\",\n",
    "      mvn_batch.sample(), \"\\n\")\n",
    "print(\"random sample with sample_shape (3,):\\n\",\n",
    "      mvn_batch.sample(sample_shape=3), \"\\n\")\n",
    "print(\"random sample with sample_shape (2, 3):\\n\",\n",
    "      mvn_batch.sample(sample_shape=(2, 3)))"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "random sample with sample_shape ():\n",
      " tf.Tensor(\n",
      "[[0.5160964 0.8165519]\n",
      " [1.7593596 1.1226768]\n",
      " [2.9044368 3.7782211]], shape=(3, 2), dtype=float32) \n",
      "\n",
      "random sample with sample_shape (3,):\n",
      " tf.Tensor(\n",
      "[[[-1.5597123   1.7975367 ]\n",
      "  [-0.19185328  1.7738345 ]\n",
      "  [ 2.08263     2.4822803 ]]\n",
      "\n",
      " [[-0.38727477  2.0092583 ]\n",
      "  [-0.14557171  1.3973126 ]\n",
      "  [ 2.0587924   1.7793128 ]]\n",
      "\n",
      " [[-0.8519139   1.2265338 ]\n",
      "  [ 2.0961163   2.3622608 ]\n",
      "  [ 2.6225648   2.068134  ]]], shape=(3, 3, 2), dtype=float32) \n",
      "\n",
      "random sample with sample_shape (2, 3):\n",
      " tf.Tensor(\n",
      "[[[[ 0.5470454   2.196875  ]\n",
      "   [ 0.5265571   2.461143  ]\n",
      "   [ 0.70663226  2.052195  ]]\n",
      "\n",
      "  [[ 0.74992186  1.7064099 ]\n",
      "   [ 0.10783082  1.7363937 ]\n",
      "   [ 1.7766122   3.305612  ]]\n",
      "\n",
      "  [[ 0.4534483   2.1120844 ]\n",
      "   [ 1.3965937   1.4270904 ]\n",
      "   [ 1.9378192   2.4216633 ]]]\n",
      "\n",
      "\n",
      " [[[ 1.1740996   0.16892165]\n",
      "   [ 0.6689609   3.3885884 ]\n",
      "   [ 0.23089004  2.011878  ]]\n",
      "\n",
      "  [[-0.25446165  1.2187932 ]\n",
      "   [ 1.6610126   0.70695627]\n",
      "   [ 3.5839667   3.2822618 ]]\n",
      "\n",
      "  [[ 1.6223348   1.2371515 ]\n",
      "   [ 1.7211132   2.2563286 ]\n",
      "   [ 4.7687783   2.5270607 ]]]], shape=(2, 3, 3, 2), dtype=float32)\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "J7Ax86-xcvyD",
    "colab_type": "text"
   },
   "source": [
    "## 最大概似估計法\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "f8eZ-35hcvyE",
    "colab_type": "text"
   },
   "source": [
    "### 可學習的分配與求解\n",
    "使用 `tensorflow` 來進行最大概似法，有許多種做法，其中，最重要的關鍵就在於如何建構概似函數。事實上，在前一小節中，我們已經可以計算在給定參數下，某個隨機樣本實現值之可能性，因此，關鍵就在於如何讓前述之可能性，轉為參數數值之函數，而最簡單的做法，就是將參數設為 `tf.Variable`，搭配自動微分與優化器對其進行更新。\n",
    "\n",
    "以下的程式碼建立了一 `batch_size` 為2的常態分配模型，我們可透過 `.trainable_varialbes` 來查看哪些變數是可以透過訓練更新其數值的。"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "MP-7H725cvyE",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "outputId": "aa7ae444-4a30-4c1a-80b9-4934458b50ee"
   },
   "source": [
    "batch_size = 2\n",
    "normal_model = tfd.Normal(\n",
    "        loc=tf.Variable(tf.zeros(batch_size), name='loc'),\n",
    "        scale=tf.Variable(tf.ones(batch_size), name='scale'))\n",
    "print(\"normal model:\\n\", normal_model, \"\\n\")\n",
    "print(\"parameters in normal model:\\n\", normal_model.trainable_variables)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "normal model:\n",
      " tfp.distributions.Normal(\"Normal\", batch_shape=[2], event_shape=[], dtype=float32) \n",
      "\n",
      "parameters in normal model:\n",
      " (<tf.Variable 'loc:0' shape=(2,) dtype=float32, numpy=array([0., 0.], dtype=float32)>, <tf.Variable 'scale:0' shape=(2,) dtype=float32, numpy=array([1., 1.], dtype=float32)>)\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "oceFlpMpdHSC",
    "colab_type": "text"
   },
   "source": [
    "TFP 的官方教學中，將前述的分配稱作可學習的分配（learnable distribution）。接著，我們在目前給定的參數數值下，產生一隨機樣本，此樣本在目前參數數值下的可能性，可簡單地使用 `.log_prob()` 方法與加總平均的計算獲得："
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "i6ZFZp1qcvyH",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "outputId": "89e7aa0a-6063-4749-a39f-416c91befa22"
   },
   "source": [
    "sample_size = 1000\n",
    "x = normal_model.sample(sample_shape=sample_size)\n",
    "loss_value = -tf.reduce_mean(tf.reduce_sum(normal_model.log_prob(x), axis = 1))\n",
    "print(\"negative likelihood value is \", loss_value.numpy())"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "negative likelihood value is  2.8669474\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "fErvUwgcdHSF",
    "colab_type": "text"
   },
   "source": [
    "最後，我們就可以透過優化器來求最大概似解了。在這邊需特別注意的是，由於 `loc` 與 `scale` 原本的數值為真實參數的數值，為了要展示優化器的正確運作，我們將其起始值設為一個較差的數值。"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "dVVB6J9VdHSG",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "outputId": "3e1bb5cb-7465-4584-878a-d073a6902c23"
   },
   "source": [
    "epochs = 400\n",
    "tol = 10**(-5)\n",
    "learning_rate = 1.0\n",
    "normal_model.loc.assign([1., 1.])\n",
    "normal_model.scale.assign([.5, .5])\n",
    "optimizer = tf.optimizers.Adam(learning_rate)\n",
    "for epoch in tf.range(epochs):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = -tf.reduce_mean(tf.reduce_sum(normal_model.log_prob(x), axis = 1))\n",
    "    gradients = tape.gradient(loss_value,\n",
    "                              normal_model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients,\n",
    "                                  normal_model.trainable_variables))\n",
    "    if (tf.reduce_max(\n",
    "            [tf.reduce_mean(\n",
    "                tf.math.abs(x)) for x in gradients]).numpy()) < tol:\n",
    "        print(\"{n} Optimizer Converges After {i} Iterations\".format(\n",
    "            n=optimizer.__class__.__name__, i=epoch))\n",
    "        break"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Adam Optimizer Converges After 271 Iterations\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "GfY2994EdHSI",
    "colab_type": "text"
   },
   "source": [
    "接著，我們比較優化器求得的解，以及分析解之間的差異（常態分配平均數與標準差的分析解即為樣本平均數與除上 $N$ 的標準差）"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "9uAr62N9dHSJ",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "outputId": "70d56207-f12d-4dbe-8cb0-e74579d26f92"
   },
   "source": [
    "print(\"ML mean estimate: \\n\", \n",
    "      normal_model.loc.numpy())\n",
    "print(\"ML standard deviation estimate: \\n\", \n",
    "      normal_model.scale.numpy())"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "ML mean estimate: \n",
      " [ 0.08081548 -0.01537854]\n",
      "ML standard deviation estimate: \n",
      " [0.99617445 1.0290864 ]\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Ja4QA3_GezuW",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "outputId": "b40dc325-85e8-453d-f463-cd589f92eed1"
   },
   "source": [
    "print(\"sample mean: \\n\", \n",
    "      tf.reduce_mean(x, axis = 0).numpy())\n",
    "print(\"sample standard deviation: \\n\", \n",
    "      tfp.stats.stddev(x, sample_axis = 0).numpy())"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "sample mean: \n",
      " [ 0.08081338 -0.01538018]\n",
      "sample standard deviation: \n",
      " [0.9961776 1.0290792]\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "PWe4hHu-cvyK",
    "colab_type": "text"
   },
   "source": [
    "我們可看到兩組解的數值幾乎相同，顯示優化器在這邊有確實地找到最大概似解。\n",
    "\n",
    "由於前述的優化程式碼，在後續的小節中仍然會持續被用到，故我們將其包成一個 `train` 函數，以便後續使用。"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "ttPqIUjbdHSO",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "def train(model, x, optimizer, initial_values, epochs, tol):\n",
    "    for initial_value, trainable_variable in \\\n",
    "            zip(initial_values, model.trainable_variables):\n",
    "        trainable_variable.assign(initial_value)\n",
    "    for epoch in tf.range(epochs):\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss_value = -tf.reduce_mean(\n",
    "                tf.reduce_sum(model.log_prob(x), axis = 1))\n",
    "        gradients = tape.gradient(loss_value,\n",
    "                                  model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients,\n",
    "                                      model.trainable_variables))\n",
    "        if (tf.reduce_max(\n",
    "                [tf.reduce_mean(\n",
    "                    tf.math.abs(x)) for x in gradients]).numpy()) < tol:\n",
    "            print(\"{n} Optimizer Converges After {i} Iterations\".format(\n",
    "                n=optimizer.__class__.__name__, i=epoch))\n",
    "            break"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "rae_6zMedHSR",
    "colab_type": "text"
   },
   "source": [
    "### 利用對射進行變數轉換\n",
    "前述的最大概似估計過程，並未對於參數估計之數值進行限制，其考慮的是非限制的優化問題（unconstrained optimization problem），然而，在實際進行優化時，若未對於參數數值進行限制的話，可能會獲得不合理之估計值（如負的變異數等）。\n",
    "\n",
    "在 TFP 的架構中，主要是透過對於參數進行對射（bijection），將原始受限制的參數轉為非限制的參數後進行估計。TFP 所內建的對射函數，可參考其 [官方網頁](https://www.tensorflow.org/probability/api_docs/python/tfp/bijectors)。\n",
    "\n",
    "在下面的範例中，我們利用 `tfp.util.TransformedVariable` 與 `tfb.Exp()` ，將常態分配的變異數 $\\sigma$ 參數化為 $\\exp(\\gamma)$，將原本需進行估計 $\\mu$ 與 $\\sigma$ 的優化問題，轉為估計 $\\mu$ 與 $\\gamma$，此時，我們不需要對 $\\gamma$ 的數值範圍進行限制，其在透過 $\\exp$ 函數的轉換後，會自動符合模型隱含的限制式。"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "5xEX0NuadHSR",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "outputId": "8e22e1bb-0d12-4135-855a-ee2a561c49fd"
   },
   "source": [
    "tfb = tfp.bijectors\n",
    "batch_size = 2\n",
    "normal_model_tr = tfd.Normal(\n",
    "    loc=tf.Variable(tf.zeros(batch_size), name='loc'),\n",
    "    scale=tfp.util.TransformedVariable(\n",
    "        tf.ones(batch_size),\n",
    "        bijector=tfb.Exp(), name=\"scale\"))\n",
    "print(\"normal model:\\n\", normal_model_tr, \"\\n\")\n",
    "print(\"parameters in normal model:\\n\", normal_model_tr.trainable_variables)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "normal model:\n",
      " tfp.distributions.Normal(\"Normal\", batch_shape=[2], event_shape=[], dtype=float32) \n",
      "\n",
      "parameters in normal model:\n",
      " (<tf.Variable 'loc:0' shape=(2,) dtype=float32, numpy=array([0., 0.], dtype=float32)>, <tf.Variable 'scale:0' shape=(2,) dtype=float32, numpy=array([0., 0.], dtype=float32)>)\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "oVvtaThrdHST",
    "colab_type": "text"
   },
   "source": [
    "我們可以直接使用前述的優化程式碼來獲得重新參數化後的參數估計"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "ZvEhEahkdHSU",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "outputId": "3716b593-4a66-4dfe-b62d-de1a21b3b062"
   },
   "source": [
    "train(model=normal_model_tr,\n",
    "      x=x,\n",
    "      optimizer=tf.optimizers.Adam(learning_rate=1.),\n",
    "      initial_values=([1., 1.], [.5, .5]),\n",
    "      epochs=400,\n",
    "      tol=10**(-5))\n",
    "\n",
    "print(\"ML mean estimate: \\n\",\n",
    "      normal_model_tr.loc.numpy())\n",
    "print(\"ML standard deviation estimate: \\n\",\n",
    "      normal_model_tr.scale.numpy())"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Adam Optimizer Converges After 208 Iterations\n",
      "ML mean estimate: \n",
      " [ 0.08081954 -0.01536704]\n",
      "ML standard deviation estimate: \n",
      " [0.9961892 1.0290959]\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "CTZysd6scvyK",
    "colab_type": "text"
   },
   "source": [
    "此變數轉換的作法，在進行多元常態分配共變異數估計時，特別的有幫助。一般來說，多元常態分配假設共變異數矩陣為對稱的正定矩陣（positive definite matrix），然而，一般在進行參數估計時，並無法保證此條件被滿足\n",
    "\n",
    "即便 `tfd.MultivariateNormalTriL` 已採用了"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "OWGvSlwUdHSY",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "outputId": "eb09d2ca-772c-4997-afbe-47718088e881"
   },
   "source": [
    "loc = tf.constant([0., 1., -1.])\n",
    "cov = tf.constant([[1, .3, .6], [.3, .5, .1], [.6, .1, 1.5]])\n",
    "to_scale_tril = tfb.Chain([\n",
    "    tfb.Invert(\n",
    "        tfb.FillTriangular(validate_args=True)),\n",
    "    tfb.TransformDiagonal(\n",
    "        tfb.Invert(tfb.Exp(validate_args=True)))])\n",
    "\n",
    "mvn_model = tfd.MultivariateNormalTriL(\n",
    "    loc=tf.Variable(loc, name='loc'),\n",
    "    scale_tril=tfp.util.TransformedVariable(\n",
    "        tf.linalg.cholesky(cov).numpy(),\n",
    "        bijector=tfp.bijectors.FillScaleTriL(\n",
    "            diag_bijector = tfb.Exp()),\n",
    "        name=\"scale\"))\n",
    "print(mvn_model)\n",
    "print(mvn_model.trainable_variables)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "tfp.distributions.MultivariateNormalTriL(\"MultivariateNormalTriL\", batch_shape=[], event_shape=[3], dtype=float32)\n",
      "(<tf.Variable 'loc:0' shape=(3,) dtype=float32, numpy=array([ 0.,  1., -1.], dtype=float32)>, <tf.Variable 'scale:0' shape=(6,) dtype=float32, numpy=\n",
      "array([ 5.8611017e-02, -1.2493903e-01,  6.0000002e-01, -1.0013630e-05,\n",
      "       -4.4581467e-01,  3.0000001e-01], dtype=float32)>)\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "3ipFEemRdHSa",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "outputId": "cd06e69d-ee79-4eb6-ac48-0f9932127d5c"
   },
   "source": [
    "print(tf.linalg.cholesky(cov).numpy())\n",
    "print(mvn_model.scale_tril.numpy())\n",
    "print(mvn_model.covariance().numpy())"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "[[ 1.          0.          0.        ]\n",
      " [ 0.3         0.64031243  0.        ]\n",
      " [ 0.6        -0.12493903  1.0603727 ]]\n",
      "[[ 0.99999994  0.          0.        ]\n",
      " [ 0.3         0.64031243  0.        ]\n",
      " [ 0.6        -0.12493903  1.0603727 ]]\n",
      "[[0.9999999  0.29999998 0.59999996]\n",
      " [0.29999998 0.5        0.09999999]\n",
      " [0.59999996 0.09999999 1.5       ]]\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ObGZ_E8Xpjec",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 478
    },
    "outputId": "542e6ba8-0b1a-42a8-c368-2b31fd4e6d71"
   },
   "source": [
    "x=mvn_model.sample([1000,1])\n",
    "optimizer=tf.optimizers.Adam(learning_rate=.5)\n",
    "epochs=400\n",
    "tol=10**(-5)\n",
    "\n",
    "for epoch in tf.range(epochs):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = -tf.reduce_mean(\n",
    "            tf.reduce_sum(mvn_model.log_prob(x), axis = 1))\n",
    "    gradients = tape.gradient(loss_value,\n",
    "                                mvn_model.trainable_variables)\n",
    "    print(gradients)\n",
    "    optimizer.apply_gradients(zip(gradients,\n",
    "                                    mvn_model.trainable_variables))\n",
    "    if (tf.reduce_max(\n",
    "            [tf.reduce_mean(\n",
    "                tf.math.abs(x)) for x in gradients]).numpy()) < tol:\n",
    "        print(\"{n} Optimizer Converges After {i} Iterations\".format(\n",
    "            n=optimizer.__class__.__name__, i=epoch))\n",
    "        break"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "(None, <tf.Tensor: shape=(6,), dtype=float32, numpy=\n",
      "array([0.9999907 , 0.        , 0.        , 0.99999017, 0.9999845 ,\n",
      "       0.        ], dtype=float32)>)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['loc:0'] when minimizing the loss.\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "ignored",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-166-1d50665c154f>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     15\u001B[0m     if (tf.reduce_max(\n\u001B[1;32m     16\u001B[0m             [tf.reduce_mean(\n\u001B[0;32m---> 17\u001B[0;31m                 tf.math.abs(x)) for x in gradients]).numpy()) < tol:\n\u001B[0m\u001B[1;32m     18\u001B[0m         print(\"{n} Optimizer Converges After {i} Iterations\".format(\n\u001B[1;32m     19\u001B[0m             n=optimizer.__class__.__name__, i=epoch))\n",
      "\u001B[0;32m<ipython-input-166-1d50665c154f>\u001B[0m in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m     15\u001B[0m     if (tf.reduce_max(\n\u001B[1;32m     16\u001B[0m             [tf.reduce_mean(\n\u001B[0;32m---> 17\u001B[0;31m                 tf.math.abs(x)) for x in gradients]).numpy()) < tol:\n\u001B[0m\u001B[1;32m     18\u001B[0m         print(\"{n} Optimizer Converges After {i} Iterations\".format(\n\u001B[1;32m     19\u001B[0m             n=optimizer.__class__.__name__, i=epoch))\n",
      "\u001B[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    178\u001B[0m     \u001B[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    179\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 180\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mtarget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    181\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mTypeError\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    182\u001B[0m       \u001B[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py\u001B[0m in \u001B[0;36mabs\u001B[0;34m(x, name)\u001B[0m\n\u001B[1;32m    263\u001B[0m   \"\"\"\n\u001B[1;32m    264\u001B[0m   \u001B[0;32mwith\u001B[0m \u001B[0mops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mname_scope\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"Abs\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 265\u001B[0;31m     \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconvert_to_tensor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"x\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    266\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mis_complex\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    267\u001B[0m       \u001B[0;32mreturn\u001B[0m \u001B[0mgen_math_ops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcomplex_abs\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mTout\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreal_dtype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001B[0m in \u001B[0;36mconvert_to_tensor\u001B[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001B[0m\n\u001B[1;32m   1339\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1340\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mret\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1341\u001B[0;31m       \u001B[0mret\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mconversion_func\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvalue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mas_ref\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mas_ref\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1342\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1343\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mret\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0mNotImplemented\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001B[0m in \u001B[0;36m_constant_tensor_conversion_function\u001B[0;34m(v, dtype, name, as_ref)\u001B[0m\n\u001B[1;32m    319\u001B[0m                                          as_ref=False):\n\u001B[1;32m    320\u001B[0m   \u001B[0m_\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mas_ref\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 321\u001B[0;31m   \u001B[0;32mreturn\u001B[0m \u001B[0mconstant\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mv\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    322\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    323\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001B[0m in \u001B[0;36mconstant\u001B[0;34m(value, dtype, shape, name)\u001B[0m\n\u001B[1;32m    260\u001B[0m   \"\"\"\n\u001B[1;32m    261\u001B[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001B[0;32m--> 262\u001B[0;31m                         allow_broadcast=True)\n\u001B[0m\u001B[1;32m    263\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    264\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001B[0m in \u001B[0;36m_constant_impl\u001B[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001B[0m\n\u001B[1;32m    268\u001B[0m   \u001B[0mctx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcontext\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcontext\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    269\u001B[0m   \u001B[0;32mif\u001B[0m \u001B[0mctx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexecuting_eagerly\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 270\u001B[0;31m     \u001B[0mt\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mconvert_to_eager_tensor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvalue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mctx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    271\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mshape\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    272\u001B[0m       \u001B[0;32mreturn\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001B[0m in \u001B[0;36mconvert_to_eager_tensor\u001B[0;34m(value, ctx, dtype)\u001B[0m\n\u001B[1;32m     94\u001B[0m       \u001B[0mdtype\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdtypes\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mas_dtype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mas_datatype_enum\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     95\u001B[0m   \u001B[0mctx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mensure_initialized\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 96\u001B[0;31m   \u001B[0;32mreturn\u001B[0m \u001B[0mops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mEagerTensor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvalue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mctx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdevice_name\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     97\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     98\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: Attempt to convert a value (None) with an unsupported type (<class 'NoneType'>) to a Tensor."
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "gwNGrAwxur3-",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "outputId": "3d1406d6-cdd0-415a-c367-9500e12f3594"
   },
   "source": [
    "mvn_model.trainable_variables"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(<tf.Variable 'loc:0' shape=(3,) dtype=float32, numpy=array([ 0.,  1., -1.], dtype=float32)>,\n",
       " <tf.Variable 'scale:0' shape=(6,) dtype=float32, numpy=\n",
       " array([-0.4414023 , -0.12493903,  0.6       , -0.50002337, -0.945828  ,\n",
       "         0.3       ], dtype=float32)>)"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 173
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    loss_value = -tf.reduce_mean(\n",
    "        tf.reduce_sum(mvn_model.log_prob(x), axis = 1))\n",
    "gradients = tape.gradient(loss_value,\n",
    "                          mvn_model.trainable_variables)\n",
    "gradients"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "loss_value = -tf.reduce_mean(\n",
    "        tf.reduce_sum(mvn_model.log_prob(x), axis = 1))\n",
    "loss_value"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mvn_model.covariance()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x = mvn_model.sample([1000,1])\n",
    "train(model=mvn_model,\n",
    "      x=x,\n",
    "      optimizer=tf.optimizers.Adam(learning_rate=.5),\n",
    "      initial_values=([1., 1., 1.], [0., 0., 0., 0., 0., 0.]),\n",
    "      epochs=400,\n",
    "      tol=10**(-5))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mvn_model.trainable_variables"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dims = 4\n",
    "mvn = tfd.MultivariateNormalTriL(\n",
    "    loc=tf.Variable(tf.zeros([dims], dtype=tf.float32), name=\"mu\"),\n",
    "    scale_tril=tfp.util.TransformedVariable(\n",
    "        tf.constant([[1,0,0,0],[2,3,0,0],[4,5,6,0],[7,8,9,10]], dtype=tf.float32),\n",
    "        tfp.bijectors.FillScaleTriL(diag_bijector = tfb.Identity(),\n",
    "                                    diag_shift=0),\n",
    "        name=\"raw_scale_tril\"))\n",
    "mvn.trainable_variables[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(tf.constant([[1,0,0,0],[2,3,0,0],[4,5,6,0],[7,8,9,10]], dtype=tf.float32).numpy())\n",
    "print(mvn.trainable_variables[1].numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "WNGem3O0rwan",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "outputId": "45e638d8-c2ba-4575-c436-916c824ae358"
   },
   "source": [
    "## 建立複雜機率模型\n"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 175
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "LoBog7er0EoQ",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "outputId": "5d2ce4a1-b612-4a39-da2b-390002fbe95d"
   },
   "source": [
    "loss_value = -tf.reduce_mean(\n",
    "        tf.reduce_sum(mvn_model.log_prob(x), axis = 1))\n",
    "loss_value"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=3.8393295>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 174
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "J3Lf5hFLqCM5",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "outputId": "542f931e-8879-4235-bf4d-20b24ae60d75"
   },
   "source": [
    "mvn_model.covariance()"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[1.00002, 0.     , 0.     ],\n",
       "       [0.     , 1.00002, 0.     ],\n",
       "       [0.     , 0.     , 1.00002]], dtype=float32)>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 149
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "NC_FDFbOoBeR",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 390
    },
    "outputId": "37357f58-640b-4877-bad3-4134cf134bc0"
   },
   "source": [
    "x = mvn_model.sample([1000,1])\n",
    "train(model=mvn_model,\n",
    "      x=x,\n",
    "      optimizer=tf.optimizers.Adam(learning_rate=.5),\n",
    "      initial_values=([1., 1., 1.], [0., 0., 0., 0., 0., 0.]),\n",
    "      epochs=400,\n",
    "      tol=10**(-5))"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['loc:0'] when minimizing the loss.\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "ignored",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-122-66a962f032b5>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      5\u001B[0m       \u001B[0minitial_values\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1.\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m1.\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m1.\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;36m0.\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0.\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0.\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0.\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0.\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0.\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m       \u001B[0mepochs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m400\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 7\u001B[0;31m       tol=10**(-5))\n\u001B[0m",
      "\u001B[0;32m<ipython-input-120-80094d9fc0ad>\u001B[0m in \u001B[0;36mtrain\u001B[0;34m(model, x, optimizer, initial_values, epochs, tol)\u001B[0m\n\u001B[1;32m     12\u001B[0m         if (tf.reduce_max(\n\u001B[1;32m     13\u001B[0m                 [tf.reduce_mean(\n\u001B[0;32m---> 14\u001B[0;31m                     tf.math.abs(x)) for x in gradients]).numpy()) < tol:\n\u001B[0m\u001B[1;32m     15\u001B[0m             print(\"{n} Optimizer Converges After {i} Iterations\".format(\n\u001B[1;32m     16\u001B[0m                 n=optimizer.__class__.__name__, i=epoch))\n",
      "\u001B[0;32m<ipython-input-120-80094d9fc0ad>\u001B[0m in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m     12\u001B[0m         if (tf.reduce_max(\n\u001B[1;32m     13\u001B[0m                 [tf.reduce_mean(\n\u001B[0;32m---> 14\u001B[0;31m                     tf.math.abs(x)) for x in gradients]).numpy()) < tol:\n\u001B[0m\u001B[1;32m     15\u001B[0m             print(\"{n} Optimizer Converges After {i} Iterations\".format(\n\u001B[1;32m     16\u001B[0m                 n=optimizer.__class__.__name__, i=epoch))\n",
      "\u001B[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    178\u001B[0m     \u001B[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    179\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 180\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mtarget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    181\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mTypeError\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    182\u001B[0m       \u001B[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py\u001B[0m in \u001B[0;36mabs\u001B[0;34m(x, name)\u001B[0m\n\u001B[1;32m    263\u001B[0m   \"\"\"\n\u001B[1;32m    264\u001B[0m   \u001B[0;32mwith\u001B[0m \u001B[0mops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mname_scope\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"Abs\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 265\u001B[0;31m     \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconvert_to_tensor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"x\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    266\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mis_complex\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    267\u001B[0m       \u001B[0;32mreturn\u001B[0m \u001B[0mgen_math_ops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcomplex_abs\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mTout\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreal_dtype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001B[0m in \u001B[0;36mconvert_to_tensor\u001B[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001B[0m\n\u001B[1;32m   1339\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1340\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mret\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1341\u001B[0;31m       \u001B[0mret\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mconversion_func\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvalue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mas_ref\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mas_ref\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1342\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1343\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mret\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0mNotImplemented\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001B[0m in \u001B[0;36m_constant_tensor_conversion_function\u001B[0;34m(v, dtype, name, as_ref)\u001B[0m\n\u001B[1;32m    319\u001B[0m                                          as_ref=False):\n\u001B[1;32m    320\u001B[0m   \u001B[0m_\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mas_ref\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 321\u001B[0;31m   \u001B[0;32mreturn\u001B[0m \u001B[0mconstant\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mv\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    322\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    323\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001B[0m in \u001B[0;36mconstant\u001B[0;34m(value, dtype, shape, name)\u001B[0m\n\u001B[1;32m    260\u001B[0m   \"\"\"\n\u001B[1;32m    261\u001B[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001B[0;32m--> 262\u001B[0;31m                         allow_broadcast=True)\n\u001B[0m\u001B[1;32m    263\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    264\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001B[0m in \u001B[0;36m_constant_impl\u001B[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001B[0m\n\u001B[1;32m    268\u001B[0m   \u001B[0mctx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcontext\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcontext\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    269\u001B[0m   \u001B[0;32mif\u001B[0m \u001B[0mctx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexecuting_eagerly\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 270\u001B[0;31m     \u001B[0mt\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mconvert_to_eager_tensor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvalue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mctx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    271\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mshape\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    272\u001B[0m       \u001B[0;32mreturn\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001B[0m in \u001B[0;36mconvert_to_eager_tensor\u001B[0;34m(value, ctx, dtype)\u001B[0m\n\u001B[1;32m     94\u001B[0m       \u001B[0mdtype\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdtypes\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mas_dtype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mas_datatype_enum\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     95\u001B[0m   \u001B[0mctx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mensure_initialized\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 96\u001B[0;31m   \u001B[0;32mreturn\u001B[0m \u001B[0mops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mEagerTensor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvalue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mctx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdevice_name\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     97\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     98\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: Attempt to convert a value (None) with an unsupported type (<class 'NoneType'>) to a Tensor."
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "0pjhy3iRsf0z",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "outputId": "2b40a4e9-24a4-41a3-e513-c72a5ada38bf"
   },
   "source": [
    "mvn_model.trainable_variables"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(<tf.Variable 'loc:0' shape=(3,) dtype=float32, numpy=array([1., 1., 1.], dtype=float32)>,\n",
       " <tf.Variable 'scale:0' shape=(6,) dtype=float32, numpy=\n",
       " array([-1.0000266,  0.       ,  0.       , -1.0000266, -1.0000266,\n",
       "         0.       ], dtype=float32)>)"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 115
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "yMC1P9tYdgT5",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "outputId": "072b17b6-9b7a-481b-b500-16052a809954"
   },
   "source": [
    "dims = 4\n",
    "mvn = tfd.MultivariateNormalTriL(\n",
    "    loc=tf.Variable(tf.zeros([dims], dtype=tf.float32), name=\"mu\"),\n",
    "    scale_tril=tfp.util.TransformedVariable(\n",
    "        tf.constant([[1,0,0,0],[2,3,0,0],[4,5,6,0],[7,8,9,10]], dtype=tf.float32),\n",
    "        tfp.bijectors.FillScaleTriL(diag_bijector = tfb.Identity(),\n",
    "                                    diag_shift=0),\n",
    "        name=\"raw_scale_tril\"))\n",
    "mvn.trainable_variables[1]"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Variable 'raw_scale_tril:0' shape=(10,) dtype=float32, numpy=array([10.,  9.,  8.,  7.,  1.,  6.,  5.,  4.,  2.,  3.], dtype=float32)>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 61
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "3eHQ-Prfgx69",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "outputId": "faed9a03-133d-43a4-bad9-798562b270d4"
   },
   "source": [
    "print(tf.constant([[1,0,0,0],[2,3,0,0],[4,5,6,0],[7,8,9,10]], dtype=tf.float32).numpy())\n",
    "print(mvn.trainable_variables[1].numpy())"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "[[ 1.  0.  0.  0.]\n",
      " [ 2.  3.  0.  0.]\n",
      " [ 4.  5.  6.  0.]\n",
      " [ 7.  8.  9. 10.]]\n",
      "[10.  9.  8.  7.  1.  6.  5.  4.  2.  3.]\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "XLsBdR-udHSj",
    "colab_type": "text"
   },
   "source": [
    "## 建立複雜機率模型\n"
   ]
  }
 ]
}